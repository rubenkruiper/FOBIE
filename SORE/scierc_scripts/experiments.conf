# Word embeddings.


glove_300d_filtered {
  path = embeddings/glove.840B.300d.txt.filtered
  size = 300
  format = txt
  lowercase = false
}


glove_300d_2w {
  path = embeddings/glove_50_300_2.txt
  size = 300
  format = txt
  lowercase = false
}


# Main configuration.
best {
  # Computation limits.
  max_antecedents = 250
  max_training_sentences = 50
  top_span_ratio = 0.8

  # Model hyperparameters.
  filter_widths = [3, 4, 5]
  filter_size = 50
  char_embedding_size = 8
  char_vocab_path = "char_vocab_old.english.txt"
  context_embeddings = ${glove_300d_filtered}
  head_embeddings = ${glove_300d_2w}
  contextualizer = lstm
  contextualization_size = 200
  contextualization_layers = 3
  ffnn_size = 150
  ffnn_depth = 2
  feature_size = 20
  max_span_width = 14
  use_metadata = true
  use_features = true
  model_heads = true
  lm_layers = 3
  lm_size = 1024
  sva = false

  # Learning hyperparameters.
  max_gradient_norm = 5.0
  lexical_dropout_rate = 0.5
  dropout_rate = 0.2
  lstm_dropout_rate = 0.4
  optimizer = adam
  learning_rate = 0.001
  decay_rate = 0.999
  decay_frequency = 100
  const_weight = 0  # 0.1
  ner_weight = 0  # 0.1

  eval_frequency = 1000
  report_frequency = 250
  log_root = logs
  eval_sleep_secs = 600
}

mtl_best = ${best} {
  char_embedding_size = 8
  contextualization_layers = 3
  contextualization_size = 200

  use_features = true
  use_metadata = true
  model_heads = true
  task_heads = false

  max_arg_width = 14
  argument_ratio = 0.8

  lexical_dropout_rate = 0.5
  dropout_rate = 0.2
  lstm_dropout_rate = 0.4
  optimizer = adam
  learning_rate = 0.001
  decay_rate = 0.999
  decay_frequency = 100

  num_attention_heads = 1
  span_score_weight = 0.0

  eval_sleep_secs = 1200


  coref_loss = "mention_rank"
  enforce_srl_constraint = false
  filter_v_args = true
  use_gold_predicates = false
  srl_weight = 0
  ner_weight = 1.0
  coref_weight = 0
  const_weight = 0.0

  batch_size = 40
  max_tokens_per_batch = 700

  # Updated dataset.
  train_path = train.english.mtl.jsonlines
  eval_path = dev.english.mtl.jsonlines
  lm_layers = 3
  lm_size = 1024
  main_metrics = srl_coref_ner

}

# Scientific KG experiments


scientific_entity = ${mtl_best} {
  include_c_v = false
  coref_weight = 0.0
  ner_weight = 1.0
  relation_weight = 0.0
  max_arg_width = 5
  contextualization_layers = 1
  main_metrics = ner

  ner_conll_eval_path = ""
  eval_frequency = 50
  report_frequency = 25
  eval_sleep_secs = 10

  filter_reverse_relations = true
  entity_ratio = 0.5
  coref_weight = 0.5
  ner_weight = 0.5
  max_arg_width = 10
  main_metrics = coref_ner
  use_metadata = false
}


fobie_nolabels = ${scientific_entity} {

  ner_labels = ["None","generic"]
  relation_labels = ["None", "TradeOff", "Not_a_TradeOff", "Arg_Modifier"]

  coref_weight = 0
  ner_weight = 0.33
  relation_weight = 1.0
  main_metrics = ner_relations
  batch_size = 10
  mention_ratio = 0.3
  entity_ratio = 0.3
  max_arg_width = 14

  # lm_path = "./data/processed_data/elmo/train_set_SCIIE.hdf5"
  # lm_path_dev = "./data/processed_data/elmo/dev_set_SCIIE.hdf5"
  # train_path = "./data/processed_data/json/train_set_SCIIE_generic.json"
  # eval_path = "./data/processed_data/json/dev_set_SCIIE_generic.json"
  # output_path = "./FOBIE_output/predictions_dev_generic.json"

  lm_path = "./data/processed_data/elmo/test_set_SCIIE.hdf5"
  lm_path_dev = "./data/processed_data/elmo/test_set_SCIIE.hdf5"
  train_path = "./data/processed_data/json/train_set_SCIIE_generic.json"
  eval_path = "./data/processed_data/json/test_set_SCIIE_generic.json"
  output_path = "./FOBIE_output/predictions_test_generic.json"

}


fobie_train = ${scientific_entity} {

  ner_labels = ["None","trigger", "argument"]
  relation_labels = ["None", "TradeOff", "Not_a_TradeOff", "Arg_Modifier"]

  coref_weight = 0
  ner_weight = 0.33
  relation_weight = 1.0
  main_metrics = ner_relations
  batch_size = 10
  mention_ratio = 0.3
  entity_ratio = 0.3
  max_arg_width = 14

  lm_path = "./data/processed_data/elmo/train_set_SCIIE.hdf5"
  train_path = "./data/processed_data/json/train_set_SCIIE.json"

  # also see replacement options below for making predictions on a single filtered
  # (You'll need to generate the ELMo embeddings for that file)
  lm_path_dev = "./data/processed_data/elmo/dev_set_SCIIE.hdf5"
  eval_path = "./data/processed_data/json/dev_set_SCIIE.json"
  output_path = "./FOBIE_output/predictions_dev_set_SCIIE.json"
}

fobie_example_replacements = ${fobie_train} {
#  Change the paths in fobie_train, examples below.
#  To predict and write predictions to output_path, run:
#  $ python write_single.py fobie_train

  lm_path_dev = "./data/processed_data/elmo/dev_set_SCIIE.hdf5"
  eval_path = "./data/processed_data/json/dev_set_SCIIE.json"
  output_path = "./FOBIE_output/predictions_dev_set_SCIIE.json"

  lm_path_dev = "./data/processed_data/elmo/test_set_SCIIE.hdf5"
  eval_path = "./data/processed_data/json/test_set_SCIIE.json"
  output_path = "./FOBIE_output/predictions_test_set_SCIIE.json"

  lm_path_dev = "./data/processed_data/elmo/example_input.hdf5"
  eval_path = "./data/processed_data/json/example_input.json"
  output_path = "./FOBIE_output/predictions_example_input.json"
}
