[LINE#0] In this research, we developed a robust two-layer classifier that can accurately classify normal hearing (NH) from hearing impaired (HI) infants with congenital sensori-neural hearing loss (SNHL) based on their Magnetic Resonance (MR) images.
0.924	[*A*]a robust two-layer classifier[*R*]can accurately classify[*A*]normal hearing[*A*]from hearing impaired (HI) infants with congenital sensori-neural hearing loss (SNHL) based on their Magnetic Resonance (MR) images	context()	negated: False ,passive: False
[LINE#1+2]  Unlike traditional methods that examine the intensity of each single voxel, we extracted high-level features to characterize the structural MR images (sMRI) and functional MR images.
0.614	[*A*]we[*R*]extracted[*A*]high - level features to characterize the functional MR images	context()	negated: False ,passive: False
0.614	[*A*]we[*R*]extracted[*A*]high - level features to characterize the structural MR images ( sMRI )	context()	negated: False ,passive: False
0.887	[*A*]traditional methods[*R*]examine[*A*]the intensity of each single voxel	context()	negated: False ,passive: False
[LINE#3] The Scale Invariant Feature Transform (SIFT) algorithm was employed to detect and describe the local features in sMRI.
0.905	[*A*]The Scale[*R*]was employed[*A*]to describe the local features in sMRI	context()	negated: False ,passive: True
0.735	[*A*]The Scale[*R*]was employed[*A*]to detect	context()	negated: False ,passive: True
[LINE#4] For fMRI, we constructed contrast maps and detected the most activated/de-activated regions in each individual.
0.639	[*A*]we[*R*]detected[*A*]the most activated / de-activated regions[*A*]For fMRI	context()	negated: False ,passive: False
0.639	[*A*]we[*R*]constructed[*A*]contrast maps[*A*]For fMRI	context()	negated: False ,passive: False
[LINE#5] Based on those salient regions occurring across individuals, the bag-of-words strategy was introduced to vectorize the contrast maps.
0.938	[*A*]the bag-of-words strategy[*R*]was introduced[*A*]to vectorize the contrast maps	context()	negated: False ,passive: True
0.911	[*A*]those salient regions[*R*]occurring[*A*]across individuals	context()	negated: False ,passive: True
[LINE#6] We then used a two-layer model to integrate these two types of features together.
0.343	[*A*]We[*R*]used a two-layer model to integrate together[*A*]these two types of features	context(We used)	negated: False ,passive: False
0.489	[*A*]We[*R*]used[*A*]a two-layer model[*A*]to integrate these two types of features together[*A*]then	context()	negated: False ,passive: False
[LINE#7] With the leave-one-out cross-validation approach, this integrated model achieved an AUC score of 0.90.
0.925	[*A*]this integrated model[*R*]achieved[*A*]an AUC score of 0.90	context()	negated: False ,passive: False
[LINE#8] Additionally, our algorithm highlighted several important brain regions that differentiated between NH and HI children.
0.920	[*A*]several important brain regions[*R*]differentiated[*A*]between NH and HI children	context()	negated: False ,passive: True
0.554	[*A*]our algorithm[*R*]highlighted[*A*]several important brain regions that differentiated between NH and HI children	context()	negated: False ,passive: False
[LINE#9] e.g. planum temporale and angular gyrus, were well known auditory and visual language association regions.
[LINE#10] Others, e.g. the anterior cingulate cortex (ACC), were not necessarily expected to play a role in differentiating HI from NH children and provided a new understanding of brain function and of the disorder itself.
0.894	[*A*]Others[*R*]provided[*A*]a new understanding of the disorder	context()	negated: False ,passive: False
0.894	[*A*]Others[*R*]provided[*A*]a new understanding of brain function	context()	negated: False ,passive: False
0.896	[*A*]Others[*R*]to play[*A*]a role in differentiating HI from NH children	context()	negated: False ,passive: False
0.578	[*A*]Others[*R*]were not expected	context()	negated: True ,passive: False
[LINE#11] These important brain regions provided clues about neuroimaging markers that may be relevant to the future use of functional neuroimaging to guide predictions about speech and language outcomes in HI infants who receive a cochlear implant.
0.934	[*A*]language outcomes in HI infants[*R*]receive[*A*]a cochlear implant	context()	negated: False ,passive: False
0.934	[*A*]speech outcomes in HI infants[*R*]receive[*A*]a cochlear implant	context()	negated: False ,passive: False
0.877	[*A*]markers[*R*]may be[*A*]relevant to the future use of functional neuroimaging	context()	negated: False ,passive: True
0.919	[*A*]These important brain regions[*R*]provided[*A*]clues about neuroimaging markers	context()	negated: False ,passive: False
[LINE#12] This type of prognostic information could be extremely useful and is currently not available to clinicians by any other means.
0.916	[*A*]This type[*R*]is not[*A*]available to clinicians by any other means[*A*]currently	context()	negated: True ,passive: True
0.814	[*A*]This type of prognostic information[*R*]could be[*A*]extremely useful	context()	negated: False ,passive: True
[LINE#13] , our study demonstrates that HI and NH infants can be differentiated by brain MR images, e.g. different fMRI contrasts in auditory language network and auditory brain stem nuclei.
[LINE#14] Based upon the discriminative features, a classification model can be built to predict whether an individual has normal hearing or impaired hearing.
0.943	[*A*]a classification model[*R*]can be built[*A*]to predict whether an individual has normal hearing or impaired hearing	context()	negated: False ,passive: True
[LINE#15] The discriminative features may also be used as objective biomarkers of hearing loss or used for further disease mechanism studies.
0.897	[*A*]The discriminative features[*R*]used[*A*]for further disease mechanism studies	context()	negated: False ,passive: True
0.870	[*A*]The discriminative features[*R*]may be used[*A*]as objective biomarkers of hearing loss	context()	negated: False ,passive: True
[LINE#16] Secondly, our two-layer model integrates sMRI and fMRI in an effective way.
0.739	[*A*]our two - layer model[*R*]integrates[*A*]fMRI	context()	negated: False ,passive: False
0.739	[*A*]our two - layer model[*R*]integrates[*A*]sMRI	context()	negated: False ,passive: False
[LINE#17] While our sMRI classifier and fMRI classifier work moderately well individually, the combination of the two classifiers gives birth to a much more powerful classifier, which corroborates the hypothesis that integration of multiple modalities improves classification accuracy.
0.905	[*A*]that integration of multiple modalities[*R*]improves[*A*]classification accuracy	context(a much more powerful classifier corroborates)	negated: False ,passive: False
0.905	[*A*]that integration of multiple modalities[*R*]improves[*A*]classification accuracy	context(a much more powerful classifier corroborates)	negated: False ,passive: False
0.890	[*A*]a much more powerful classifier[*R*]corroborates[*A*]the hypothesis	context()	negated: False ,passive: False
0.932	[*A*]the combination of the two classifiers[*R*]gives[*A*]birth[*A*]to a much more powerful classifier	context()	negated: False ,passive: False
[LINE#18] Besides, our integration approach is very flexible, and it can be easily extended to include many diverse types of data.
0.411	[*A*]it[*R*]to include[*A*]many diverse types of data	context()	negated: False ,passive: True
0.452	[*A*]it[*R*]can be easily extended[*A*]to include many diverse types of data	context()	negated: False ,passive: True
0.476	[*A*]our integration approach[*R*]is[*A*]very flexible	context()	negated: False ,passive: True
[LINE#19] Future work with this machine learning approach to automated image classification may allow us to make predictions about speech and language outcomes in individual children who receive cochlear implants for remediation of congenital hearing impairment.
0.388	[*A*]us[*R*]to make[*A*]predictions about language outcomes in individual children	context(Future work with this machine learning approach to automated image classification may allow)	negated: False ,passive: False
0.937	[*A*]Future work with this machine learning approach to automated image classification[*R*]may allow[*A*]us to make predictions about language outcomes in individual children	context()	negated: False ,passive: False
0.388	[*A*]us[*R*]to make[*A*]predictions about speech outcomes in individual children	context(Future work with this machine learning approach to automated image classification may allow)	negated: False ,passive: False
0.937	[*A*]Future work with this machine learning approach to automated image classification[*R*]may allow[*A*]us to make predictions about speech outcomes in individual children	context()	negated: False ,passive: False
0.887	[*A*]individual children[*R*]receive[*A*]cochlear implants	context()	negated: False ,passive: False
[LINE#20]  The following are the supplementary data related to this articleFig..
0.925	[*A*]the supplementary data[*R*]related[*A*]to this articleFig	context()	negated: False ,passive: True
0.613	[*A*]The following[*R*]are[*A*]the supplementary data related to this articleFig	context()	negated: False ,passive: True
[LINE#21] S1Distribution of sMRI-fMRI scores for all 39 folds of cross validation.
[LINE#22] Each panel is one-fold of cross-validation.
0.925	[*A*]Each panel[*R*]is[*A*]one-fold of cross-validation	context()	negated: False ,passive: True
[LINE#23] Horizontal axis is the output of the sMRI classifier and vertical axis is the output of the fMRI classifier.
0.946	[*A*]the output of the vertical axis[*R*]is[*A*]the output of the fMRI classifier	context(Horizontal axis is)	negated: False ,passive: True
0.950	[*A*]Horizontal axis[*R*]is[*A*]the output of the vertical axis is the output of the fMRI classifier	context()	negated: False ,passive: True
0.960	[*A*]the output of the sMRI classifier[*R*]is[*A*]the output of the fMRI classifier	context(Horizontal axis is)	negated: False ,passive: True
0.950	[*A*]Horizontal axis[*R*]is[*A*]the output of the sMRI classifier is the output of the fMRI classifier	context()	negated: False ,passive: True
[LINE#24] Blue dots are HI training samples, red dots are NH training samples, the black star is the testing sample.
0.900	[*A*]Blue dots[*R*]are[*A*]HI training samples	context(red dots are the black star is)	negated: False ,passive: True
0.900	[*A*]red dots[*R*]are[*A*]NH training samples	context(the black star is)	negated: False ,passive: True
0.916	[*A*]the black star[*R*]is[*A*]the testing sample	context()	negated: False ,passive: True
[LINE#25] The true label of the testing sample is HI for fold1 to fold18, and NH for fold19 to fold39.Supplementary data to this article can be found online at http://dx.doi.org/10.1016/j.nicl.2013.09.008.
0.820	[*A*]The NH for fold19[*R*]can be found[*A*]online[*A*]at http://dx.doi.org/10.1016/j.nicl.2013.09.008.	context()	negated: False ,passive: True
0.960	[*A*]The true label of the testing sample[*R*]is[*A*]HI for fold1	context()	negated: False ,passive: True
[LINE#26] In this work, we have built a robust two-layer classifier that can accurately separate HI from NH infants.
0.933	[*A*]a robust two-layer classifier[*R*]can accurately separate[*A*]HI[*A*]from NH infants	context()	negated: False ,passive: False
0.509	[*A*]we[*R*]have built[*A*]a robust two-layer classifier that can accurately separate HI from NH infants[*A*]In this work	context()	negated: False ,passive: False
[LINE#27] We realize that hearing in newborns can be accurately tested using the auditory brainstem response (ABR) evaluations or the otoacoustic emission (OAE) measures, it is thus not our intention to develop a tool for computer-aided diagnosis of hearing loss.
0.319	[*A*]it[*R*]is not[*A*]our intention to develop a tool for computer-aided diagnosis of hearing loss	context()	negated: True ,passive: True
0.317	[*A*]We[*R*]realize[*A*]that hearing in newborns can be accurately tested using the auditory brainstem response (ABR) evaluations or the otoacoustic emission (OAE) measures	context()	negated: False ,passive: False
[LINE#28] Rather we provide a proof of principle that it is possible to accurately determine the functional, developmental status of the central auditory system in congenitally hearing impaired children based on MR images alone by utilizing machine learning techniques.
0.918	[*A*]impaired children[*R*]based[*A*]on MR images alone	context()	negated: False ,passive: True
0.240	[*A*]we[*R*]provide[*A*]a proof of principle that it is possible to accurately determine the functional, developmental status of the central auditory system in congenitally hearing impaired children based on MR images alone by utilizing machine learning techniques	context()	negated: False ,passive: False
[LINE#29] Such success has been previously reported in other progressive diseases, such as Alzheimer's disease (Cuingnet et al., 2011).
0.954	[*A*]Such success[*R*]has been reported[*A*]in other progressive diseases, such as Alzheimer's disease[*A*]previously	context()	negated: False ,passive: True
[LINE#30] However, for many progressive diseases, definite diagnosis is often difficult to establish, in which case the LOOCV approach may not be able to estimate the classifier performance accurately.
0.920	[*A*]the LOOCV approach[*R*]to estimate accurately[*A*]the classifier performance	context()	negated: False ,passive: False
0.933	[*A*]the LOOCV approach[*R*]may not be[*A*]able to estimate the classifier performance accurately	context()	negated: True ,passive: True
0.813	[*A*]definite diagnosis[*R*]is[*A*]often[*A*]difficult to establish	context()	negated: False ,passive: True
[LINE#31] Therefore, our dataset with solid labels corresponding to diagnostic categories of the participants that have NH or HI enables us to make an objective evaluation of our algorithm, and demonstrate conclusively the feasibility of using machine learning in making automated diagnoses or prognoses based on imaging examinations.
0.350	[*A*]us[*R*]to demonstrate conclusively[*A*]the feasibility of using machine	context()	negated: False ,passive: False
0.309	[*A*]us[*R*]to make[*A*]an objective evaluation of our algorithm	context()	negated: False ,passive: False
0.634	[*A*]our dataset with solid labels[*R*]enables[*A*]us[*A*]to make an objective evaluation of our algorithm, and demonstrate conclusively the feasibility of using machine	context()	negated: False ,passive: False
0.713	[*A*]machine[*R*]learning	context()	negated: False ,passive: False
0.905	[*A*]the participants[*R*]have[*A*]NH or HI	context()	negated: False ,passive: False
0.903	[*A*]solid labels[*R*]corresponding[*A*]to diagnostic categories of the participants	context()	negated: False ,passive: True
[LINE#32+33]  The approach described here may not be limited to a specific disease; essentially, any disease dataset with sMRI and fMRIbrain images can be analyzed with our method provided that sufficient training data is available.
0.717	[*A*]The approach[*R*]described[*A*]here	context(any disease dataset with fMRIbrain images can be analyzed)	negated: False ,passive: False
0.756	[*A*]any disease dataset with fMRIbrain images[*R*]can be analyzed	context()	negated: False ,passive: False
0.903	[*A*]any disease[*R*]dataset[*A*]with fMRIbrain images	context()	negated: False ,passive: True
0.717	[*A*]The approach[*R*]described[*A*]here	context(any disease dataset with sMRI images can be analyzed)	negated: False ,passive: False
0.808	[*A*]any disease dataset with sMRI images[*R*]can be analyzed	context()	negated: False ,passive: False
0.341	[*A*]our method[*R*]provided	context()	negated: False ,passive: False
0.918	[*A*]any disease[*R*]dataset[*A*]with sMRI images	context()	negated: False ,passive: True
0.828	[*A*]sufficient training data[*R*]is[*A*]available	context()	negated: False ,passive: True
[LINE#34] A major innovation that makes highly accurate predictions possible in our approach is that we extracted high-level features instead of using each single voxel as a feature as in traditional approaches.
0.514	[*A*]we[*R*]extracted[*A*]high-level features instead of using each single voxel as a feature as in traditional approaches	context(A major innovation that makes highly accurate predictions possible in our approach is)	negated: False ,passive: False
0.610	[*A*]A major innovation that makes highly accurate predictions possible in our approach[*R*]is[*A*]that we extracted high-level features instead of using each single voxel as a feature as in traditional approaches	context()	negated: False ,passive: True
0.825	[*A*]A major innovation[*R*]makes[*A*]highly accurate predictions possible[*A*]in our approach	context()	negated: False ,passive: False
[LINE#35] The SIFT features from sMRI images and region-level features from fMRI images are much less sensitive to registration errors when compared to voxel-features.
0.939	[*A*]The SIFT features from region - level features from fMRI images[*R*]are[*A*]much less sensitive to registration errors[*A*]when compared to voxel - features	context()	negated: False ,passive: True
0.905	[*A*]The SIFT features from sMRI images[*R*]are[*A*]much less sensitive to registration errors[*A*]when compared to voxel - features	context()	negated: False ,passive: True
[LINE#36] In addition, utilization of high-level features can considerably reduce the dimensionality of feature space, which not only makes our classification problem easier to handle, but also helps to reduce the problem of over-fitting.
0.899	[*A*]utilization of high - level features[*R*]can reduce[*A*]the dimensionality of feature	context()	negated: False ,passive: False
0.810	[*A*]feature space[*R*]makes[*A*]our classification problem easier to handle	context()	negated: False ,passive: False
0.899	[*A*]utilization of high - level features[*R*]can reduce[*A*]the dimensionality of feature space	context()	negated: False ,passive: False
[LINE#37] At last, our classification model is more interpretable, because our model involves fewer features consisting of continuous regions instead of scattered voxels.
0.903	[*A*]fewer features[*R*]consisting[*A*]of scattered voxels	context()	negated: False ,passive: True
0.638	[*A*]our model[*R*]involves[*A*]fewer features consisting of scattered voxels	context()	negated: False ,passive: True
0.903	[*A*]fewer features[*R*]consisting[*A*]of continuous regions	context()	negated: False ,passive: True
0.638	[*A*]our model[*R*]involves[*A*]fewer features consisting of continuous regions	context()	negated: False ,passive: True
0.714	[*A*]our classification model[*R*]is[*A*]more interpretable[*A*]because our model involves fewer features[*A*]At last	context()	negated: False ,passive: True
[LINE#38] These features can then be related more easily to disease etiology, diagnosis and prognosis.
0.916	[*A*]These features[*R*]can be related more easily[*A*]to disease prognosis[*A*]then	context()	negated: False ,passive: True
0.916	[*A*]These features[*R*]can be related more easily[*A*]to disease diagnosis[*A*]then	context()	negated: False ,passive: True
0.916	[*A*]These features[*R*]can be related more easily[*A*]to disease etiology[*A*]then	context()	negated: False ,passive: True
[LINE#39] Another innovation of our approach is that we employed a bag-of-words strategy to analyze the functional contrast maps.
0.397	[*A*]we[*R*]employed a bag-of-words strategy to analyze[*A*]the functional contrast maps	context(Another innovation of our approach is we employed)	negated: False ,passive: False
0.397	[*A*]we[*R*]employed[*A*]a bag-of-words strategy	context(Another innovation of our approach is)	negated: False ,passive: False
0.443	[*A*]Another innovation of our approach[*R*]is[*A*]that we employed a bag-of-words strategy to analyze the functional contrast maps	context()	negated: False ,passive: True
[LINE#40] This technique can characterize the activation pattern for every individual in spite of the great variability in the activation pattern among individuals.
0.937	[*A*]This technique[*R*]can characterize[*A*]the activation pattern for every individual[*A*]in spite of the great variability in the activation pattern among individuals	context()	negated: False ,passive: False
[LINE#41] Considering the relatively small sample size, we constructed our feature pool with all available samples, including the one used for testing during the cross-validation.
0.903	[*A*]the one[*R*]used[*A*]for testing[*A*]during the cross-validation	context()	negated: False ,passive: True
0.418	[*A*]we[*R*]constructed[*A*]our feature pool with all available samples, including the one	context()	negated: False ,passive: False
[LINE#42] We implemented a variant version of our algorithm, in which we extracted ROIs based only on the training samples, and subsequently applied those ROIs to the testing sample directly.
0.306	[*A*]we[*R*]applied directly[*A*]a variant version of our algorithm[*A*]subsequently	context()	negated: False ,passive: False
0.240	[*A*]We[*R*]implemented[*A*]a variant version of our algorithm , in which we subsequently applied those ROIs to the testing sample directly	context()	negated: False ,passive: False
0.920	[*A*]ROIs[*R*]based[*A*]only on the training samples	context()	negated: False ,passive: True
0.490	[*A*]we[*R*]extracted[*A*]ROIs[*A*]a variant version of our algorithm	context()	negated: False ,passive: False
0.463	[*A*]We[*R*]implemented[*A*]a variant version of our algorithm , in which we extracted ROIs	context()	negated: False ,passive: False
[LINE#43] As expected, the variant algorithm performed slightly worse (AUC=0.81) than our original algorithm (AUC=0.83).
0.751	[*A*]the variant algorithm[*R*]performed slightly worse	context()	negated: False ,passive: False
[LINE#44] Adding the ROIs from new samples requires us to retrain the classifier every time when new samples are available.
0.943	[*A*]new samples[*R*]are[*A*]available[*A*]every time	context()	negated: False ,passive: True
0.452	[*A*]us[*R*]to retrain[*A*]the classifier[*A*]every time when new samples are available	context()	negated: False ,passive: False
0.910	[*A*]Adding the ROIs from new samples[*R*]requires[*A*]us[*A*]to retrain the classifier every time	context()	negated: False ,passive: False
[LINE#45] As the feature pool becomes larger in the future, the retraining is not necessary.
0.767	[*A*]the retraining[*R*]is not[*A*]necessary	context()	negated: True ,passive: True
0.911	[*A*]the feature pool[*R*]becomes[*A*]larger in the future	context()	negated: False ,passive: True
[LINE#46+47+48]  Integration of different types of data , e.g. data from multiple modalities, has been demonstrated to be more powerful for classification(Fan et al., 2007, 2008; Tosun et al., 2010; Wang et al., 2012).
0.933	[*A*]Integration of different types of data[*R*]to be[*A*]more powerful for classification[*A*]Fan et al., 2007, 2008	context()	negated: False ,passive: True
[LINE#49] However, how to implement such integrations in the best way remains to be explored (Orru et al., 2012).
0.866	[*A*]how to implement such integrations in the best way[*R*]remains[*A*]to be explored	context()	negated: False ,passive: True
[LINE#50+51]  Traditionally, features from different types of data are concatenated and a single classifier is trained(Fan et al., 2007, 2008; Tosun et al., 2010; Wang et al., 2012).
0.751	[*A*]a single classifier[*R*]is trained	context()	negated: False ,passive: False
0.801	[*A*]features from different types of data[*R*]are concatenated	context()	negated: False ,passive: False
[LINE#52] Specifically, the traditional integration method requires the training set to be organized into matrices, with each row representing a training sample and each column representing a feature.
0.903	[*A*]each column[*R*]representing[*A*]a feature	context()	negated: False ,passive: False
0.948	[*A*]the traditional integration method[*R*]requires[*A*]the training set to be organized into matrices , with each column	context()	negated: False ,passive: False
0.903	[*A*]each row[*R*]representing[*A*]a training sample	context()	negated: False ,passive: False
0.887	[*A*]the training[*R*]to be organized[*A*]into matrices	context()	negated: False ,passive: True
0.925	[*A*]the training[*R*]set[*A*]to be organized into matrices	context()	negated: False ,passive: True
0.948	[*A*]the traditional integration method[*R*]requires[*A*]the training set to be organized into matrices , with each row	context()	negated: False ,passive: False
[LINE#53] One matrix is constructed for one type of data, and subsequently all the matrices are concatenated into one big matrix, which serves as the input for classifier training.
0.897	[*A*]one big matrix[*R*]serves[*A*]as the input for classifier training	context()	negated: False ,passive: False
0.948	[*A*]all the matrices[*R*]are concatenated[*A*]into one big matrix[*A*]subsequently	context()	negated: False ,passive: True
0.903	[*A*]One matrix[*R*]is constructed[*A*]for one type of data	context()	negated: False ,passive: True
[LINE#54] In our project, the fMRI data can be easily organized in this way.
0.918	[*A*]the fMRI data[*R*]can be easily organized[*A*]In our project	context()	negated: False ,passive: True
[LINE#55] For sMRI, however, each training sample has a set of SIFT features, which can be treated as a set of words included in an article.
0.813	[*A*]words[*R*]included[*A*]in an article	context()	negated: False ,passive: True
0.914	[*A*]SIFT features[*R*]can be treated[*A*]as a set of words	context()	negated: False ,passive: True
0.942	[*A*]each training sample[*R*]has[*A*]a set of SIFT features	context()	negated: False ,passive: False
[LINE#56] Different articles have different sets of words.
0.903	[*A*]Different articles[*R*]have[*A*]different sets of words	context()	negated: False ,passive: False
[LINE#57] Thus, it is not easy to organize the sMRI data into a matrix as described above, and the traditional integration method is not applicable.
0.799	[*A*]the traditional integration method[*R*]is not[*A*]applicable	context()	negated: True ,passive: True
[LINE#58] Under such circumstances, we proposed a two-layer model to integrate the sMRI and fMRI data.
0.740	[*A*]we[*R*]proposed[*A*]a two - layer model to integrate the fMRI data[*A*]Under such circumstances	context()	negated: False ,passive: False
0.740	[*A*]we[*R*]proposed[*A*]a two - layer model to integrate the sMRI data[*A*]Under such circumstances	context()	negated: False ,passive: False
[LINE#59] Since the traditional approach was not applicable in our project, we did not compare their performances in the present paper.
0.309	[*A*]we[*R*]did not compare[*A*]their performances in the present paper	context()	negated: True ,passive: False
0.848	[*A*]the traditional approach[*R*]was not[*A*]applicable in our project	context()	negated: True ,passive: True
[LINE#60] Additionally, our two-layer model is also applicable when features from different modalities can be concatenated.
0.769	[*A*]features from different modalities[*R*]can be concatenated	context()	negated: False ,passive: False
0.758	[*A*]our two-layer model[*R*]is[*A*]also[*A*]applicable[*A*]when features from different modalities can be concatenated	context()	negated: False ,passive: True
[LINE#61] In this case, one classifier is trained for one modality, and a second-layer classifier is subsequently used to integrate the multiple classifiers on the first-layer.
0.913	[*A*]a second - layer classifier[*R*]to integrate[*A*]the multiple classifiers on the first - layer	context()	negated: False ,passive: False
0.959	[*A*]a second - layer classifier[*R*]is used[*A*]to integrate the multiple classifiers on the first - layer[*A*]subsequently	context()	negated: False ,passive: True
0.702	[*A*]one classifier[*R*]is trained[*A*]for one modality[*A*]In this case	context()	negated: False ,passive: True
[LINE#62] This approach is able to combine as many types of data as possible, without worrying about the high dimensionality or overfitting.
0.887	[*A*]This approach[*R*]to combine[*A*]as many types of data as possible	context()	negated: False ,passive: False
0.952	[*A*]This approach[*R*]is[*A*]able to combine as many types of data as possible, without worrying about the high dimensionality or overfitting	context()	negated: False ,passive: True
[LINE#63] Although computer-aided diagnosis of hearing loss is not needed, our algorithm can potentially advance the study of congenital hearing loss mechanism by identifying discriminative brain regions as disease biomarkers for hearing impairment at various levels in the auditory system.
0.535	[*A*]our algorithm[*R*]can advance[*A*]the study of congenital hearing loss mechanism	context()	negated: False ,passive: False
0.816	[*A*]computer-aided diagnosis of hearing loss[*R*]is not needed	context()	negated: True ,passive: False
[LINE#64] Inspecting the most important features that differentiate children born with hearing impairment from children with normal hearing in this study, we see some features that are in line with hypotheses about under stimulation of auditory function in HI infants; while other observations already begin to add to our knowledge of how congenital deafness affects brain development and function.
0.903	[*A*]congenital deafness[*R*]affects[*A*]brain function	context()	negated: False ,passive: False
0.903	[*A*]congenital deafness[*R*]affects[*A*]brain development	context()	negated: False ,passive: False
0.877	[*A*]children[*R*]with hearing[*A*]impairment[*A*]from children with normal hearing in this study	context()	negated: False ,passive: False
0.698	[*A*]other observations[*R*]to add	context()	negated: False ,passive: False
0.767	[*A*]children[*R*]born	context()	negated: False ,passive: False
0.309	[*A*]we[*R*]see[*A*]some features that are in line with hypotheses about under stimulation of auditory function in HI infants	context(other observations begin)	negated: False ,passive: False
0.792	[*A*]other observations[*R*]begin[*A*]already	context()	negated: False ,passive: True
0.939	[*A*]the most important features[*R*]differentiate[*A*]children born with hearing impairment from children with normal hearing in this study	context()	negated: False ,passive: False
0.887	[*A*]some features[*R*]are[*A*]in line with hypotheses	context()	negated: False ,passive: True
[LINE#65] For example, features B, F, H, and I include known components of the auditory language network which our group and others have previously shown to be engaged by the narrative comprehension task (Karunanayaka et al., 2007; Schmithorst et al., 2006).
0.927	[*A*]known components of the auditory language network[*R*]to be engaged[*A*]by the narrative comprehension task	context()	negated: False ,passive: True
0.418	[*A*]I[*R*]include[*A*]known components of the auditory language network which our group have previously shown to be engaged by the narrative comprehension task	context()	negated: False ,passive: True
[LINE#66+67]  These features include (B) the planum temporale and primary auditory cortex in the left hemisphere (including Wernicke's area, the classical language recognition module), as well as the angular gyrus and supramarginal gyrus at the temporal parietal junction of the (F) left and (H, I)right hemispheres, known auditory and visual language association regions.
0.913	[*A*]right hemispheres[*R*]known[*A*]visual language association regions	context()	negated: False ,passive: False
0.732	[*A*]These features[*R*]include	context()	negated: False ,passive: False
0.903	[*A*]These features[*R*]include[*A*]B	context()	negated: False ,passive: True
[LINE#68]  Although all participants were bilaterally severely to profoundly hearing impaired, we observe left dominant auditory/language related activity present in components A, B, and.
0.157	[*A*]we[*R*]observe left left	context(we observe)	negated: False ,passive: False
0.183	[*A*]we[*R*]observe[*A*]left	context()	negated: False ,passive: False
0.767	[*A*]all participants[*R*]were[*A*]bilaterally severely	context()	negated: False ,passive: True
[LINE#69] F. In addition, components H and I contain right hemisphere auditory/language activity.
0.452	[*A*]I[*R*]contain[*A*]right hemisphere auditory / language activity	context()	negated: False ,passive: False
0.903	[*A*]components H[*R*]contain[*A*]right hemisphere auditory / language activity	context()	negated: False ,passive: False
[LINE#70] Functional features such as these are not unexpected in terms of regions of differential cortical activation between HI and NH children listening to natural language as an auditory stimulus and it is reassuring to see these regions highlighted by our algorithm as potential biomarkers corresponding to hearing impairment.
0.939	[*A*]HI and NH children[*R*]listening[*A*]to natural language	context()	negated: False ,passive: False
0.903	[*A*]potential biomarkers[*R*]corresponding[*A*]to hearing impairment	context()	negated: False ,passive: True
0.835	[*A*]these regions[*R*]highlighted[*A*]by our algorithm[*A*]as potential biomarkers	context()	negated: False ,passive: True
0.926	[*A*]Functional features such as these[*R*]are not[*A*]unexpected[*A*]in terms of regions of differential	context()	negated: True ,passive: True
[LINE#71] Similarly, there is evidence of differential activation in subcortical features corresponding to the auditory brainstem pathways.
0.903	[*A*]subcortical features[*R*]corresponding[*A*]to the auditory brainstem pathways	context()	negated: False ,passive: True
[LINE#72] J include elements of the reticular auditory pathway of the brainstem which has been identified by electrophysiological studies to have a key role in auditory perception of location of sounds as well as the ability to filter a source of sound in background noise.
0.887	[*A*]the brainstem[*R*]to have[*A*]a key role in auditory perception of the ability	context()	negated: False ,passive: False
0.927	[*A*]the brainstem[*R*]has been identified[*A*]by electrophysiological studies[*A*]to have a key role in auditory perception of the ability	context()	negated: False ,passive: True
0.887	[*A*]the brainstem[*R*]has been identified[*A*]by electrophysiological studies	context()	negated: False ,passive: True
0.855	[*A*]J[*R*]include[*A*]elements of the reticular auditory pathway of the brainstem	context()	negated: False ,passive: True
[LINE#73] Roughly these features appear to encompass key elements of the auditory pathway at the level of the pons (D) including the cochlear nucleus, trapezoid body, lateral lemniscus and superior olive on the right, (A) inferior colliculus, medial geniculate on the left and (J) thalamus bilaterally (Kretschmann and Weinrich, 1998).
0.938	[*A*]these features[*R*]to encompass[*A*]key elements of the auditory pathway at the level of the pons ( D ) including Kretschmann and Weinrich , 1998	context()	negated: False ,passive: False
0.927	[*A*]these features[*R*]to encompass[*A*]key elements of the auditory pathway at the level of the pons	context()	negated: False ,passive: False
0.938	[*A*]these features[*R*]to encompass[*A*]key elements of the auditory pathway at the level of the pons ( D ) including ( A ) inferior colliculus Kretschmann and Weinrich , 1998	context()	negated: False ,passive: False
0.938	[*A*]these features[*R*]to encompass[*A*]key elements of the auditory pathway at the level of the pons ( D ) including superior olive Kretschmann and Weinrich , 1998	context()	negated: False ,passive: False
0.938	[*A*]these features[*R*]to encompass[*A*]key elements of the auditory pathway at the level of the pons ( D ) including lateral lemniscus Kretschmann and Weinrich , 1998	context()	negated: False ,passive: False
0.938	[*A*]these features[*R*]to encompass[*A*]key elements of the auditory pathway at the level of the pons ( D ) including trapezoid body Kretschmann and Weinrich , 1998	context()	negated: False ,passive: False
0.927	[*A*]these features[*R*]to encompass[*A*]key elements of the auditory pathway at the level of the pons ( D ) including the cochlear nucleus	context()	negated: False ,passive: False
0.938	[*A*]these features[*R*]to encompass[*A*]key elements of the auditory pathway[*A*]at the level of the pons ( D ) including and Weinrich , 1998	context()	negated: False ,passive: False
0.938	[*A*]these features[*R*]to encompass[*A*]key elements of the auditory pathway at the level of the pons ( D ) including the left and Weinrich , 1998	context()	negated: False ,passive: False
0.938	[*A*]these features[*R*]to encompass[*A*]key elements of the auditory pathway at the level of the pons ( D ) including ( A ) inferior colliculus and Weinrich , 1998	context()	negated: False ,passive: False
0.938	[*A*]these features[*R*]to encompass[*A*]key elements of the auditory pathway at the level of the pons ( D ) including superior olive and Weinrich , 1998	context()	negated: False ,passive: False
0.938	[*A*]these features[*R*]to encompass[*A*]key elements of the auditory pathway at the level of the pons ( D ) including lateral lemniscus and Weinrich , 1998	context()	negated: False ,passive: False
0.938	[*A*]these features[*R*]to encompass[*A*]key elements of the auditory pathway at the level of the pons ( D ) including trapezoid body and Weinrich , 1998	context()	negated: False ,passive: False
0.938	[*A*]these features[*R*]to encompass[*A*]key elements of the auditory pathway at the level of the pons ( D ) including the cochlear nucleus and Weinrich , 1998	context()	negated: False ,passive: False
0.732	[*A*]these features[*R*]appear	context()	negated: False ,passive: False
[LINE#74] Although the resolution of the fMRI scans (445mm) is not sufficient to resolve these structures individually, differences in activation in these regions, as indicated by reference to the higher resolution anatomical images, suggest that brain stem auditory nuclei may be involved.
0.678	[*A*]auditory nuclei[*R*]may be involved	context(anatomical images suggest brain stem)	negated: False ,passive: False
0.896	[*A*]brain[*R*]stem[*A*]auditory nuclei may be involved	context(anatomical images suggest)	negated: False ,passive: True
0.689	[*A*]anatomical images[*R*]suggest[*A*]that brain stem auditory nuclei may be involved	context()	negated: False ,passive: False
0.939	[*A*]the resolution of the fMRI scans[*R*]to resolve individually[*A*]these structures	context()	negated: False ,passive: False
0.940	[*A*]the resolution of the fMRI scans[*R*]is not[*A*]sufficient to resolve these structures individually	context()	negated: True ,passive: True
[LINE#75] One feature that is conspicuously absent from those illustrated in Fig. 7 is the primary auditory cortex (BA41).
0.949	[*A*]One feature that is conspicuously absent from those[*R*]is[*A*]the primary auditory cortex	context()	negated: False ,passive: True
0.269	[*A*]those[*R*]illustrated[*A*]in Fig	context()	negated: False ,passive: True
0.574	[*A*]One feature[*R*]is[*A*]conspicuously absent from those	context()	negated: False ,passive: True
[LINE#76] We expected that this region would be important in differentiating HI from NH participants and hoped that it could potentially become a biomarker for predicting outcome for hearing and language following cochlear implantation in HI infants as suggested by our earlier work (Patel et al., 2007).
0.311	[*A*]it[*R*]could become[*A*]a biomarker for predicting outcome for language following cochlear implantation in HI infants as suggested by our earlier work ( Patel et al . , 2007	context(We hoped)	negated: False ,passive: True
0.202	[*A*]We[*R*]hoped[*A*]that it could potentially become a biomarker for predicting outcome for language following cochlear implantation in HI infants as suggested by our earlier work ( Patel et al . , 2007	context()	negated: False ,passive: False
0.454	[*A*]it[*R*]could become[*A*]a biomarker for predicting outcome for hearing following cochlear implantation in HI infants	context(We hoped)	negated: False ,passive: True
0.202	[*A*]We[*R*]hoped[*A*]that it could potentially become a biomarker for predicting outcome for hearing following cochlear implantation in HI infants	context()	negated: False ,passive: False
0.900	[*A*]this region[*R*]would be[*A*]important in differentiating HI from NH participants	context(We expected)	negated: False ,passive: True
0.317	[*A*]We[*R*]expected[*A*]that this region would be important in differentiating HI from NH participants	context()	negated: False ,passive: False
[LINE#77] The sedation used in the present study is a likely confounding to primary auditory function and may be partly responsible for the absence of a functional MRI feature in primary auditory cortex that differentiates the groups (DiFrancesco et al., in press).
0.897	[*A*]primary auditory cortex[*R*]differentiates[*A*]the groups	context()	negated: False ,passive: False
0.975	[*A*]The sedation used in the present study[*R*]is[*A*]a likely confounding to primary auditory function DiFrancesco et al	context()	negated: False ,passive: True
0.903	[*A*]The sedation[*R*]used[*A*]in the present study	context()	negated: False ,passive: True
[LINE#78] However, because Fig. 7 highlights differences between the groups that optimally separate them, it is possible that brain regions beyond primary auditory cortex that are responsible for recognizing sounds as speech and for extracting and associating content are more differentially stimulated in a scenario where the hearing impaired brain receives a rare auditory input that is above the threshold it can detect.
0.949	[*A*]brain regions beyond primary auditory cortex[*R*]are[*A*]responsible for recognizing sounds as speech and for associating content	context()	negated: False ,passive: True
0.974	[*A*]brain regions beyond primary auditory cortex that are responsible for recognizing sounds as speech and for associating content[*R*]more differentially stimulated[*A*]in a scenario	context()	negated: False ,passive: True
0.881	[*A*]the hearing impaired brain[*R*]receives[*A*]a rare auditory input that is above the threshold[*A*]a scenario	context()	negated: False ,passive: False
0.927	[*A*]a rare auditory input[*R*]is[*A*]above the threshold	context()	negated: False ,passive: True
0.921	[*A*]brain regions beyond primary auditory cortex[*R*]are[*A*]responsible for recognizing sounds as speech and for extracting	context()	negated: False ,passive: True
0.884	[*A*]the threshold[*R*]can detect[*A*]it	context()	negated: False ,passive: True
0.933	[*A*]the hearing[*R*]impaired[*A*]a scenario	context()	negated: False ,passive: True
0.810	[*A*]the groups[*R*]optimally separate[*A*]them	context()	negated: False ,passive: False
0.833	[*A*]Fig[*R*]highlights[*A*]differences between the groups	context()	negated: False ,passive: False
[LINE#79] Vibrations, loud noise and other stimuli may occasionally stimulate the auditory cortex in a deaf infant so that it is capable of processing sound and responds during our experiment in the same manner as the NH children who are receiving sound stimulation at the same relative SPL.
0.775	[*A*]other stimuli[*R*]may stimulate[*A*]the auditory cortex[*A*]so that it responds during our experiment in the same manner[*A*]occasionally	context()	negated: False ,passive: False
0.683	[*A*]other stimuli[*R*]may stimulate[*A*]the auditory cortex[*A*]so that it is capable of processing sound[*A*]occasionally	context()	negated: False ,passive: False
0.775	[*A*]loud noise[*R*]may stimulate[*A*]the auditory cortex[*A*]so that it responds during our experiment in the same manner[*A*]occasionally	context()	negated: False ,passive: False
0.683	[*A*]loud noise[*R*]may stimulate[*A*]the auditory cortex[*A*]so that it is capable of processing sound[*A*]occasionally	context()	negated: False ,passive: False
0.934	[*A*]the NH children[*R*]are receiving[*A*]sound stimulation[*A*]at the same relative SPL	context()	negated: False ,passive: False
0.309	[*A*]it[*R*]responds[*A*]during our experiment in the same manner	context()	negated: False ,passive: False
0.758	[*A*]Vibrations[*R*]may stimulate[*A*]the auditory cortex[*A*]so that it responds during our experiment in the same manner[*A*]occasionally	context()	negated: False ,passive: False
0.522	[*A*]it[*R*]is[*A*]capable of processing sound	context()	negated: False ,passive: True
0.662	[*A*]Vibrations[*R*]may stimulate[*A*]the auditory cortex[*A*]so that it is capable of processing sound[*A*]occasionally	context()	negated: False ,passive: False
[LINE#80] However, unless the HI infant is participating in a successful hearing aid trial, it is much less likely that they are routinely subjected to an auditory stream of speech that is consistently above their hearing threshold and hence unintelligible.
0.770	[*A*]speech[*R*]is[*A*]consistently[*A*]hence unintelligible	context()	negated: False ,passive: True
0.837	[*A*]speech[*R*]is[*A*]consistently[*A*]above their hearing threshold	context()	negated: False ,passive: True
0.616	[*A*]they[*R*]are routinely subjected[*A*]to an auditory stream of speech	context()	negated: False ,passive: True
0.278	[*A*]it[*R*]is[*A*]much less likely	context()	negated: False ,passive: True
0.933	[*A*]the HI infant[*R*]is participating[*A*]in a successful hearing aid trial	context()	negated: False ,passive: False
[LINE#81] HI infants in this study were all severe to profoundly hearing-impaired and ultimately received a cochlear implant because they did not derive sufficient benefit from an external hearing aid.
0.616	[*A*]they[*R*]did not derive[*A*]sufficient benefit[*A*]from an external hearing aid	context()	negated: True ,passive: False
0.957	[*A*]HI infants in this study[*R*]received[*A*]a cochlear implant[*A*]because they did not derive sufficient benefit from an external hearing aid[*A*]ultimately	context()	negated: False ,passive: False
0.856	[*A*]HI infants in this study[*R*]were[*A*]all severe	context()	negated: False ,passive: True
0.934	[*A*]HI infants in this study[*R*]were[*A*]severe to profoundly hearing - impaired	context()	negated: False ,passive: True
[LINE#82+83+84]  Though this explanation is speculative, it could explain why features B, C, E, F, G, H, and I seem to be more important in separating the HI and NH groups of infants based on brain activation during fMRI.On the other hand, our analysis on the fMRI data in this study also identified a number of areas that are not necessarily expected to play a role in differentiating HI from NH children.
0.953	[*A*]the NH groups of infants[*R*]based[*A*]on brain activation[*A*]during fMRI.On the other hand	context()	negated: False ,passive: True
0.456	[*A*]I[*R*]to be[*A*]more important in separating the NH groups of infants	context()	negated: False ,passive: True
0.799	[*A*]our analysis on the fMRI data in this study[*R*]identified[*A*]a number of areas	context()	negated: False ,passive: False
0.953	[*A*]the HI groups of infants[*R*]based[*A*]on brain activation[*A*]during fMRI.On the other hand	context()	negated: False ,passive: True
0.456	[*A*]I[*R*]to be[*A*]more important in separating the HI groups of infants	context()	negated: False ,passive: True
0.195	[*A*]I[*R*]seem	context()	negated: False ,passive: False
0.896	[*A*]areas[*R*]to play[*A*]a role in differentiating HI from NH children	context()	negated: False ,passive: False
0.900	[*A*]areas[*R*]are not expected[*A*]to play a role in differentiating HI from NH children	context()	negated: False ,passive: True
0.847	[*A*]features B , C , E , F , G , H , our analysis on the fMRI data in this study[*R*]identified[*A*]a number of areas	context(it could explain)	negated: False ,passive: False
0.399	[*A*]it[*R*]could explain[*A*]why features B , C , E , F , G , H , our analysis on the fMRI data in this study also identified a number of areas	context()	negated: False ,passive: False
0.813	[*A*]this explanation[*R*]is[*A*]speculative	context()	negated: False ,passive: True
[LINE#85]  In particular, several functional features also appear in various portions of the anterior cingulate cortex (ACC, BA 24,32,33): areas associated with attention management, conflict monitoring, and error detection.
0.894	[*A*]areas[*R*]associated[*A*]with error detection	context()	negated: False ,passive: True
0.894	[*A*]areas[*R*]associated[*A*]with conflict monitoring	context()	negated: False ,passive: True
0.894	[*A*]areas[*R*]associated[*A*]with attention management	context()	negated: False ,passive: True
0.897	[*A*]several functional features[*R*]appear[*A*]in various portions of the anterior cingulate cortex	context()	negated: False ,passive: True
[LINE#86] These features may be related to responses in the HI group to the novel auditory stimulus.
0.947	[*A*]These features[*R*]may be related[*A*]to responses in the HI group to the novel auditory stimulus	context()	negated: False ,passive: True
[LINE#87] ACC features are present in all three contrasts (C2, E1, E2, and G), suggesting a difference in response to sound input in the HI group who do not typically receive an auditory input at a level above their auditory threshold.
0.961	[*A*]ACC features[*R*]are[*A*]present in all three contrasts[*A*]suggesting a difference in response to sound input in the HI group	context()	negated: False ,passive: True
[LINE#88] Important features are also present in secondary visual cortex (H) (BA18), associative visual cortex (BA19) and other subcortical regions; differentiating the two groups.
0.897	[*A*]other subcortical regions[*R*]differentiating[*A*]the two groups	context()	negated: False ,passive: False
0.903	[*A*]Important features[*R*]are[*A*]also[*A*]present in secondary visual cortex ( H	context()	negated: False ,passive: True
0.897	[*A*]associative visual cortex[*R*]differentiating[*A*]the two groups	context()	negated: False ,passive: False
0.903	[*A*]Important features[*R*]are[*A*]also[*A*]present in secondary visual cortex	context()	negated: False ,passive: True
[LINE#89] These features provide clues about additional neuroimaging biomarkers that may be relevant to the future use of functional neuroimaging to guide predictions about speech and language outcomes in HI infants who receive a cochlear implant.
0.934	[*A*]language outcomes in HI infants[*R*]receive[*A*]a cochlear implant	context()	negated: False ,passive: False
0.934	[*A*]speech outcomes in HI infants[*R*]receive[*A*]a cochlear implant	context()	negated: False ,passive: False
0.897	[*A*]additional neuroimaging biomarkers[*R*]may be[*A*]relevant to the future use of functional neuroimaging	context()	negated: False ,passive: True
0.903	[*A*]These features[*R*]provide[*A*]clues about additional neuroimaging biomarkers	context()	negated: False ,passive: False
[LINE#90] This type of prognostic information, currently not available, is obviously of great significance.
0.933	[*A*]This type of prognostic information[*R*]is[*A*]obviously[*A*]of great significance	context()	negated: False ,passive: True
[LINE#91] For example, it helps to calibrate the expectations and avoid subsequent disappointment, save money of the family and avoid anesthetic risks when it is clear that a child will derive no benefit from the procedure.
0.168	[*A*]it[*R*]helps to avoid[*A*]anesthetic risks[*A*]when it is clear that a child will derive no benefit from the procedure	context(it helps)	negated: False ,passive: False
0.211	[*A*]it[*R*]helps[*A*]to avoid anesthetic risks when it is clear that a child will derive no benefit from the procedure	context()	negated: False ,passive: False
0.388	[*A*]it[*R*]helps to save[*A*]money of the family	context(it helps)	negated: False ,passive: False
0.457	[*A*]it[*R*]helps[*A*]to save money of the family	context()	negated: False ,passive: False
0.388	[*A*]it[*R*]helps to avoid[*A*]subsequent disappointment	context(it helps)	negated: False ,passive: False
0.457	[*A*]it[*R*]helps[*A*]to avoid subsequent disappointment	context()	negated: False ,passive: False
0.388	[*A*]it[*R*]helps to calibrate[*A*]the expectations	context(it helps)	negated: False ,passive: False
0.457	[*A*]it[*R*]helps[*A*]to calibrate the expectations	context()	negated: False ,passive: False
[LINE#92+93]  In the present study, all infants were sedated for a clinical MRI scan andthe fMRI task was appended to the end of the protocol.
0.887	[*A*]all infants[*R*]was appended[*A*]to the end of the protocol	context()	negated: False ,passive: True
0.926	[*A*]all infants[*R*]scan[*A*]andthe fMRI task	context()	negated: False ,passive: False
0.952	[*A*]all infants[*R*]were sedated[*A*]for a clinical MRI[*A*]In the present study	context()	negated: False ,passive: True
[LINE#94] Further, there were different agents used for the sedation in the population we sampled, including propofol, Nembutal and sevoflurane.
0.890	[*A*]different agents[*R*]used[*A*]for the sedation in the population we sampled , including sevoflurane	context()	negated: False ,passive: True
0.907	[*A*]different agents[*R*]used[*A*]for the sedation in the population we sampled , including Nembutal	context()	negated: False ,passive: True
0.884	[*A*]the population[*R*]sampled[*A*]we	context()	negated: False ,passive: True
0.890	[*A*]different agents[*R*]used[*A*]for the sedation in the population we sampled , including propofol	context()	negated: False ,passive: True
[LINE#95] These drugs may have a different influence on the BOLD signal we detected.
0.919	[*A*]the BOLD signal[*R*]detected[*A*]we	context()	negated: False ,passive: True
0.918	[*A*]These drugs[*R*]may have[*A*]a different influence on the BOLD signal	context()	negated: False ,passive: False
[LINE#96+97]  Note that the influence of sedation is to attenuate the auditory and language related brain activity and corresponding BOLD signal relative to what would be detected in awake or even sleeping babies(Difrancesco et al., 2011; DiFrancesco et al., 2013, in press; Wilke et al., 2003).
[LINE#98] Therefore, the current approach for automatic classification of NH vs. HI would likely be more effective in a scenario where fMRI data could be recorded from the participants without the influence of sedation.
0.949	[*A*]fMRI data[*R*]could be recorded[*A*]a scenario	context()	negated: False ,passive: True
0.947	[*A*]the current approach for automatic classification of NH vs. HI[*R*]would be[*A*]more effective in a scenario	context()	negated: False ,passive: True
[LINE#99] Demonstrating that our approach can accurately classify infants by hearing status even under the confounding influence of sedation encourages optimism for other applications where confounding disease-related conditions may modify the BOLD signal, such as cerebrovascular diseases.
0.943	[*A*]where confounding disease-related conditions[*R*]may modify[*A*]the BOLD signal	context()	negated: False ,passive: False
[LINE#100] In the future, we will try image segmentation algorithms to define ROIs instead of thresholding the contrast maps.
0.433	[*A*]we[*R*]will try image segmentation algorithms to define[*A*]ROIs	context(we will try)	negated: False ,passive: False
0.577	[*A*]we[*R*]will try[*A*]image segmentation algorithms[*A*]to define ROIs instead of thresholding the contrast maps[*A*]In the future	context()	negated: False ,passive: False
[LINE#101] Other evidence, such as tissue density maps and functional connectivity networks, may be integrated into our model.
0.903	[*A*]Other evidence , such as tissue density functional connectivity networks[*R*]may be integrated[*A*]into our model	context()	negated: False ,passive: True
0.884	[*A*]Other evidence , such as tissue density maps[*R*]may be integrated[*A*]into our model	context()	negated: False ,passive: True
[LINE#102] For example, we can train a classifier based on the tissue density maps and then integrate it into our model with the second-layer classifier.
0.343	[*A*]we[*R*]can integrate[*A*]it[*A*]into our model with the second - layer classifier[*A*]then	context()	negated: False ,passive: False
0.903	[*A*]a classifier[*R*]based[*A*]on the tissue density maps	context()	negated: False ,passive: True
0.452	[*A*]we[*R*]can train[*A*]a classifier based on the tissue density maps	context()	negated: False ,passive: False
[LINE#103] Beyond the MRI data, our model will also permit integration from electrophysiologic imaging modalities such as evoked response potentials (ERP), electroencephalography (EEG), or magnetoencephalography (MEG).
0.535	[*A*]our model[*R*]will permit[*A*]integration	context()	negated: False ,passive: False
[LINE#104] These brain scanning techniques directly record brain activities; however they are limited in their spatial resolution by the algorithms that are used to localize sources of brain activity based on recordings at the surface of the skull.
0.897	[*A*]These brain scanning techniques[*R*]directly record[*A*]brain activities	context(they are limited)	negated: False ,passive: False
0.401	[*A*]they[*R*]are limited[*A*]in their spatial resolution by the algorithms	context()	negated: False ,passive: True
0.903	[*A*]brain activity[*R*]based[*A*]on recordings[*A*]at the surface of the skull	context()	negated: False ,passive: True
0.887	[*A*]the algorithms[*R*]are used[*A*]to localize sources of brain activity	context()	negated: False ,passive: True
0.894	[*A*]brain[*R*]scanning[*A*]techniques	context()	negated: False ,passive: False
[LINE#105] Combining MR imaging features with electrophysiologic features recorded directly from brain responses to auditory input could leverage the benefits of each imaging modality to produce much more accurate predictions about patient outcomes.
0.932	[*A*]the benefits of each imaging modality[*R*]to produce[*A*]much more accurate predictions about patient outcomes	context()	negated: False ,passive: False
0.903	[*A*]electrophysiologic features[*R*]recorded directly[*A*]from brain responses to auditory input	context()	negated: False ,passive: True
[LINE#106] Due to the inherent properties of our two-layer model, integration of other evidences can be easily implemented.
[LINE#107] With the improved classifier, the method is likely to have applications to many other diseases.
0.887	[*A*]the method[*R*]to have[*A*]applications to many other diseases	context()	negated: False ,passive: False
0.925	[*A*]the method[*R*]is[*A*]likely to have applications to many other diseases	context()	negated: False ,passive: True
[LINE#108+109]  It has been estimated that approximately 1 to 6 infants per 1000 are born with severe to profound congenital sensori-neural hearing loss (SNHL)(Bachmann and Arvedson, 1998; Cunningham and Cox, 2003; Kemper and Downs, 2000; Northern, 1994).
[LINE#110] Those children receive little or no benefit from hearing aids and face challenges in developing language abilities due to their inability to detect acoustic-phonetic signals, which are essential for hearing-dependent learning.
0.905	[*A*]acoustic-phonetic signals[*R*]are[*A*]essential for hearing-dependent learning	context()	negated: False ,passive: True
0.890	[*A*]Those children[*R*]receive[*A*]little or no benefit[*A*]from hearing aids and face challenges in developing language abilities due to their inability	context()	negated: False ,passive: False
[LINE#111] Cochlear implantation (CI) is a surgical procedure that inserts an electronic device into the cochlea for direct stimulation of the auditory nerve and has been demonstrated to be effective in restoring hearing in patients suffering from SNHL.
0.911	[*A*]patients[*R*]suffering[*A*]from SNHL	context()	negated: False ,passive: False
0.934	[*A*]Cochlear implantation[*R*]is[*A*]a surgical procedure	context()	negated: False ,passive: True
0.933	[*A*]a surgical procedure[*R*]inserts[*A*]an electronic device[*A*]into the cochlea for direct stimulation of the auditory nerve	context()	negated: False ,passive: False
0.892	[*A*]Cochlear implantation[*R*]is[*A*]a surgical procedure that inserts an electronic device into the cochlea for direct stimulation of the auditory nerve	context()	negated: False ,passive: True
[LINE#112+113]  Statistical data from the National Institute on Deafness and Other Communication Disorders(NIDCD) indicate that approximately 28,400 children in the United States have received a cochlear implant as of December 2010.
0.952	[*A*]approximately 28,400 children in the United States[*R*]have received[*A*]a cochlear implant[*A*]as of December 2010	context(Statistical data from Other Communication Disorders indicate)	negated: False ,passive: False
0.899	[*A*]Statistical data from Other Communication Disorders[*R*]indicate[*A*]that approximately 28,400 children in the United States have received a cochlear implant as of December 2010	context()	negated: False ,passive: False
0.952	[*A*]approximately 28,400 children in the United States[*R*]have received[*A*]a cochlear implant[*A*]as of December 2010	context(Statistical data from the National Institute on Deafness indicate)	negated: False ,passive: False
0.927	[*A*]Statistical data from the National Institute on Deafness[*R*]indicate[*A*]that approximately 28,400 children in the United States have received a cochlear implant as of December 2010	context()	negated: False ,passive: False
[LINE#114] While many congenitally deaf CI recipients achieve a high degree of accuracy in speech perception and develop near-normal language skills, about 30% of the recipients do not derive any benefit from the CI (Niparko et al., 2010).
0.944	[*A*]many congenitally deaf CI recipients[*R*]achieve[*A*]a high degree of accuracy[*A*]in speech perception	context()	negated: False ,passive: False
[LINE#115] A deeper understanding of hearing loss and better characterization of the brain regions affected by hearing loss will help reduce the high variance in CI outcomes and result in a more effective treatment of children with hearing loss.
0.946	[*A*]A deeper understanding of hearing better characterization of the brain regions[*R*]will help[*A*]reduce the high variance in CI	context()	negated: False ,passive: False
0.946	[*A*]A deeper understanding of hearing better characterization of the brain regions[*R*]will help reduce[*A*]the high variance in CI outcomes	context(A deeper understanding of hearing better characterization of the brain regions will help)	negated: False ,passive: False
0.946	[*A*]A deeper understanding of hearing better characterization of the brain regions[*R*]will help[*A*]reduce the high variance in CI outcomes	context()	negated: False ,passive: False
0.911	[*A*]the brain regions[*R*]affected[*A*]by hearing loss	context()	negated: False ,passive: True
0.927	[*A*]A deeper understanding of hearing loss[*R*]will help reduce[*A*]the high variance[*A*]in CI	context(A deeper understanding of hearing loss will help)	negated: False ,passive: False
0.927	[*A*]A deeper understanding of hearing loss[*R*]will help[*A*]reduce the high variance in CI	context()	negated: False ,passive: False
0.927	[*A*]A deeper understanding of hearing loss[*R*]will help reduce[*A*]the high variance in CI outcomes	context(A deeper understanding of hearing loss will help)	negated: False ,passive: False
0.927	[*A*]A deeper understanding of hearing loss[*R*]will help[*A*]reduce the high variance in CI outcomes	context()	negated: False ,passive: False
[LINE#116] In recent years, Magnetic Resonance (MR) images have been used to study neurological disorders and brain development in children, such as reading and attention problems, traumatic brain injury, hearing impairment, perinatal stroke and other conditions (Horowitz-Kraus and Holland, 2012; Leach and Holland, 2010; Smith et al., 2011; Tillema et al., 2008; Tlustos et al., 2011).
0.948	[*A*]Tlustos[*R*]et[*A*]al	context()	negated: False ,passive: False
0.877	[*A*]images[*R*]to study[*A*]neurological disorders and brain development	context()	negated: False ,passive: False
0.960	[*A*]images[*R*]have been used[*A*]to study neurological disorders and brain development in children, such as reading and attention problems, traumatic brain injury, hearing impairment, perinatal stroke and other conditions[*A*]In recent years	context()	negated: False ,passive: True
[LINE#117] Brain MRI scans have revealed significant differences between Hearing Impaired (HI) and Normal Hearing (NH) children.
0.964	[*A*]Brain MRI scans[*R*]have revealed[*A*]significant differences between Hearing Impaired (HI) and Normal Hearing (NH) children	context()	negated: False ,passive: False
[LINE#118] Jonas et al. reviewed a total number of 162 patients' structural MRI scans, and detected 51 abnormalities in 49 patients.
[LINE#119] Those abnormalities included white matter changes, structural or anatomical abnormalities, neoplasms, gray matter changes, vasculitis and neuro-metabolic changes (Jonas et al., 2012).
0.937	[*A*]Those abnormalities[*R*]included[*A*]white matter changes, structural or anatomical abnormalities, neoplasms, gray matter changes, vasculitis and neuro-metabolic changes	context()	negated: False ,passive: True
[LINE#120] Similar studies have showed consistent results (Lapointe et al., 2006; Smith et al., 2011; Trimble et al., 2007).
0.903	[*A*]Similar studies[*R*]have showed[*A*]consistent results	context()	negated: False ,passive: False
[LINE#121]  Furthermore, functional MRI studies have demonstrated that the activation pattern of HI is different from that of NH during certain scanning tasks (Bilecen et al., 2000; Patel et al., 2007; Propst et al., 2010; Scheffler et al., 1998;.
0.883	[*A*]the activation pattern of HI[*R*]is[*A*]different from that of NH	context(functional MRI studies have demonstrated)	negated: False ,passive: True
0.883	[*A*]functional MRI studies[*R*]have demonstrated[*A*]that the activation pattern of HI is different from that of NH during certain scanning tasks	context()	negated: False ,passive: False
[LINE#122] For example, Propst and colleagues studied the activation pattern of HI with narrowband noise and speech-in-noise tasks (Propst et al., 2010).
0.911	[*A*]colleagues[*R*]studied[*A*]the activation pattern of HI	context()	negated: False ,passive: False
0.877	[*A*]Propst[*R*]studied[*A*]the activation pattern of HI	context()	negated: False ,passive: False
[LINE#123] In the narrowband noise task, they found that HI children had weaker activation in the auditory areas when compared to NH children.
0.961	[*A*]HI children[*R*]had[*A*]weaker activation in the auditory areas when compared to NH children	context(they found)	negated: False ,passive: False
0.608	[*A*]they[*R*]found[*A*]that HI children had weaker activation in the auditory areas[*A*]In the narrowband noise task	context()	negated: False ,passive: False
[LINE#124] Meanwhile, NH also activated auditory association areas and attention networks, which were not detected in HI children.
0.913	[*A*]auditory attention networks[*R*]were not detected[*A*]in HI children	context()	negated: True ,passive: True
0.945	[*A*]NH[*R*]activated[*A*]auditory attention networks , which were not detected in HI children[*A*]Meanwhile	context()	negated: False ,passive: False
0.899	[*A*]NH[*R*]activated[*A*]auditory association areas[*A*]Meanwhile	context()	negated: False ,passive: False
[LINE#125] In the speech-in-noise task, HI children activated the secondary auditory processing areas only in the left hemisphere, rather than bilaterally as is typical of NH.
0.973	[*A*]HI children[*R*]activated[*A*]the secondary auditory processing areas only in the left hemisphere, rather than bilaterally[*A*]In the speech-in-noise task	context()	negated: False ,passive: False
[LINE#126] Recently, we have tried to use the activation in the primary auditory cortex (A1) to predict CI outcomes.
0.333	[*A*]we[*R*]have tried to use the activation to predict[*A*]CI outcomes	context(we have tried to use)	negated: False ,passive: False
0.433	[*A*]we[*R*]have tried to use[*A*]the activation[*A*]in the primary auditory cortex[*A*]to predict CI outcomes	context(we have tried)	negated: False ,passive: False
0.686	[*A*]we[*R*]have tried[*A*]to use the activation in the primary auditory cortex (A1) to predict CI outcomes[*A*]Recently	context()	negated: False ,passive: False
[LINE#127] A strong correlation (linear regression coefficient, R=0.88) was detected between the improvement in post-CI hearing threshold and the amount of activation in the A1 region before CI (Patel et al., 2007).
0.944	[*A*]A strong correlation[*R*]was detected[*A*]between the improvement in post-CI hearing threshold and the amount of activation in the A1 region	context()	negated: False ,passive: True
[LINE#128] Despite these recent advances, it remains unclear whether these structural and functional abnormalities are sufficient to distinguish HI from NH individuals.
0.913	[*A*]these functional abnormalities[*R*]to distinguish[*A*]HI[*A*]from NH individuals	context()	negated: False ,passive: False
0.913	[*A*]these structural abnormalities[*R*]to distinguish[*A*]HI[*A*]from NH individuals	context()	negated: False ,passive: False
[LINE#129] In this study, we set out to investigate whether we can accurately classify HI from NH individuals based on MR images alone by utilizing machine learning techniques.
0.433	[*A*]we[*R*]can accurately classify[*A*]HI[*A*]from NH individuals	context(we set out to investigate)	negated: False ,passive: False
0.399	[*A*]we[*R*]set out to investigate[*A*]whether we can accurately classify HI from NH individuals based on MR images alone by utilizing machine learning techniques	context(we set out)	negated: False ,passive: False
0.543	[*A*]we[*R*]set out[*A*]to investigate whether we can accurately classify HI from NH individuals based on MR images alone by utilizing machine learning techniques[*A*]In this study	context()	negated: False ,passive: False
0.833	[*A*]HI[*R*]by utilizing[*A*]machine learning techniques	context()	negated: False ,passive: False
0.938	[*A*]NH individuals[*R*]based[*A*]on MR images alone	context()	negated: False ,passive: True
[LINE#130] We have trained three classifiers, one based on structural MR (sMRI) images, another based on functional MR (fMRI) images, and a third that integrates sMRI and fMRI images.
0.905	[*A*]a third[*R*]integrates[*A*]fMRI images	context()	negated: False ,passive: False
0.905	[*A*]a third[*R*]integrates[*A*]sMRI images	context()	negated: False ,passive: False
0.544	[*A*]another[*R*]based[*A*]on a third	context()	negated: False ,passive: True
0.590	[*A*]another[*R*]based[*A*]on functional MR ( fMRI ) images	context()	negated: False ,passive: True
0.590	[*A*]one[*R*]based[*A*]on structural MR ( sMRI ) images	context()	negated: False ,passive: True
0.452	[*A*]We[*R*]have trained[*A*]three classifiers	context()	negated: False ,passive: False
[LINE#131] While traditional methods utilize voxel-based morphometric (VBM) features, in which each single voxel serves as an independent feature, we extracted high-level features to characterize the 3D images.
0.433	[*A*]we[*R*]extracted high-level features to characterize[*A*]the 3D images	context(we extracted)	negated: False ,passive: False
0.433	[*A*]we[*R*]extracted[*A*]high-level features[*A*]to characterize the 3D images	context()	negated: False ,passive: False
0.957	[*A*]each single voxel[*R*]serves[*A*]as an independent feature[*A*]voxel-based morphometric (VBM) features	context()	negated: False ,passive: False
0.918	[*A*]traditional methods[*R*]utilize[*A*]voxel-based morphometric (VBM) features	context()	negated: False ,passive: False
[LINE#132] Specifically, we employed the Scale Invariant Feature Transform (SIFT) algorithm to detect and describe local features in sMRI and extracted region-level features to represent the functional contrast maps.
0.919	[*A*]region - level features[*R*]to represent[*A*]the functional contrast maps	context()	negated: False ,passive: False
0.867	[*A*]algorithm[*R*]describe[*A*]local features	context(we employed)	negated: False ,passive: False
0.388	[*A*]we[*R*]employed[*A*]the Scale	context()	negated: False ,passive: False
0.433	[*A*]we[*R*]employed[*A*]the Scale Invariant Feature Transform	context()	negated: False ,passive: False
[LINE#133]  Based upon the extracted features, SVM classifiers were trained to separate HI from NH.The SIFT algorithm was first proposed by Lowe for object recognition.
0.928	[*A*]SVM classifiers[*R*]to separate[*A*]HI[*A*]from NH.The SIFT algorithm	context()	negated: False ,passive: False
0.938	[*A*]SVM classifiers[*R*]were trained[*A*]to separate HI from NH.The SIFT algorithm	context()	negated: False ,passive: True
[LINE#134] Since then, it has been widely used in the computer vision field.
0.490	[*A*]it[*R*]has been used[*A*]in the computer vision field[*A*]Since then	context()	negated: False ,passive: True
[LINE#135] Basically, the SIFT algorithm detects blob-like image components and calculates a vector to describe each of these components.
0.933	[*A*]the SIFT algorithm[*R*]calculates[*A*]a vector to describe each of these components	context()	negated: False ,passive: False
0.933	[*A*]the SIFT algorithm[*R*]detects[*A*]blob - like image components	context()	negated: False ,passive: False
[LINE#136] Each vector becomes a SIFT feature.
0.918	[*A*]Each vector[*R*]becomes[*A*]a SIFT feature	context()	negated: False ,passive: True
[LINE#137] The set of SIFT features extracted from an image contains important characteristics of this image and can be used for subsequent analysis, e.g. object recognition, gesture recognition etc.
0.903	[*A*]The set[*R*]can be used[*A*]for subsequent analysis	context()	negated: False ,passive: True
0.934	[*A*]The set of SIFT features[*R*]contains[*A*]important characteristics of this image	context()	negated: False ,passive: False
0.927	[*A*]SIFT features[*R*]extracted[*A*]from an image	context()	negated: False ,passive: True
[LINE#138] In this study, we employed the SIFT algorithm to extract SIFT features from brain structural MR images, and devised an approach for the automatic classification of NH vs. HI based on the SIFT features.
0.961	[*A*]the automatic classification of NH vs. HI[*R*]based[*A*]on the SIFT features	context()	negated: False ,passive: True
0.740	[*A*]we[*R*]devised[*A*]an approach for the automatic classification of NH vs. HI[*A*]In this study	context()	negated: False ,passive: False
0.433	[*A*]we[*R*]employed the SIFT algorithm to extract[*A*]SIFT features[*A*]from brain structural MR images	context(we employed)	negated: False ,passive: False
0.577	[*A*]we[*R*]employed[*A*]the SIFT algorithm[*A*]to extract SIFT features from brain structural MR images[*A*]In this study	context()	negated: False ,passive: False
[LINE#139] There are three levels of significance for this study.
[LINE#140] First of all, we convincingly demonstrate that hearing loss can be accurately diagnosed based on MR images alone.
0.896	[*A*]hearing loss[*R*]can be accurately diagnosed[*A*]based on MR images alone	context(we convincingly demonstrate)	negated: False ,passive: True
0.309	[*A*]we[*R*]convincingly demonstrate[*A*]that hearing loss can be accurately diagnosed based on MR images alone	context()	negated: False ,passive: False
[LINE#141] Secondly, brain regions identified by the classifiers enable us to better understand hearing loss, and may serve as valuable indicators for the CI outcome and facilitate follow-up treatment post-CI (Jonas et al., 2012).
0.911	[*A*]brain[*R*]may serve[*A*]as valuable indicators for the CI outcome	context()	negated: False ,passive: False
0.293	[*A*]us[*R*]to understand hearing[*A*]loss	context(us to understand)	negated: False ,passive: False
0.293	[*A*]us[*R*]to understand[*A*]hearing loss	context()	negated: False ,passive: False
0.882	[*A*]brain regions identified by the classifiers[*R*]enable[*A*]us[*A*]to better understand hearing loss	context()	negated: False ,passive: False
0.903	[*A*]brain regions[*R*]identified[*A*]by the classifiers	context()	negated: False ,passive: True
[LINE#142] Finally, our algorithm can be easily extended to assist in diagnosing other disorders affecting children's brains, e.g., speech sound disorders of childhood, leading to a path for improving child health.
0.901	[*A*]other disorders[*R*]affecting e.g.[*A*]children's brains	context()	negated: False ,passive: False
0.759	[*A*]our algorithm[*R*]can be easily extended[*A*]to assist in diagnosing other disorders[*A*]Finally	context()	negated: False ,passive: True
[LINE#143] The organization of this article is as follows.
0.853	[*A*]The organization of this article[*R*]is[*A*]as follows	context()	negated: False ,passive: True
[LINE#144] In Materials and methods, we describe in sequence the data sources and the preprocessing procedures, the methods of analyzing sMRI and fMRI images, the integrative model that combines these two methods, and the validation of our classifiers.
0.639	[*A*]we[*R*]describe[*A*]in sequence[*A*]the methods of analyzing fMRI images[*A*]In methods	context()	negated: False ,passive: False
0.639	[*A*]we[*R*]describe[*A*]in sequence[*A*]the methods of analyzing sMRI images[*A*]In methods	context()	negated: False ,passive: False
0.639	[*A*]we[*R*]describe[*A*]in sequence[*A*]the methods of analyzing fMRI images[*A*]In Materials	context()	negated: False ,passive: False
0.639	[*A*]we[*R*]describe[*A*]in sequence[*A*]the methods of analyzing sMRI images[*A*]In Materials	context()	negated: False ,passive: False
0.444	[*A*]we[*R*]describe[*A*]in sequence[*A*]the validation of our classifiers[*A*]In methods	context()	negated: False ,passive: False
0.350	[*A*]we[*R*]describe[*A*]in sequence[*A*]the integrative model that combines these two methods[*A*]In methods	context()	negated: False ,passive: False
0.595	[*A*]we[*R*]describe[*A*]in sequence[*A*]the preprocessing procedures[*A*]In methods	context()	negated: False ,passive: False
0.595	[*A*]we[*R*]describe[*A*]in sequence[*A*]the data sources[*A*]In methods	context()	negated: False ,passive: False
0.444	[*A*]we[*R*]describe[*A*]in sequence[*A*]the validation of our classifiers[*A*]In Materials	context()	negated: False ,passive: False
0.897	[*A*]the integrative model[*R*]combines[*A*]these two methods	context()	negated: False ,passive: False
0.350	[*A*]we[*R*]describe[*A*]in sequence[*A*]the integrative model that combines these two methods[*A*]In Materials	context()	negated: False ,passive: False
0.595	[*A*]we[*R*]describe[*A*]in sequence[*A*]the preprocessing procedures[*A*]In Materials	context()	negated: False ,passive: False
0.595	[*A*]we[*R*]describe[*A*]in sequence[*A*]the data sources[*A*]In Materials	context()	negated: False ,passive: False
[LINE#145] In Results, we compare the classification performance of the sMRI classifier, the fMRI classifier and the combined classifier, and assess the stability of feature selection as well as the discriminatory power of features.
0.554	[*A*]we[*R*]assess[*A*]the stability of the discriminatory power of features[*A*]In Results	context()	negated: False ,passive: False
0.554	[*A*]we[*R*]assess[*A*]the stability of feature selection[*A*]In Results	context()	negated: False ,passive: False
0.639	[*A*]we[*R*]compare[*A*]the classification performance of the sMRI classifier[*A*]In Results	context()	negated: False ,passive: False
[LINE#146] Finally, in Discussion, we summarize the present work, highlight the significance of our approach, and discuss the limitations and envisioned future improvements.
0.595	[*A*]we[*R*]summarize[*A*]the envisioned future improvements[*A*]in Discussion	context()	negated: False ,passive: False
0.595	[*A*]we[*R*]summarize[*A*]the present work[*A*]in Discussion	context()	negated: False ,passive: False
[LINE#147] We also examine the predictive brain regions our classifiers identified and discuss their relevance in the context of hearing loss.
0.903	[*A*]the predictive brain regions[*R*]identified[*A*]our classifiers	context()	negated: False ,passive: True
0.274	[*A*]We[*R*]examine[*A*]the predictive brain regions our classifiers identified	context()	negated: False ,passive: False
[LINE#148] Materials and methods. Data acquisition and preprocessing.
0.677	[*A*]methods[*R*]preprocessing	context()	negated: False ,passive: False
0.677	[*A*]Materials[*R*]preprocessing	context()	negated: False ,passive: False
[LINE#149] -nine infants and toddlers participated in a clinically indicated MRI brain study under sedation.
0.911	[*A*]toddlers[*R*]participated[*A*]in a clinically indicated MRI brain study under sedation	context()	negated: False ,passive: False
0.925	[*A*]- nine infants[*R*]participated[*A*]in a clinically indicated MRI brain study under sedation	context()	negated: False ,passive: False
[LINE#150] This study was conducted with approval from the Cincinnati Children's Hospital Medical Center Institutional Review Board (IRB).
0.381	[*A*]Institutional Review Board[*R*][is] Hospital Medical Center [of][*A*]Cincinnati Children	context()	negated: False ,passive: False
0.381	[*A*]Institutional Review Board[*R*][is] Medical Center [of][*A*]Hospital	context()	negated: False ,passive: False
0.732	[*A*]This study[*R*]was conducted	context()	negated: False ,passive: False
[LINE#151] Eighteen of the participants had SNHL (10 females, average age=14months, range=8-24months).
0.947	[*A*]Eighteen of the participants[*R*]had[*A*]SNHL	context()	negated: False ,passive: False
[LINE#152] All hearing impaired participants were referred by the Division of Otolaryngology for MRI as part of the cochlear implant staging process and consented to participate in our adjoining fMRI protocol.
0.243	[*A*]All[*R*]consented to participate[*A*]in our adjoining fMRI protocol	context(All consented)	negated: False ,passive: False
0.243	[*A*]All[*R*]consented[*A*]to participate in our adjoining fMRI protocol	context()	negated: False ,passive: False
0.931	[*A*]All hearing impaired participants[*R*]were referred[*A*]by the Division of Otolaryngology[*A*]as part of the cochlear implant staging process	context()	negated: False ,passive: True
0.903	[*A*]All hearing[*R*]impaired[*A*]participants	context()	negated: False ,passive: False
[LINE#153] They had documented bilateral severe to profound hearing loss with average hearing thresholds in the range of 90dB or greater.
0.755	[*A*]They[*R*]had documented[*A*]bilateral severe[*A*]to profound hearing loss with average hearing thresholds in the range of 90dB or greater	context()	negated: False ,passive: False
[LINE#154] Nine of these subjects had no measureable hearing response in either ear at the maximum level of our audiometry equipment, at 120dB and can be considered deaf.
0.940	[*A*]Nine of these subjects[*R*]had[*A*]no measureable hearing response in either ear at the maximum level of our audiometry equipment , at 120dB	context()	negated: False ,passive: False
[LINE#155] The remaining 21 participants were normal hearing controls (15 females, average age=12months, range=8-17months).
0.919	[*A*]The remaining 21 participants[*R*]were[*A*]normal hearing controls	context()	negated: False ,passive: True
[LINE#156] These children received clinical MRI scans with sedation for non-hearing related indications.
0.918	[*A*]These children[*R*]received[*A*]clinical MRI scans with sedation for non-hearing related indications	context()	negated: False ,passive: False
[LINE#157] They were recruited for the control group if they met the inclusion criteria: gestational age of at least 36weeks, normal otoacoustic emissions hearing, and normal neuroanatomy determined by the neuroradiologist.
0.919	[*A*]at least normal neuroanatomy[*R*]determined[*A*]by the neuroradiologist	context()	negated: False ,passive: True
0.932	[*A*]at least normal otoacoustic emissions hearing[*R*]determined[*A*]by the neuroradiologist	context()	negated: False ,passive: True
0.911	[*A*]at least 36weeks[*R*]determined[*A*]by the neuroradiologist	context()	negated: False ,passive: True
0.680	[*A*]they[*R*]met[*A*]the inclusion criteria	context()	negated: False ,passive: False
0.465	[*A*]They[*R*]were recruited[*A*]for the control group[*A*]if they met the inclusion criteria	context()	negated: False ,passive: True
[LINE#158] Informed consent of parent or guardian was obtained prior to the study protocol, and the parent agreed to additional hearing tests at a separate visit.
0.903	[*A*]the parent[*R*]agreed[*A*]to additional hearing tests[*A*]at a separate visit	context()	negated: False ,passive: False
0.932	[*A*]Informed consent of parent or guardian[*R*]was obtained[*A*]prior to the study protocol	context()	negated: False ,passive: True
[LINE#159] The child's reason for referral for brain MRI was not related to hearing.
0.961	[*A*]The child's reason for referral for brain MRI[*R*]was not related[*A*]to hearing	context()	negated: True ,passive: True
[LINE#160] Exclusions included head circumference <5 percentile or >95 percentile, orthodontic or metallic implants that interfere with the MRI, abnormal brain pathology in the central auditory pathways.
0.896	[*A*]implants[*R*]interfere[*A*]with the MRI	context()	negated: False ,passive: False
0.931	[*A*]Exclusions[*R*]included[*A*]head circumference <5 percentile or >95 percentile, orthodontic or metallic	context()	negated: False ,passive: True
[LINE#161] Examples of indications for scanning in this group were, "odd body positioning-rule out chiari malformation", "recent onset irritable behavior-rule out brain tumor".
0.943	[*A*]Examples of indications for scanning in this group[*R*]were[*A*]odd body positioning-rule out chiari malformation	context()	negated: False ,passive: True
[LINE#162] All participants were screened for hearing loss using otoacoustic emission (OAE) prior to the MRI scan.
0.887	[*A*]All participants[*R*]for hearing[*A*]loss	context()	negated: False ,passive: False
0.903	[*A*]All participants[*R*]were screened[*A*]for hearing loss	context()	negated: False ,passive: True
[LINE#163] Failed OAE at the time of scan was also an exclusion criterion for the normal control group.
0.964	[*A*]Failed OAE at the time of scan[*R*]was[*A*]also[*A*]an exclusion criterion for the normal control group	context()	negated: False ,passive: True
[LINE#164+165]  All of these brain scans of both hearingimpaired group and control group were reviewed by a pediatric neuroradiologist and assessed as having no anatomical findings of significance.
0.953	[*A*]All of these brain scans of both hearingimpaired control group[*R*]were assessed[*A*]as having no anatomical findings of significance	context()	negated: False ,passive: True
0.953	[*A*]All of these brain scans of both hearingimpaired group group[*R*]were assessed[*A*]as having no anatomical findings of significance	context()	negated: False ,passive: True
0.953	[*A*]All of these brain scans of both hearingimpaired control group[*R*]were reviewed[*A*]by a pediatric neuroradiologist	context()	negated: False ,passive: True
0.953	[*A*]All of these brain scans of both hearingimpaired group group[*R*]were reviewed[*A*]by a pediatric neuroradiologist	context()	negated: False ,passive: True
[LINE#166] One of the challenges of research in pediatric neuroimaging is that it is unethical to expose children to more than minimal risk for the purposes of research.
0.584	[*A*]it[*R*]is[*A*]unethical to expose children to more than minimal risk for the purposes of research	context(One of the challenges of research in pediatric neuroimaging is)	negated: False ,passive: True
0.861	[*A*]One of the challenges of research in pediatric neuroimaging[*R*]is[*A*]that it is unethical to expose children to more than minimal risk for the purposes of research	context()	negated: False ,passive: True
[LINE#167] This principle is dictated by our conscience as well as by the IRB at most institutions.
0.918	[*A*]This principle[*R*]is dictated[*A*]by the IRB[*A*]at most institutions	context()	negated: False ,passive: True
0.835	[*A*]This principle[*R*]is dictated[*A*]by our conscience[*A*]at most institutions	context()	negated: False ,passive: True
[LINE#168] Consequently, one of the fine points in the design of the present study is that we were required to select our control population among infants who were referred for an MRI scan with sedation because of a clinical indication.
0.256	[*A*]we[*R*]were required[*A*]to select our control population among infants	context(one of the fine points in the design of the present study is)	negated: False ,passive: True
0.888	[*A*]one of the fine points in the design of the present study[*R*]is[*A*]that we were required to select our control population among infants	context()	negated: False ,passive: True
0.274	[*A*]we[*R*]to select[*A*]our control population among infants	context()	negated: False ,passive: False
[LINE#169] With the precautions described above and other procedures we took to insure normal auditory function and brain anatomy, this is perhaps the best control group that could be obtained for this age group in an ethical fashion.
0.349	[*A*]we[*R*]to insure[*A*]brain anatomy	context(the precautions other procedures took)	negated: False ,passive: False
0.880	[*A*]the precautions other procedures[*R*]took[*A*]to insure brain anatomy	context()	negated: False ,passive: True
0.349	[*A*]we[*R*]to insure[*A*]normal auditory function	context(the precautions other procedures took)	negated: False ,passive: False
0.880	[*A*]the precautions other procedures[*R*]took[*A*]to insure normal auditory function	context()	negated: False ,passive: True
0.411	[*A*]we[*R*]to insure[*A*]brain anatomy	context()	negated: False ,passive: False
0.269	[*A*]this[*R*]is[*A*]perhaps[*A*]the best control group that could be obtained for this age group in an ethical fashion	context()	negated: False ,passive: True
0.737	[*A*]the best control group[*R*]could be obtained	context()	negated: False ,passive: False
0.411	[*A*]we[*R*]to insure[*A*]normal auditory function	context()	negated: False ,passive: False
0.767	[*A*]the precautions[*R*]described[*A*]above	context()	negated: False ,passive: True
[LINE#170] However, it is important to note that the controls were not randomly sampled from the general population. .
[LINE#171] acquisitionAnatomical images for this study were acquired using a 3.0Tesla Siemens Trio MRI scanner in the clinical Department of Radiology.
0.785	[*A*]acquisitionAnatomical images for this study[*R*]were acquired	context()	negated: False ,passive: False
[LINE#172] Isotropic images of the brain were acquired using an inversion recovery prepared rapid gradient-echo 3D method (MP-RAGE) covering the entire brain at a spatial resolution of 111mm in an axial orientation.
0.926	[*A*]Isotropic images of the brain[*R*]were acquired[*A*]using an inversion recovery	context()	negated: False ,passive: True
[LINE#173] 3D MP-RAGE acquisition parameters were as follows: TI/TR/TE=1100/1900/4.1ms, FOV=25.620.8cm, matrix=256208, scan time=3min and 50s.
0.953	[*A*]3 D MP - RAGE acquisition parameters[*R*]were[*A*]as follows : TI / TR / TE=1100/1900/4.1 ms , scan time=3min	context()	negated: False ,passive: True
0.927	[*A*]3 D MP - RAGE acquisition parameters[*R*]were[*A*]as follows : TI / TR / TE=1100/1900/4.1 ms	context()	negated: False ,passive: True
[LINE#174] These high resolution 3D-T1 weighted images were used for co-registration of fMRI scans which were also acquired during this scheduled MRI.Functional MRI scans were performed using a silent background fMRI acquisition technique that allowed auditory stimuli to be presented during a silent gradient interval of the scan, followed by an acquisition interval that captured the peak BOLD response of relevant brain regions (Schmithorst and Holland, 2004).
0.897	[*A*]an acquisition interval[*R*]captured[*A*]BOLD response of relevant brain regions	context()	negated: False ,passive: False
0.927	[*A*]a silent gradient interval of the scan[*R*]followed[*A*]by an acquisition interval	context()	negated: False ,passive: True
0.893	[*A*]fMRI scans[*R*]were acquired[*A*]during this scheduled MRI.Functional MRI scans	context()	negated: False ,passive: True
0.913	[*A*]an acquisition interval[*R*]captured[*A*]the peak BOLD response of relevant brain regions	context()	negated: False ,passive: False
0.878	[*A*]auditory stimuli[*R*]to be presented[*A*]during a silent gradient interval of the scan	context(a silent background fMRI acquisition technique allowed)	negated: False ,passive: True
0.951	[*A*]a silent background fMRI acquisition technique[*R*]allowed[*A*]auditory stimuli to be presented during a silent gradient interval of the scan	context()	negated: False ,passive: False
0.957	[*A*]These high resolution 3D - T1 weighted images[*R*]were used[*A*]for co-registration of fMRI scans	context()	negated: False ,passive: True
[LINE#175] Using the scanner described above we acquired BOLD fMRI scans in an axial plane (44mm resolution), using the manufacturer's standard gradient echo, EPI sequence covering the same FOV as the 3D T1 images (see paragraph above), with the following parameters: TR/TE=2000/23msec, flip angle=90, matrix=6464 and 25 axial slices with thickness=5mm.
0.550	[*A*]we[*R*]acquired[*A*]BOLD fMRI[*A*]using the manufacturer 's standard gradient echo , EPI sequence	context()	negated: False ,passive: False
0.767	[*A*]the scanner[*R*]described[*A*]above	context()	negated: False ,passive: True
[LINE#176+177]  In the present study, all stimulus and control intervals were of equal duration(5s) in a three-phase auditory paradigm consisting of speech, silence, and narrow band noise tones interleaved with acquisition periods of 6s during which 3 image volumes were obtained covering the whole brain.
0.948	[*A*]all control intervals[*R*]were[*A*]of equal duration[*A*]in a three - phase auditory paradigm[*A*]In the present study	context()	negated: False ,passive: True
0.919	[*A*]narrow band noise tones[*R*]interleaved[*A*]with acquisition periods of 6 s	context()	negated: False ,passive: True
0.932	[*A*]a three - phase auditory paradigm[*R*]consisting[*A*]of narrow band noise tones	context()	negated: False ,passive: True
0.948	[*A*]a three - phase auditory paradigm consisting of silence[*R*]interleaved[*A*]with acquisition periods of 6 s	context()	negated: False ,passive: True
0.802	[*A*]6 s[*R*]were obtained[*A*]covering the whole brain	context()	negated: False ,passive: True
0.894	[*A*]speech[*R*]interleaved[*A*]with acquisition periods of 6 s	context()	negated: False ,passive: True
0.932	[*A*]a three - phase auditory paradigm[*R*]consisting[*A*]of speech	context()	negated: False ,passive: True
0.948	[*A*]all stimulus intervals[*R*]were[*A*]of equal duration[*A*]in a three - phase auditory paradigm[*A*]In the present study	context()	negated: False ,passive: True
[LINE#178+179]  A timing diagram for the fMRI data acquisition and stimulation paradigm is shown in Fig.speech stimulus consisted of sentences read in a female voice.
0.948	[*A*]A timing diagram for the stimulation paradigm[*R*]is shown[*A*]in Fig.speech stimulus	context()	negated: False ,passive: True
0.713	[*A*]sentences[*R*]read	context()	negated: False ,passive: False
0.927	[*A*]Fig.speech stimulus[*R*]consisted[*A*]of sentences	context()	negated: False ,passive: True
0.964	[*A*]A timing diagram for the fMRI data acquisition[*R*]is shown[*A*]in Fig.speech stimulus	context()	negated: False ,passive: True
[LINE#180] Altogether 36 sentences were read in 18 segments of 5s duration and comprising 2 sentences each.
0.827	[*A*]5 s[*R*]comprising[*A*]2 sentences each	context()	negated: False ,passive: True
0.903	[*A*]36 sentences[*R*]were read[*A*]in 18 segments of 5 s	context()	negated: False ,passive: True
0.992	[*A*]36 sentences[*R*]were read in[*A*]18 segments of 5 s duration	context()	negated: False ,passive: False
0.993	[*A*]36 sentences[*R*]were read in[*A*]18 segments	context()	negated: False ,passive: False
0.903	[*A*]36 sentences[*R*]were read[*A*]in 18 segments of 5 s duration	context()	negated: False ,passive: True
[LINE#181] This condition was followed by a 6s data acquisition and then a 5s interval of silence as a control condition.
0.903	[*A*]This condition[*R*]was followed[*A*]by a 6 s	context()	negated: False ,passive: True
0.903	[*A*]This condition[*R*]was followed[*A*]by a 6 s data acquisition	context()	negated: False ,passive: True
[LINE#182] After another 6s control interval acquisition, a second auditory control condition was played.
0.949	[*A*]a second auditory control condition[*R*]was played[*A*]After another 6s control interval acquisition	context()	negated: False ,passive: True
[LINE#183] This condition consisted of Narrow Band Noise (NBN) tones patterned after standard audiology evaluations for detection of hearing thresholds.
0.894	[*A*]tones[*R*]patterned[*A*]after standard audiology evaluations for detection of hearing thresholds	context()	negated: False ,passive: True
0.918	[*A*]This condition[*R*]consisted[*A*]of Narrow Band Noise	context()	negated: False ,passive: True
[LINE#184] Five NBN tones of 1s duration with center frequencies of 250, 500, 1000, 2000 and 4000Hz and bandwidth of 50% were played in random order during this control condition, for a total of 5s during a silent interval of the scanner.
0.991	[*A*]Five NBN tones of 1s duration with center frequencies of 250, 500, 1000, 2000 and 4000Hz and bandwidth of 50%[*R*]were played[*A*]in random order[*A*]during this control condition	context()	negated: False ,passive: True
[LINE#185] An additional interval of 1s of silence followed each acquisition to provide an acoustic demarcation prior to the stimulus onset of each stimulus condition.
0.964	[*A*]An additional interval of 1s of silence[*R*]followed[*A*]each acquisition[*A*]to provide an acoustic demarcation prior to the stimulus onset of each stimulus condition	context()	negated: False ,passive: True
[LINE#186] This resulted in the fMRI acquisition time of approximately 11min.
0.425	[*A*]This[*R*]resulted[*A*]in the fMRI acquisition time of approximately 11min	context()	negated: False ,passive: True
[LINE#187] See Fig. 1 for a detailed schematic of the task and timing.
[LINE#188] Auditory stimuli were administered through calibrated MR compatible headphones at a sound level of 10-15dB greater than the individual participant's Pure Tone Average (PTA) hearing threshold.
0.937	[*A*]Auditory stimuli[*R*]were administered[*A*]at a sound level of 10-15dB greater than the individual participant's Pure Tone Average (PTA) hearing threshold	context()	negated: False ,passive: True
[LINE#189] Each hearing impaired participant in the study had a recent audiogram, which was used to determine the sound level for fMRI.
0.913	[*A*]a recent audiogram[*R*]was used[*A*]to determine the sound level for fMRI	context()	negated: False ,passive: True
0.975	[*A*]Each hearing impaired participant in the study[*R*]had[*A*]a recent audiogram, which was used to determine the sound level for fMRI	context()	negated: False ,passive: False
0.903	[*A*]Each hearing[*R*]impaired[*A*]participant in the study	context()	negated: False ,passive: False
[LINE#190] Our MR compatible audio system was modified to allow for an output through the headphones measuring up to 130dB. .
0.918	[*A*]the headphones[*R*]measuring up[*A*]to 130dB	context()	negated: False ,passive: True
0.730	[*A*]Our MR compatible audio system[*R*]to allow[*A*]for an output through the headphones	context()	negated: False ,passive: False
0.762	[*A*]Our MR compatible audio system[*R*]was modified[*A*]to allow for an output through the headphones	context()	negated: False ,passive: True
[LINE#191+192]  preprocessingfMRI data were initially analyzed on a voxel-by-voxel basis to identify the activated brain regions using a standard pre-processing pipeline implemented in the Cincinnati Children's Hospital Image Processing Software (CCHIPS)(Schmithorst et al., 2010) written in IDL computer language.
0.381	[*A*]Processing Software[*R*][is] Hospital Image [of][*A*]Cincinnati Children	context()	negated: False ,passive: False
0.381	[*A*]Processing Software[*R*][is] Image [of][*A*]Hospital	context()	negated: False ,passive: False
0.956	[*A*]a standard pre-processing pipeline[*R*]implemented[*A*]in the Cincinnati Children's Hospital Image Processing Software (CCHIPS)(Schmithorst et al	context()	negated: False ,passive: True
0.812	[*A*]preprocessingfMRI data[*R*]were analyzed[*A*]initially	context()	negated: False ,passive: True
[LINE#193] In this paper, we use voxel for 3-dimensional images and pixel for 2-dimensional images.
0.595	[*A*]we[*R*]use[*A*]voxel[*A*]for 3 - dimensional pixel[*A*]In this paper	context()	negated: False ,passive: False
0.702	[*A*]we[*R*]use[*A*]voxel[*A*]for 3 - dimensional images for 2 - dimensional images[*A*]In this paper	context()	negated: False ,passive: False
[LINE#194] Since the subjects were sedated, we assumed that the anatomical image was naturally aligned with the functional images for each individual.
0.888	[*A*]the anatomical image[*R*]was naturally aligned[*A*]with the functional images for each individual	context(we assumed)	negated: False ,passive: True
0.271	[*A*]we[*R*]assumed[*A*]that the anatomical image was naturally aligned with the functional images for each individual	context()	negated: False ,passive: False
0.732	[*A*]the subjects[*R*]were sedated	context()	negated: False ,passive: False
[LINE#195] Therefore, alignments between anatomical images and functional images were not needed in preprocessing.
0.842	[*A*]alignments between anatomical images and functional images[*R*]were not needed[*A*]in preprocessing	context()	negated: True ,passive: True
[LINE#196] In this case, it does not matter if we apply the normalization transformation before or after contrast determination.
[LINE#197] To generate both normalized contrast maps used in the current study as well as contrast maps in native space for other uses, we first generated contrast maps in each individual's native space and then normalized the contrast maps to standard space.
0.919	[*A*]both normalized contrast maps[*R*]used[*A*]in contrast maps[*A*]in native space	context()	negated: False ,passive: True
0.554	[*A*]we[*R*]generated[*A*]contrast maps[*A*]in each individual 's native space[*A*]first	context()	negated: False ,passive: False
0.948	[*A*]both normalized contrast maps[*R*]used[*A*]in the current study in native space for other uses	context()	negated: False ,passive: True
0.481	[*A*]both[*R*]normalized[*A*]the contrast maps[*A*]to standard space[*A*]then	context()	negated: False ,passive: False
0.178	[*A*]both[*R*]normalized[*A*]then	context()	negated: False ,passive: True
[LINE#198]  The raw EPI images were simultaneously corrected for Nyquist ghosting and geometrical distortion (due to B0 field inhomogeneity).
0.947	[*A*]The raw EPI images[*R*]were corrected[*A*]for geometrical distortion ( due to B0 field inhomogeneity[*A*]simultaneously	context()	negated: False ,passive: True
0.956	[*A*]The raw EPI images[*R*]were corrected[*A*]for Nyquist ghosting[*A*]simultaneously	context()	negated: False ,passive: True
[LINE#199] EPI functional MR time-series images were corrected on a voxel-by-voxel basis for drift using a quadratic baseline correction.
0.813	[*A*]drift[*R*]using[*A*]a quadratic baseline correction	context()	negated: False ,passive: False
0.857	[*A*]EPI functional MR time-series images[*R*]were corrected	context()	negated: False ,passive: False
[LINE#200] Motion artifacts were corrected using a pyramid iterative co-registration algorithm (Thevenaz et al., 1998).
0.732	[*A*]Motion artifacts[*R*]were corrected	context()	negated: False ,passive: False
[LINE#201] During this stage, infant brain images were transformed to the AC-PC plane.
0.957	[*A*]infant brain images[*R*]were transformed[*A*]to the AC-PC plane[*A*]During this stage	context()	negated: False ,passive: True
[LINE#202+203]  Finally, the individual image volumes (1,2,3) in the event-related fMRI acquisition were separated and submitted to a final pre-processing step using the General Linear Model(Worsley et al., 2002) to construct individual Z-maps for each volume and contrast condition (speech vs. silence, speech vs. tones and tones vs. silence).
0.980	[*A*]the individual image volumes ( 1,2 , 3 ) in the event - related fMRI acquisition[*R*]to construct[*A*]individual Z - maps[*A*]for each contrast condition	context()	negated: False ,passive: False
0.993	[*A*]the individual image volumes ( 1,2 , 3 ) in the event - related fMRI acquisition[*R*]were separated[*A*]to construct individual Z - maps for each contrast condition[*A*]Finally	context()	negated: False ,passive: True
0.989	[*A*]the individual image volumes ( 1,2 , 3 ) in the event - related fMRI acquisition[*R*]were submitted[*A*]to a final pre-processing step[*A*]Finally	context()	negated: False ,passive: True
0.980	[*A*]the individual image volumes ( 1,2 , 3 ) in the event - related fMRI acquisition[*R*]to construct[*A*]individual Z - maps[*A*]for each volume	context()	negated: False ,passive: False
0.989	[*A*]the individual image volumes ( 1,2 , 3 ) in the event - related fMRI acquisition[*R*]were separated[*A*]to construct individual Z - maps for each volume[*A*]Finally	context()	negated: False ,passive: True
[LINE#204] Z-maps showing activation for each condition for each participant were then computed by averaging the Z-maps from the individual volumes for each contrast condition (Patel et al., 2007; Schmithorst and Holland, 2004).
0.884	[*A*]Z - maps showing activation for each condition for each participant[*R*]were computed[*A*]then	context()	negated: False ,passive: True
0.841	[*A*]Z - maps[*R*]showing[*A*]activation[*A*]for each condition for each participant	context()	negated: False ,passive: False
[LINE#205] These Z-maps, in each individual's native space were used by the radiologists and neurotologists for clinical interpretation of findings.
0.945	[*A*]These Z - maps[*R*]were used[*A*]by neurotologists for clinical interpretation of findings[*A*]in each individual 's native space	context()	negated: False ,passive: True
0.957	[*A*]These Z - maps , in each individual 's native space[*R*]were used[*A*]by the radiologists for clinical interpretation of findings	context()	negated: False ,passive: True
[LINE#206] The neuroradiologist reviewed both functional and anatomical MRI scans for each participant and completed a standardized report indicating whether brain abnormalities or brain activities were detected in primary auditory areas, language areas or other brain regions.
0.941	[*A*]brain abnormalities or brain activities[*R*]were detected[*A*]in primary auditory areas, language areas or other brain regions	context(a standardized report indicating)	negated: False ,passive: True
0.929	[*A*]a standardized report[*R*]indicating[*A*]whether brain abnormalities or brain activities were detected in primary auditory areas, language areas or other brain regions	context()	negated: False ,passive: False
0.927	[*A*]The neuroradiologist[*R*]completed[*A*]a standardized report indicating whether brain abnormalities or brain activities were detected in primary auditory areas, language areas or other brain regions	context()	negated: False ,passive: False
0.918	[*A*]The neuroradiologist[*R*]reviewed[*A*]both functional and anatomical MRI scans for each participant	context()	negated: False ,passive: False
[LINE#207]  After that, we performed spatial normalization using SPM8 with a T1 template constructed from a control group of age matched subjects selected specifically for this infant cohort.
0.433	[*A*]we[*R*]performed spatial normalization using[*A*]SPM8[*A*]with a T1 template	context(we performed)	negated: False ,passive: False
0.293	[*A*]we[*R*]performed[*A*]spatial normalization[*A*]After that	context()	negated: False ,passive: False
0.911	[*A*]age matched subjects[*R*]selected specifically[*A*]for this infant cohort	context()	negated: False ,passive: True
0.911	[*A*]a T1 template[*R*]constructed[*A*]from a control group of age matched subjects	context()	negated: False ,passive: True
[LINE#208] The normalized anatomical images and functional Z-maps were then submitted to the next stages of analysis. .
0.947	[*A*]functional Z - maps[*R*]were submitted[*A*]to the next stages of analysis[*A*]then	context()	negated: False ,passive: True
0.929	[*A*]The normalized anatomical images[*R*]were submitted[*A*]to the next stages of analysis[*A*]then	context()	negated: False ,passive: True
[LINE#209+210]  Feature extraction and model learning based on structural MR imagesFor sMRI images, we used SIFT features to represent the brain images and developed an algorithm to analyze the SIFT features.
0.713	[*A*]model[*R*]learning	context()	negated: False ,passive: False
0.732	[*A*]Feature extraction[*R*]learning	context()	negated: False ,passive: False
[LINE#211] We have previously applied this method to Alzheimer's disease, Parkinson's disease and bipolar disease, and it has demonstrated promising classification performance (Chen et al., 2013)..
0.536	[*A*]We[*R*]have applied[*A*]this method[*A*]to Alzheimer disease[*A*]previously	context()	negated: False ,passive: False
0.536	[*A*]We[*R*]have applied[*A*]this method[*A*]to Alzheimer[*A*]previously	context()	negated: False ,passive: False
0.536	[*A*]We[*R*]have applied[*A*]this method[*A*]to Alzheimer Parkinson 's disease[*A*]previously	context()	negated: False ,passive: False
0.536	[*A*]We[*R*]have applied[*A*]this method[*A*]to Alzheimer 's disease[*A*]previously	context()	negated: False ,passive: False
0.397	[*A*]it[*R*]has demonstrated promising[*A*]classification performance	context(it has demonstrated)	negated: False ,passive: False
0.560	[*A*]it[*R*]has demonstrated[*A*]promising classification performance ( Chen et al . , 2013	context()	negated: False ,passive: False
[LINE#212] Obtaining 2D slices from 3D brain imagesDue to the high density of SIFT features in the brain images and the pair-wise comparison among SIFT features required in a later step, analyzing the 3D brain image as a whole is computationally infeasible.
0.895	[*A*]analyzing the 3D brain image as a whole[*R*]is[*A*]computationally infeasible	context()	negated: False ,passive: True
0.927	[*A*]SIFT features[*R*]required[*A*]in a later step	context()	negated: False ,passive: True
[LINE#213] Thus, the spatially normalized 3D brain (157189136) was divided into 560 202020 cubes.
0.993	[*A*]3 D brain[*R*]was divided into[*A*]560 202020 cubes	context()	negated: False ,passive: False
0.939	[*A*]3D brain[*R*]was divided[*A*]into 560 202020 cubes[*A*]spatially normalized	context()	negated: False ,passive: True
[LINE#214] Since the dimensions of brain image were not divisible by 20, the cubes at the end of dimensions only contained the remaining volume of the brain image and therefore had a size smaller than 202020.
0.913	[*A*]the dimensions[*R*]had[*A*]a size smaller than 202020	context()	negated: False ,passive: False
0.927	[*A*]the cubes at the end of dimensions[*R*]contained[*A*]the remaining volume of the brain image	context()	negated: False ,passive: False
0.814	[*A*]the dimensions of brain image[*R*]were not[*A*]divisible by 20	context()	negated: True ,passive: True
[LINE#215] The number 20 was determined based on our experience from the application of this algorithm to several other diseases.
0.899	[*A*]The number 20[*R*]was determined[*A*]based on our experience from the application of this algorithm to several other diseases	context()	negated: False ,passive: True
[LINE#216] The cube size mainly affects the computation speed and accuracy of the likelihood scores as described in the Feature evaluation section below.
0.897	[*A*]The cube size[*R*]affects[*A*]the accuracy of the likelihood scores[*A*]as described in the Feature evaluation section below	context()	negated: False ,passive: False
0.897	[*A*]The cube size[*R*]affects[*A*]the computation speed of the likelihood scores[*A*]as described in the Feature evaluation section below	context()	negated: False ,passive: False
[LINE#217] A larger size leads to a much longer computation time, while a smaller size decreases the accuracy of likelihood scores and subsequently leads to lower classification accuracy.
0.843	[*A*]A larger size[*R*]leads to a much longer computation time leads[*A*]to lower classification accuracy	context(A larger size leads)	negated: False ,passive: False
0.783	[*A*]a smaller size[*R*]decreases[*A*]subsequently	context()	negated: False ,passive: True
0.911	[*A*]a smaller size[*R*]decreases[*A*]the accuracy of likelihood scores	context()	negated: False ,passive: False
0.911	[*A*]A larger size[*R*]leads[*A*]to a much longer computation time	context()	negated: False ,passive: False
[LINE#218] According to our experimental results, the cube size 202020 provides a good balance between speed and accuracy.
0.919	[*A*]the cube size 202020[*R*]provides[*A*]a good balance between speed and accuracy	context()	negated: False ,passive: False
[LINE#219] Every cube was sliced along three different orientations to obtain 3 sets of 20 2D brain images.
0.937	[*A*]Every cube[*R*]was sliced[*A*]along three different orientations[*A*]to obtain 3 sets of 20 2D brain images	context()	negated: False ,passive: True
[LINE#220] We analyzed every cube and every set of 2D brain images individually.
0.445	[*A*]We[*R*]analyzed individually[*A*]every set of 2 D brain images	context()	negated: False ,passive: False
0.452	[*A*]We[*R*]analyzed[*A*]every cube	context()	negated: False ,passive: False
[LINE#221] The analysis results were combined together in the last step.
0.911	[*A*]The analysis results[*R*]were combined[*A*]together[*A*]in the last step	context()	negated: False ,passive: True
[LINE#222] Extracting SIFT featuresThe SIFT algorithm for analyzing 2D images was implemented in several stable software packages (Lowe; Vedaldi and Fulkerson, 2010).
0.934	[*A*]Extracting SIFT featuresThe SIFT algorithm for analyzing 2 D images[*R*]was implemented[*A*]in several stable software packages	context()	negated: False ,passive: True
0.887	[*A*]SIFT featuresThe SIFT algorithm[*R*]for analyzing[*A*]2 D images	context()	negated: False ,passive: False
[LINE#223] In this study, we used the SIFT algorithm provided in a publicly available computer vision software package vlFeat (Vedaldi and Fulkerson, 2010).
0.944	[*A*]the SIFT algorithm[*R*]provided[*A*]in a publicly available computer vision software package vlFeat	context()	negated: False ,passive: True
0.639	[*A*]we[*R*]used[*A*]the SIFT algorithm[*A*]In this study	context()	negated: False ,passive: False
[LINE#224] The SIFT features are described by center locations, scales, orientations and appearance matrices.
0.957	[*A*]The SIFT features[*R*]are described[*A*]by center locations, scales, orientations and appearance matrices	context()	negated: False ,passive: True
[LINE#225]  An example of SIFT features is shown in Fig..
0.953	[*A*]An example of SIFT features[*R*]is shown[*A*]in Fig	context()	negated: False ,passive: True
[LINE#226] The SIFT features are shown as circles in Fig. 2(a).
0.944	[*A*]The SIFT features[*R*]are shown[*A*]as circles in Fig	context()	negated: False ,passive: True
[LINE#227] Each circle represents a SIFT feature.
0.918	[*A*]Each circle[*R*]represents[*A*]a SIFT feature	context()	negated: False ,passive: False
[LINE#228] The center and radius of the circle represent the center location and the scale of the SIFT feature.
0.967	[*A*]The center and radius of the circle[*R*]represent[*A*]the center location and the scale of the SIFT feature	context()	negated: False ,passive: False
[LINE#229] The existence of a SIFT feature suggests that there is a blob-like image component at the center location of the SIFT feature and the scale of the feature represents the radius of the blob-like component.
0.851	[*A*]The existence of a SIFT feature[*R*]suggests[*A*]that there is a blob-like image component at the center location of the SIFT feature and the scale of the feature	context()	negated: False ,passive: False
[LINE#230] The image intensity distribution around the blob-like component is further characterized by an orientation and an appearance matrix.
0.945	[*A*]The image intensity distribution around the blob - like component[*R*]characterized[*A*]by an appearance matrix	context()	negated: False ,passive: True
0.964	[*A*]The image intensity distribution around the blob - like component[*R*]is[*A*]further characterized by an appearance matrix	context()	negated: False ,passive: True
0.945	[*A*]The image intensity distribution around the blob - like component[*R*]characterized[*A*]by an orientation	context()	negated: False ,passive: True
0.964	[*A*]The image intensity distribution around the blob - like component[*R*]is[*A*]further characterized by an orientation	context()	negated: False ,passive: True
[LINE#231] The orientation, as shown by the line starting from the center of the circle, represents the general direction of change in image intensity.
0.887	[*A*]The orientation[*R*]represents[*A*]the general direction of change in image intensity	context()	negated: False ,passive: False
0.903	[*A*]the line[*R*]starting[*A*]from the center of the circle	context()	negated: False ,passive: True
[LINE#232] The appearance matrix represents the detailed change in image intensity.
0.911	[*A*]The appearance matrix[*R*]represents[*A*]the detailed change in image intensity	context()	negated: False ,passive: False
[LINE#233]  An example of an appearance matrix is shown in Fig..
0.943	[*A*]An example of an appearance matrix[*R*]is shown[*A*]in Fig	context()	negated: False ,passive: True
[LINE#234] The square centered at the center location of a SIFT feature is divided into 16 subsquares.
0.993	[*A*]The square centered at the center location of a SIFT feature[*R*]is divided into[*A*]16 subsquares	context()	negated: False ,passive: False
0.968	[*A*]The square centered at the center location of a SIFT feature[*R*]is divided[*A*]into 16 subsquares	context()	negated: False ,passive: True
0.918	[*A*]The square[*R*]centered[*A*]at the center location of a SIFT feature	context()	negated: False ,passive: True
[LINE#235] There are 8 lines starting from the center of each subsquare along 8 different directions.
0.937	[*A*]8 lines[*R*]starting[*A*]from the center of each subsquare along 8 different directions	context()	negated: False ,passive: True
[LINE#236] The length of a line represents the number of pixels which have a gradient direction the same as the line, and some of the lines may have a length of zero.
0.919	[*A*]some of the lines[*R*]may have[*A*]a length of zero	context()	negated: False ,passive: False
0.877	[*A*]pixels[*R*]have[*A*]a gradient direction	context()	negated: False ,passive: False
0.926	[*A*]The length of a line[*R*]represents[*A*]the number of pixels	context()	negated: False ,passive: False
[LINE#237+238]  For example, many of the pixels in the lower left corner subsquare, as shown in Fig.2(b), have a gradient direction pointing to the lower side of the image; therefore the length of the line starting from the center of this subsquare and pointing to the lower side is long.
0.903	[*A*]the line[*R*]starting[*A*]from the center of this subsquare	context()	negated: False ,passive: True
0.911	[*A*]a gradient direction[*R*]pointing[*A*]to the lower side of the image	context()	negated: False ,passive: False
0.791	[*A*]the length of the line[*R*]is[*A*]long	context()	negated: False ,passive: True
0.965	[*A*]many of the pixels in the lower left corner subsquare[*R*]shown[*A*]in Fig.2	context()	negated: False ,passive: True
[LINE#239] The center location, scale, direction and appearance matrix of a SIFT feature can be organized as a vector of 133 numbers: the center location includes 3 numbers representing its coordinates in the 3D volume of the brain image; the scale and orientation is represented as one number respectively; the appearance matrix is represented by 128 numbers, 8 numbers for each of the 16 subsquares.
0.969	[*A*]The center location, scale, direction and appearance matrix of a SIFT feature[*R*]can be organized[*A*]as a vector of 133 numbers	context(the center location includes the scale and orientation is represented respectively the appearance matrix is represented)	negated: False ,passive: True
0.873	[*A*]the center location[*R*]includes[*A*]3 numbers representing its coordinates in the 3D volume of the brain image	context(the scale and orientation is represented respectively the appearance matrix is represented)	negated: False ,passive: True
0.894	[*A*]the scale and orientation[*R*]is represented respectively[*A*]as one number	context(the appearance matrix is represented)	negated: False ,passive: True
0.888	[*A*]the appearance matrix[*R*]is represented[*A*]by 128 numbers	context()	negated: False ,passive: True
0.890	[*A*]3 numbers[*R*]representing[*A*]its coordinates in the 3D volume of the brain image	context()	negated: False ,passive: False
[LINE#240] This vector form is used in the computation; while the isomorphic graph representation, as shown in Fig. 2, is used as a user friendly way of representing the SIFT features. .
0.891	[*A*]This vector form[*R*]is used[*A*]in the computation	context(while the isomorphic graph representation , as shown in Fig is used)	negated: False ,passive: True
0.973	[*A*]while the isomorphic graph representation, as shown in Fig[*R*]is used[*A*]as a user friendly way of representing the SIFT features	context()	negated: False ,passive: True
0.944	[*A*]while the isomorphic graph representation[*R*]shown[*A*]in Fig	context()	negated: False ,passive: True
[LINE#241] Feature evaluationThe extracted SIFT features were identified as one of the three feature types, namely patient feature, healthy feature and noise feature.
0.910	[*A*]SIFT features[*R*]were identified[*A*]as one of the three feature types	context(Feature evaluationThe extracted)	negated: False ,passive: True
0.924	[*A*]Feature evaluationThe[*R*]extracted[*A*]SIFT features	context()	negated: False ,passive: False
[LINE#242] The features were evaluated based on their frequencies of occurrence in patient brains and healthy brains.
0.835	[*A*]The features[*R*]were evaluated[*A*]based on their frequencies of occurrence in healthy brains	context()	negated: False ,passive: True
0.835	[*A*]The features[*R*]were evaluated[*A*]based on their frequencies of occurrence in patient brains	context()	negated: False ,passive: True
[LINE#243] There were two steps to evaluate the features, and each SIFT feature was evaluated separately.
0.803	[*A*]each SIFT feature[*R*]was evaluated separately	context()	negated: False ,passive: False
[LINE#244] The first step was to find all the other features that were similar to the feature that was being analyzed.
0.698	[*A*]the feature[*R*]was being analyzed	context()	negated: False ,passive: False
0.905	[*A*]all the other features[*R*]were[*A*]similar to the feature	context()	negated: False ,passive: True
0.836	[*A*]The first step[*R*]to find[*A*]all the other features that were similar to the feature	context()	negated: False ,passive: False
0.932	[*A*]The first step[*R*]was[*A*]to find all the other features	context()	negated: False ,passive: True
[LINE#245] The similarity between two features was measured by four criteria: the distance between the center locations x(i, j), the scale difference (i, j), the orientation difference o(i, j) and the difference between their appearance matrix a(i, j).
0.926	[*A*]The similarity between two features[*R*]was measured[*A*]by four criteria	context()	negated: False ,passive: True
[LINE#246+247+248+249]  They were defined as follows:(1)xij= xi was the center location of feature i, oi was the orientation angle of featurei and ai was the appearance matrix of feature i.
0.906	[*A*]oi[*R*]ai was[*A*]the appearance matrix of feature	context()	negated: False ,passive: True
0.938	[*A*]oi[*R*]was[*A*]the orientation angle of featurei	context()	negated: False ,passive: True
0.852	[*A*]xi[*R*]was[*A*]the center location of feature	context()	negated: False ,passive: True
0.361	[*A*]They[*R*]were defined[*A*]as follows	context()	negated: False ,passive: True
[LINE#250] If all the four differences were less than their corresponding threshold, two features were considered to be similar.
0.735	[*A*]two features[*R*]to be[*A*]similar	context()	negated: False ,passive: True
0.732	[*A*]two features[*R*]were considered	context()	negated: False ,passive: False
0.860	[*A*]all the four differences[*R*]were[*A*]less than their corresponding threshold	context()	negated: False ,passive: True
[LINE#251+252+253+254]  All the features that were similar to feature i constituted the similar feature set for feature i:(5)Si =fj:xij<xij<oij<oaij<awhereo and a were similarity thresholds for center locations, scales, orientations and appearance matrix, respectively.
0.388	[*A*]i[*R*]constituted[*A*]the similar feature set for feature	context(All the features to feature)	negated: False ,passive: False
0.784	[*A*]All the features[*R*]to feature[*A*]i constituted the similar feature	context()	negated: False ,passive: False
0.932	[*A*]the similar feature[*R*]set[*A*]for feature	context()	negated: False ,passive: True
0.825	[*A*]All the features[*R*]were[*A*]similar to feature i constituted the similar feature	context()	negated: False ,passive: True
[LINE#255] (2010), the thresholds x and  were set to 0.5 and 2/3 respectively.
0.263	[*A*]2010[*R*]were set[*A*]to 2/3[*A*]respectively	context()	negated: False ,passive: True
0.263	[*A*]2010[*R*]were set[*A*]to 0.5[*A*]respectively	context()	negated: False ,passive: True
[LINE#256] The thresholds o and a were set to /2 and 0.45 respectively based on a grid search (Chang and Lin, 2011).
0.503	[*A*]0.45[*R*]based[*A*]on a grid search	context()	negated: False ,passive: True
0.381	[*A*]a[*R*]were set[*A*]to / 2[*A*]respectively based on a grid search	context()	negated: False ,passive: True
0.887	[*A*]The thresholds[*R*]based[*A*]on a grid search	context()	negated: False ,passive: True
[LINE#257] Grid search is an efficient way to find the best parameter combinations, when there are multiple parameters in a model and the parameters are continuous variables.
0.903	[*A*]the parameters[*R*]are[*A*]continuous variables	context()	negated: False ,passive: True
0.952	[*A*]Grid search[*R*]is[*A*]an efficient way to find the best parameter combinations ,	context()	negated: False ,passive: True
0.925	[*A*]Grid search[*R*]is[*A*]an efficient way to find the best parameter combinations	context()	negated: False ,passive: True
[LINE#258] First, we discretized the continuous parameters.
0.595	[*A*]we[*R*]discretized[*A*]the continuous parameters[*A*]First	context()	negated: False ,passive: False
[LINE#259] Parameter o was discretized into three discrete values [/4, 2/4, 3/4], and parameter a was discretized into five discrete values [0.3, 0.35, 0.4, 0.45, 0.5].
0.903	[*A*]parameter a[*R*]was discretized[*A*]into five discrete values	context()	negated: False ,passive: True
0.906	[*A*]Parameter[*R*]was discretized[*A*]into three discrete values	context()	negated: False ,passive: True
[LINE#260] Then all the combinations of these discrete values, 15 combinations in total, were tried and the parameter combination with the highest classification accuracy was chosen as the best parameter setting.
0.943	[*A*]the parameter combination with the highest classification accuracy[*R*]was chosen[*A*]as the best parameter setting	context()	negated: False ,passive: True
0.916	[*A*]all the combinations of these discrete values , 15 combinations in total[*R*]were tried[*A*]Then	context()	negated: False ,passive: True
[LINE#261] The second step for feature evaluation was to assign likelihood scores to the SIFT features.
0.956	[*A*]The second step for feature evaluation[*R*]was[*A*]to assign likelihood scores to the SIFT features	context()	negated: False ,passive: True
[LINE#262]  The likelihood score was defined as follows:(6)Li=lnSiP/NPSiC/.
0.751	[*A*]The likelihood score[*R*]was defined	context()	negated: False ,passive: False
[LINE#263+264]  Si was the similar feature set for, P was the patient feature set which included all the SIFT features extracted from all patient brains in the training set, C was the healthy feature set including all the SIFT features from all healthy brains in the training set, NP and NC was the number of patient brains and the number of healthy control brains in the training set, respectively.
0.906	[*A*]NC[*R*]was[*A*]the number of the number of healthy control brains in the training set[*A*]respectively	context()	negated: False ,passive: True
0.858	[*A*]Si[*R*]was[*A*]the similar feature set for	context(P was C was NC was)	negated: False ,passive: True
0.896	[*A*]P[*R*]was[*A*]the patient feature set which included all the SIFT features	context(C was NC was)	negated: False ,passive: True
0.921	[*A*]C[*R*]was[*A*]the healthy feature set including all the SIFT features from all healthy brains in the training set	context(NC was)	negated: False ,passive: True
0.858	[*A*]NC[*R*]was[*A*]the number of patient brains[*A*]respectively	context()	negated: False ,passive: True
0.906	[*A*]NP[*R*]was[*A*]the number of the number of healthy control brains in the training set[*A*]respectively	context()	negated: False ,passive: True
0.858	[*A*]Si[*R*]was[*A*]the similar feature set for	context(P was C was NP was)	negated: False ,passive: True
0.896	[*A*]P[*R*]was[*A*]the patient feature set which included all the SIFT features	context(C was NP was)	negated: False ,passive: True
0.921	[*A*]C[*R*]was[*A*]the healthy feature set including all the SIFT features from all healthy brains in the training set	context(NP was)	negated: False ,passive: True
0.858	[*A*]NP[*R*]was[*A*]the number of patient brains[*A*]respectively	context()	negated: False ,passive: True
0.939	[*A*]all the SIFT features[*R*]extracted[*A*]from all patient brains in the training set	context()	negated: False ,passive: True
0.920	[*A*]the patient feature set[*R*]included[*A*]all the SIFT features	context()	negated: False ,passive: True
0.828	[*A*]the similar feature[*R*]set[*A*]for	context()	negated: False ,passive: True
[LINE#265] A SIFT feature was identified as a patient feature if Li was larger than a threshold l; it was a healthy feature if Li was smaller than -l; it was a noise feature otherwise.
0.928	[*A*]A SIFT feature[*R*]was identified[*A*]as a patient feature[*A*]if Li was larger than a threshold l	context(it was it was)	negated: False ,passive: True
0.503	[*A*]it[*R*]was[*A*]a healthy feature[*A*]if Li was smaller	context(it was)	negated: False ,passive: True
0.457	[*A*]it[*R*]was[*A*]a noise feature[*A*]otherwise	context()	negated: False ,passive: True
0.887	[*A*]Li[*R*]was[*A*]smaller than -l	context()	negated: False ,passive: True
0.887	[*A*]Li[*R*]was[*A*]larger than a threshold l	context()	negated: False ,passive: True
[LINE#266] Formally, the class labels of the features were determined as follows:(7)Ci=1,Li>l0,Lil-1,Li<-lwhere l was the threshold for likelihood scores.
0.943	[*A*]the class labels of the features[*R*]were determined[*A*]as follows:(7)Ci=1,Li	context()	negated: False ,passive: True
[LINE#267] We used grid search to determine the best parameter setting.
0.388	[*A*]We[*R*]used grid search to determine[*A*]the best parameter setting	context(We used)	negated: False ,passive: False
0.388	[*A*]We[*R*]used[*A*]grid search[*A*]to determine the best parameter setting	context()	negated: False ,passive: False
[LINE#268] For the threshold, the value from 0.1 to 1.2 with a step size of 0.1 was searched.
0.973	[*A*]the value from 0.1 to 1.2 with a step size of 0.1[*R*]was searched[*A*]For the threshold	context()	negated: False ,passive: True
[LINE#269+270]  After the grid search, l was set to be 0.9.According to the above feature evaluation process, we need to find the similar feature set for every feature ((5)), which requires comparing this feature with all other features.
0.932	[*A*]the similar feature[*R*]set[*A*]for every feature	context()	negated: False ,passive: True
0.514	[*A*]we[*R*]need to find[*A*]the similar feature set for every feature ((5)),	context(we need)	negated: False ,passive: False
0.397	[*A*]we[*R*]need[*A*]to find the similar feature	context()	negated: False ,passive: False
0.786	[*A*]l[*R*]to be 0.9.According[*A*]to the above feature evaluation process	context()	negated: False ,passive: False
0.887	[*A*]every feature[*R*]requires[*A*]comparing this feature with all other features	context()	negated: False ,passive: False
0.886	[*A*]l[*R*]was set[*A*]to be 0.9.According to the above feature evaluation process[*A*]After the grid search	context()	negated: False ,passive: True
[LINE#271] For more than 105 features in 39 brains, it would require 1010 pair-wise distance calculations, which is a very slow process.
0.999	[*A*]it[*R*]would require[*A*]1010 pair - wise distance calculations	context()	negated: False ,passive: False
0.927	[*A*]1010 pair-wise distance calculations[*R*]is[*A*]a very slow process	context()	negated: False ,passive: True
0.702	[*A*]it[*R*]would require[*A*]1010 pair-wise distance calculations, which is a very slow process[*A*]For more than 105 features in 39 brains	context()	negated: False ,passive: False
[LINE#272] Upon those observations, we divided the whole brain volume into small cubes.
0.350	[*A*]we[*R*]divided[*A*]the whole brain volume[*A*]into small cubes[*A*]Upon those observations	context()	negated: False ,passive: False
[LINE#273] For the evaluation of a feature, we only calculated its distance to the other features in the same cube.
0.274	[*A*]we[*R*]calculated[*A*]its distance[*A*]to the other features in the same cube	context()	negated: False ,passive: False
[LINE#274] In this way, the computation time is significantly reduced, but the classification accuracy may be adversely affected.
0.751	[*A*]the classification accuracy[*R*]may be adversely affected	context()	negated: False ,passive: False
0.779	[*A*]the computation time[*R*]is reduced[*A*]significantly	context()	negated: False ,passive: True
[LINE#275] For example, a feature close to cube boundaries may have some of its similar features (Eq.
0.882	[*A*]a feature close to cube boundaries[*R*]may have[*A*]some of its similar features	context()	negated: False ,passive: False
[LINE#276]  Ignoring those similar features in adjacent cubes could lead to an inaccurate likelihood score (.
0.938	[*A*]Ignoring those similar features in adjacent cubes[*R*]could lead[*A*]to an inaccurate likelihood score	context()	negated: False ,passive: False
[LINE#277] This issue is especially serious when the number of training samples is limited as in our project.
0.900	[*A*]the number of training samples[*R*]is[*A*]limited as in our project	context()	negated: False ,passive: True
0.915	[*A*]This issue[*R*]is[*A*]especially serious[*A*]when the number of training samples is limited as in our project	context()	negated: False ,passive: True
[LINE#278] On the other hand, a larger cube size would have fewer features close to cube boundaries, and would result in more accurate likelihood scores and hence higher classification accuracy.
0.905	[*A*]a larger cube size[*R*]would result[*A*]in more accurate hence higher classification accuracy	context()	negated: False ,passive: True
0.905	[*A*]a larger cube size[*R*]would result[*A*]in more accurate likelihood scores	context()	negated: False ,passive: True
0.919	[*A*]a larger cube size[*R*]would have[*A*]fewer features	context()	negated: False ,passive: False
[LINE#279] According to our previous experience from the application of this algorithm to the classification of several other diseases, such as Parkinson's disease, Alzheimer's disease and bipolar disorder, 202020 was considered to be an appropriate cube size.
0.503	[*A*]202020[*R*]to be[*A*]an appropriate cube size	context()	negated: False ,passive: True
[LINE#280]  This cube size 202020, determined based on adult-sized brains in our previous studies, was used directly for the infant brains in the present study, since our infant brains were normalized using the infant template and the infant template was enlarged to the size very close to that of adult brains.
0.363	[*A*]our infant brains[*R*]were normalized	context()	negated: False ,passive: False
0.905	[*A*]This cube size 202020[*R*]was used directly[*A*]for the infant brains in the present study	context()	negated: False ,passive: True
[LINE#281] Training SVM classifiersWe trained a linear SVM for every set of 2D slices in every cube to classify the set of SIFT features extracted from this set of 2D slices across subjects into 3 categories.
0.949	[*A*]SVM classifiersWe[*R*]trained[*A*]a linear SVM[*A*]for every set of 2D slices in every cube	context()	negated: False ,passive: False
0.927	[*A*]SIFT features[*R*]extracted[*A*]from this set of 2D slices across subjects	context()	negated: False ,passive: True
[LINE#282] For a new SIFT feature from a brain image whose class-label is unknown, the corresponding SVM is expected to be able to predict the class label of this new SIFT feature without finding its similar feature set in the huge amount of SIFT features extracted from the brain images used for training. .
0.934	[*A*]the corresponding SVM[*R*]to predict[*A*]the class label of this new SIFT feature	context()	negated: False ,passive: False
0.911	[*A*]the brain images[*R*]used[*A*]for training	context()	negated: False ,passive: True
0.925	[*A*]the corresponding SVM[*R*]to be[*A*]able to predict the class label of this new SIFT feature without finding its similar feature	context()	negated: False ,passive: True
0.927	[*A*]SIFT features[*R*]extracted[*A*]from the brain images	context()	negated: False ,passive: True
0.803	[*A*]the corresponding SVM[*R*]is expected	context()	negated: False ,passive: False
0.756	[*A*]its similar feature[*R*]set[*A*]in the huge amount of SIFT features	context()	negated: False ,passive: True
0.841	[*A*]whose class-label[*R*]is[*A*]unknown	context()	negated: False ,passive: True
[LINE#283+284]  Predicting new subjectsTo predict a new subject to be NH or HI, the subject's sMRI scan was first normalized to the standard space using SPM8 with the infant T1 template (.
0.925	[*A*]the standard space[*R*]using[*A*]SPM8[*A*]with the infant T1 template	context()	negated: False ,passive: False
0.925	[*A*]a new subject[*R*]to be[*A*]NH or HI	context()	negated: False ,passive: True
[LINE#285] The normalized brain was divided into cubes and sliced along three orientations as described above.
0.911	[*A*]The normalized brain[*R*]was sliced[*A*]along three orientations[*A*]as described above	context()	negated: False ,passive: True
0.911	[*A*]The normalized brain[*R*]was divided[*A*]into cubes	context()	negated: False ,passive: True
[LINE#286] SIFT features were extracted and then classified using the SVM that was trained for the same cube and same slice orientation.
0.846	[*A*]the SVM[*R*]was trained[*A*]for the same slice orientation	context()	negated: False ,passive: True
0.846	[*A*]the SVM[*R*]was trained[*A*]for the same cube	context()	negated: False ,passive: True
0.732	[*A*]SIFT features[*R*]were extracted	context()	negated: False ,passive: False
[LINE#287] After all the SIFT features were classified, we counted the number of features of the three types.
0.595	[*A*]we[*R*]counted[*A*]the number of features of the three types[*A*]After all the SIFT features were classified	context()	negated: False ,passive: False
0.769	[*A*]all the SIFT features[*R*]were classified	context()	negated: False ,passive: False
[LINE#288] The total number of noise features was not used in the final decision process.
0.932	[*A*]The total number of noise features[*R*]was not used[*A*]in the final decision process	context()	negated: True ,passive: True
[LINE#289]  The new subject was classified according to the following equation:(8)Classlabel=.
0.911	[*A*]The new subject[*R*]was classified[*A*]according to the following equation	context()	negated: False ,passive: True
[LINE#290] HI,ifCsum>sNH,otherwisewhere Csum=iC^i, C^i is the predicted class label of the i-th SIFT feature as shown in Eq.
0.891	[*A*]C^i[*R*]is[*A*]the predicted class label of the i-th SIFT feature	context()	negated: False ,passive: True
[LINE#291] (7), s is a threshold for the final classification of sMRI and its value is determined based on the method described in section Validation of the classifier. .
0.903	[*A*]the method[*R*]described[*A*]in section Validation of the classifier	context()	negated: False ,passive: True
0.341	[*A*]its value[*R*]is determined	context()	negated: False ,passive: False
0.874	[*A*]s[*R*]is[*A*]a threshold for the final classification of sMRI	context()	negated: False ,passive: True
[LINE#292+293]  Feature extraction and model learning based on functional MR imagesFor fMRI images, we constructed contrast maps using the General Linear Model (GLM) (Worsley et al., 2002) as described in the Data acquisition and preprocessing section.
[LINE#294] Contrast values were estimated from the difference in image intensity for each voxel between two conditions.
0.937	[*A*]Contrast values[*R*]were estimated[*A*]from the difference in image intensity for each voxel between two conditions	context()	negated: False ,passive: True
[LINE#295] A positive contrast value indicated that brain activation was higher in the first condition when compared to the second condition, while a negative contrast value suggested a lower activation in the first condition.
0.941	[*A*]brain activation[*R*]was[*A*]higher[*A*]while a negative contrast value suggested a lower activation in the first condition	context(A positive contrast value indicated)	negated: False ,passive: True
0.841	[*A*]A positive contrast value[*R*]indicated[*A*]that brain activation was higher in the first condition when compared to the second condition, while a negative contrast value suggested a lower activation in the first condition	context()	negated: False ,passive: False
0.919	[*A*]a negative contrast value[*R*]suggested[*A*]a lower activation in the first condition	context()	negated: False ,passive: False
[LINE#296] We generated region-level features and proposed a novel approach to vectorize the contrast maps utilizing the "bag-of-words" strategy (Sivic and Zisserman, 2009)..
0.911	[*A*]the contrast maps[*R*]utilizing[*A*]the " bag - of - words	context()	negated: False ,passive: False
0.911	[*A*]the contrast maps[*R*]utilizing[*A*]the " bag - of - words " strategy	context()	negated: False ,passive: False
0.452	[*A*]We[*R*]proposed[*A*]a novel approach to vectorize the contrast maps	context()	negated: False ,passive: False
0.452	[*A*]We[*R*]generated[*A*]region - level features	context()	negated: False ,passive: False
[LINE#297+298]  Feature generation from contrastmapsNormalized Z-maps were thresholded to select voxels with extreme contrast values for subsequent analysis.
0.945	[*A*]Feature generation from contrastmapsNormalized Z-maps[*R*]to select[*A*]voxels with extreme contrast values for subsequent analysis	context()	negated: False ,passive: False
0.970	[*A*]Feature generation from contrastmapsNormalized Z-maps[*R*]were thresholded[*A*]to select voxels with extreme contrast values for subsequent analysis	context()	negated: False ,passive: True
[LINE#299] Among the selected voxels, we connected the voxels which were adjacent to each other in a 3D neighborhood, in which each voxel had 26 neighbors if it was not on the border.
0.452	[*A*]it[*R*]was not[*A*]on the border	context()	negated: True ,passive: True
0.923	[*A*]each voxel[*R*]had[*A*]26 neighbors[*A*]if it was not on the border[*A*]a 3D neighborhood	context()	negated: False ,passive: False
0.887	[*A*]the voxels[*R*]were[*A*]adjacent to each other[*A*]in a 3D neighborhood	context()	negated: False ,passive: True
0.702	[*A*]we[*R*]connected[*A*]the voxels which were adjacent to each other in a 3D neighborhood,[*A*]Among the selected voxels	context()	negated: False ,passive: False
[LINE#300] As a result, the selected voxels were merged into a set of disjoint regions, each of which was defined as a region of interest (ROI) (Dykstra, 1994; Pokrajac et al., 2005).
0.592	[*A*]each of which[*R*]was defined[*A*]as a region of interest (ROI	context()	negated: False ,passive: True
0.911	[*A*]the selected voxels[*R*]were merged[*A*]into a set of disjoint regions	context()	negated: False ,passive: True
[LINE#301] To prevent mixing positive voxels and negative voxels in a single ROI, which could negate the signal, we considered these two categories of voxels separately.
0.897	[*A*]a single ROI[*R*]could negate[*A*]the signal	context()	negated: False ,passive: False
[LINE#302] Positive voxels were ranked decreasingly whereas negative voxels were ranked increasingly according to their activation magnitudes.
0.835	[*A*]negative voxels[*R*]were ranked[*A*]increasingly[*A*]according to their activation magnitudes	context()	negated: False ,passive: True
0.890	[*A*]Positive voxels[*R*]were ranked[*A*]decreasingly[*A*]whereas negative voxels were ranked increasingly according to their activation magnitudes	context()	negated: False ,passive: True
[LINE#303] Only the top 5% of each category were selected.
0.830	[*A*]Only the top 5% of each category[*R*]were selected	context()	negated: False ,passive: False
[LINE#304] The cutoff of 5% was chosen because it outperformed other cutoffs, 1% and 10%, with respect to the classification performance.
0.915	[*A*]The cutoff of 5 %[*R*]was chosen[*A*]because it outperformed other cutoffs , 1 10 % , with respect to the classification performance	context()	negated: False ,passive: True
0.452	[*A*]it[*R*]outperformed[*A*]other cutoffs	context()	negated: False ,passive: False
0.915	[*A*]The cutoff of 5 %[*R*]was chosen[*A*]because it outperformed other cutoffs , 1 % , with respect to the classification performance	context()	negated: False ,passive: True
[LINE#305] In this way, a number of ROIs were delineated to characterize the pattern of a contrast map.
0.928	[*A*]a number of ROIs[*R*]to characterize[*A*]the pattern of a contrast map	context()	negated: False ,passive: False
0.965	[*A*]a number of ROIs[*R*]were delineated[*A*]to characterize the pattern of a contrast map[*A*]In this way	context()	negated: False ,passive: True
[LINE#306] Due to individual differences and random noise, however, the set of ROIs delineated from different subjects varied significantly.
0.818	[*A*]the set of ROIs[*R*]delineated	context()	negated: False ,passive: False
[LINE#307] To address this problem, we delineated a set of ROIs based on each subject, and applied all ROIs derived from all subjects to each single subject to form a long vector for each subject, with each dimension representing the mean contrast value over all voxels within the corresponding ROI.
0.910	[*A*]all ROIs[*R*]derived[*A*]from all subjects to each single subject	context(we applied)	negated: False ,passive: True
0.518	[*A*]we[*R*]applied[*A*]all ROIs derived from all subjects to each single subject to form a long vector for each subject, with each dimension	context()	negated: False ,passive: False
0.433	[*A*]we[*R*]delineated[*A*]a set of ROIs	context()	negated: False ,passive: False
0.914	[*A*]all ROIs[*R*]to form[*A*]a long vector for each subject	context()	negated: False ,passive: False
0.937	[*A*]each dimension[*R*]representing[*A*]the mean contrast value over all voxels within the corresponding ROI	context()	negated: False ,passive: False
[LINE#308] Finally, we concatenated the vectors from the three contrast maps, and obtained a 1474-dimension vector for each subject.
0.999	[*A*]we[*R*]obtained[*A*]1474 - dimension vector	context()	negated: False ,passive: False
0.595	[*A*]we[*R*]obtained[*A*]a 1474 - dimension vector for each subject[*A*]Finally	context()	negated: False ,passive: False
0.595	[*A*]we[*R*]concatenated[*A*]the vectors[*A*]from the three contrast maps[*A*]Finally	context()	negated: False ,passive: False
[LINE#309] In other words, each significantly activated/deactivated region was treated as a word, and all words occurring across all subjects constituted the dictionary.
0.932	[*A*]all words occurring across all subjects[*R*]constituted[*A*]the dictionary	context()	negated: False ,passive: False
0.903	[*A*]all words[*R*]occurring[*A*]across all subjects	context()	negated: False ,passive: True
0.932	[*A*]each significantly activated / deactivated region[*R*]was treated[*A*]as a word	context()	negated: False ,passive: True
[LINE#310] The frequency of each word was measured by the mean contrast value.
0.926	[*A*]The frequency of each word[*R*]was measured[*A*]by the mean contrast value	context()	negated: False ,passive: True
[LINE#311+312]  An intuitive view of the contrast map vectorization process is shown in Fig. we performed ROI detection on each contrast map and then concatenated all the ROIs together,.
0.764	[*A*]An intuitive[*R*]concatenated together[*A*]then	context()	negated: False ,passive: False
0.944	[*A*]An intuitive view of the contrast map vectorization process[*R*]is shown[*A*]in Fig	context(we performed)	negated: False ,passive: True
0.388	[*A*]we[*R*]performed[*A*]ROI detection[*A*]on each contrast map	context()	negated: False ,passive: False
[LINE#313] ROIs that were consistent among subjects were detected more than once.
0.829	[*A*]ROIs that were consistent among subjects[*R*]were detected[*A*]more than once	context()	negated: False ,passive: True
0.877	[*A*]ROIs[*R*]were[*A*]consistent among subjects	context()	negated: False ,passive: True
[LINE#314] To merge those similar ROIs into one single feature, we performed a hierarchical clustering with average linkage (Johnson, 1967).
0.452	[*A*]we[*R*]performed[*A*]a hierarchical clustering	context()	negated: False ,passive: False
[LINE#315+316+317]  The original space was represented as:(9)S1, 1S1, 1474SN1SN1474where each row represents a training sample and each column represents a ROI, S(i,j) is the mean contrast value of ROI j for subjecti, N is the total number of subjects.
0.425	[*A*]i[*R*]is[*A*]the mean contrast value of ROI j for subjecti	context(N is)	negated: False ,passive: True
0.908	[*A*]The original space[*R*]was represented[*A*]as:(9)S1, 1S1	context(N is)	negated: False ,passive: True
0.862	[*A*]N[*R*]is[*A*]the total number of subjects	context()	negated: False ,passive: True
0.903	[*A*]each column[*R*]represents[*A*]a ROI	context()	negated: False ,passive: False
[LINE#318] The distance between two ROIs was calculated as the Euclidean distance:(10)distROIiROIj=k=1NSki-Skj2We cut the hierarchical tree with the inconsistency coefficient of 0.01, and calculated the mean value of the ROIs that were clustered together as the value of the joint feature.
0.940	[*A*]the mean value of the ROIs[*R*]were clustered together[*A*]as the value of the joint feature	context()	negated: False ,passive: True
0.879	[*A*]distROIiROIj=k=1NSki-Skj2We[*R*]calculated[*A*]the mean value of the ROIs	context()	negated: False ,passive: False
0.905	[*A*]distROIiROIj=k=1NSki-Skj2We[*R*]cut[*A*]the hierarchical tree[*A*]with the inconsistency coefficient of 0.01	context()	negated: False ,passive: False
0.970	[*A*]The distance between two ROIs[*R*]was calculated[*A*]as the Euclidean distance[*A*]10)distROIiROIj=k=1NSki-Skj2We cut the hierarchical tree with the inconsistency coefficient of 0.01, and calculated the mean value of the ROIs	context()	negated: False ,passive: True
[LINE#319] The cutoff of 0.01 was easily determined since the cluster results did not change in the cutoff range from 0.01 to 0.7.
0.751	[*A*]the cluster results[*R*]did not change[*A*]from 0.01 to 0.7	context()	negated: True ,passive: True
0.948	[*A*]The cutoff of 0.01[*R*]was easily determined[*A*]since the cluster results did not change in the cutoff range from 0.01 to 0.7	context()	negated: False ,passive: True
[LINE#320] After hierarchical clustering, the dimensionality was reduced to 969. .
0.993	[*A*]the dimensionality[*R*]was reduced to[*A*]969	context()	negated: False ,passive: False
0.943	[*A*]the dimensionality[*R*]was reduced[*A*]to 969[*A*]After hierarchical clustering	context()	negated: False ,passive: True
[LINE#321] Sedation methodSubjects were sedated with three different sedation methods during the MRI scanning.
0.918	[*A*]Sedation methodSubjects[*R*]were sedated[*A*]with three different sedation methods during the MRI scanning	context()	negated: False ,passive: True
[LINE#322] Different sedation methods were expected to affect the activation pattern differently (DiFrancesco et al., in press).
0.894	[*A*]Different sedation methods[*R*]to affect differently[*A*]the activation pattern	context()	negated: False ,passive: False
0.751	[*A*]Different sedation methods[*R*]were expected	context()	negated: False ,passive: False
[LINE#323] Therefore, we added sedation method as an additional feature, which was represented as a 3D binary vector(11)100010001.As shown in the matrix defined in Eq.
0.918	[*A*]the matrix[*R*]defined[*A*]in Eq	context()	negated: False ,passive: True
0.918	[*A*]100010001.As[*R*]shown[*A*]in the matrix	context()	negated: False ,passive: True
0.897	[*A*]an additional feature[*R*]was represented[*A*]as a 3D binary vector	context()	negated: False ,passive: True
0.452	[*A*]we[*R*]added[*A*]sedation method as an additional feature	context()	negated: False ,passive: False
[LINE#324] (11), each row of the matrix represented one of the three sedation methods.
0.926	[*A*]each row of the matrix[*R*]represented[*A*]one of the three sedation methods	context()	negated: False ,passive: False
[LINE#325] In this way, we represented each subject as a 972-dimension feature vector, including 969 features from the contrast maps after hierarchical clustering and 3 binary features from sedation method.
0.452	[*A*]we[*R*]represented[*A*]each subject	context()	negated: False ,passive: False
[LINE#326] Therefore, our dataset was represented as D defined in Eq.
0.840	[*A*]D[*R*]defined[*A*]in Eq	context()	negated: False ,passive: True
0.638	[*A*]our dataset[*R*]was represented[*A*]as D	context()	negated: False ,passive: True
[LINE#327+328]  (12):(12)D=x1y1,,xiyi,x39y39|xiR972where x(i) and y(i) was the feature vector and group label (NH or HI)for the i-th subject, respectively.
0.962	[*A*]|xiR972where x(i) and y[*R*]was[*A*]the feature vector and group label[*A*]respectively	context()	negated: False ,passive: True
[LINE#329] This dataset D was used for subsequent feature selection and model learning. .
0.911	[*A*]This dataset D[*R*]was used[*A*]for model learning	context()	negated: False ,passive: True
0.911	[*A*]This dataset D[*R*]was used[*A*]for subsequent feature selection	context()	negated: False ,passive: True
[LINE#330] Feature selection and model learningThe WEKA software package was utilized to select a subset of features that were highly correlated with class labels and uncorrelated with each other (Hall, 1999).
0.771	[*A*]a subset of features[*R*]were[*A*]uncorrelated with each other	context()	negated: False ,passive: True
0.901	[*A*]learningThe WEKA software package[*R*]to select[*A*]a subset of features that were uncorrelated with each other ( Hall , 1999 )	context()	negated: False ,passive: False
0.677	[*A*]features[*R*]were highly correlated	context()	negated: False ,passive: False
0.928	[*A*]learningThe WEKA software package[*R*]to select[*A*]a subset of features	context()	negated: False ,passive: False
0.939	[*A*]learningThe WEKA software package[*R*]was utilized[*A*]to select a subset of features	context()	negated: False ,passive: True
[LINE#331+332]  The merit of a subset of features was measured as:(13)MSkrcfk+kk-1rffwhere rcf was the mean correlation between class label and selected features, rff was the mean correlation between two features, k was the number of features in subset S. Greedy hill-climbing augmented with a backtracking facility was applied to search through the space of feature subsets (Dechter and Pearl, 1985).
0.857	[*A*]the number of features in subset S. Greedy hill-climbing[*R*]was applied	context(k was)	negated: False ,passive: False
0.959	[*A*]The merit of a subset of features[*R*]was measured[*A*]as:(13)MSkrcfk+kk-1rffwhere rcf was the mean correlation between class label and selected features	context(rff was k was)	negated: False ,passive: True
0.862	[*A*]rff[*R*]was[*A*]the mean correlation between two features	context(k was)	negated: False ,passive: True
0.899	[*A*]k[*R*]was[*A*]the number of features in subset S. Greedy hill-climbing augmented with a backtracking facility was applied to search through the space of feature subsets (Dechter and Pearl, 1985	context()	negated: False ,passive: True
0.962	[*A*]the number of features in subset S. Greedy hill-climbing[*R*]to search[*A*]through the space of feature subsets	context()	negated: False ,passive: True
0.953	[*A*]MSkrcfk+kk-1rffwhere rcf[*R*]was[*A*]the mean correlation between class label and selected features	context()	negated: False ,passive: True
0.949	[*A*]subset S. Greedy hill-climbing[*R*]augmented[*A*]with a backtracking facility	context()	negated: False ,passive: True
[LINE#333] For explanation purposes, we can imagine that there was a rooted tree, which had included all possible feature subsets.
0.112	[*A*]we[*R*]can imagine[*A*]that there was a rooted tree	context()	negated: False ,passive: False
0.897	[*A*]a rooted tree[*R*]had included[*A*]all possible feature subsets	context()	negated: False ,passive: True
[LINE#334] In this tree, each node was a feature subset, which was represented as a 972 dimensional binary vector, with 1(0) indicating that the corresponding feature was (not) selected.
0.612	[*A*]the corresponding feature[*R*]was not[*A*]selected	context(1 ( 0 indicating)	negated: True ,passive: True
0.264	[*A*]1(0[*R*]indicating[*A*]that the corresponding feature was (not) selected	context()	negated: False ,passive: False
0.897	[*A*]a feature subset[*R*]was represented[*A*]as a 972 dimensional binary vector	context()	negated: False ,passive: True
0.718	[*A*]the corresponding feature[*R*]selected	context()	negated: False ,passive: False
0.928	[*A*]each node[*R*]was[*A*]a feature subset, which was represented as a 972 dimensional binary vector, with 1(0) indicating that the corresponding feature was (not) selected[*A*]In this tree	context()	negated: False ,passive: True
[LINE#335] Each node had 972 successors/children, each of which was generated by flipping one of the 972 dimensions of the current node.
0.516	[*A*]Each node[*R*]had successors of[*A*]972 successors /	context()	negated: False ,passive: False
0.999	[*A*]Each node[*R*]had[*A*]972 successors /	context()	negated: False ,passive: False
0.551	[*A*]each of which[*R*]by flipping[*A*]one of the 972 dimensions of the current node	context()	negated: False ,passive: False
0.699	[*A*]each of which[*R*]was generated[*A*]by flipping one of the 972 dimensions of the current node	context()	negated: False ,passive: True
0.952	[*A*]Each node[*R*]had[*A*]972 successors/children, each of which was generated by flipping one of the 972 dimensions of the current node	context()	negated: False ,passive: False
[LINE#336] Our goal was to step through this tree to find a node with relatively high Ms.
0.819	[*A*]Our goal[*R*]was[*A*]to step through this tree to find a node with relatively high Ms.	context()	negated: False ,passive: True
[LINE#337] In practice, the whole tree would not be constructed because it was unlimited.
0.278	[*A*]it[*R*]was[*A*]unlimited	context()	negated: False ,passive: True
0.848	[*A*]the whole tree[*R*]would not be constructed[*A*]because it was unlimited	context()	negated: True ,passive: True
[LINE#338] Only the successors were generated whenever needed.
0.783	[*A*]Only the successors[*R*]were generated[*A*]whenever needed	context()	negated: False ,passive: True
[LINE#339] The search started from the root, which was the empty set of features in our project, and repeatedly chose the successor with the highest Ms at each node.
0.903	[*A*]The search[*R*]repeatedly chose[*A*]the successor with the highest Ms at each node	context()	negated: False ,passive: False
0.850	[*A*]the root[*R*]was[*A*]the empty set of features in our project	context()	negated: False ,passive: True
0.903	[*A*]The search[*R*]started[*A*]from the root	context()	negated: False ,passive: True
[LINE#340] The search terminated when 5 consecutive non-improving steps occurred.
0.769	[*A*]5 consecutive non-improving steps[*R*]occurred	context()	negated: False ,passive: False
0.903	[*A*]The search[*R*]terminated[*A*]when 5 consecutive non-improving steps occurred	context()	negated: False ,passive: False
[LINE#341] With the selected subset of features, we trained a linear SVM classifier (Chang and Lin, 2011). .
0.498	[*A*]we[*R*]trained[*A*]a linear SVM classifier	context()	negated: False ,passive: False
[LINE#342+343]  Predicting new subjectsGiven a new subject, we first normalized the contrast maps to the infant template space(Altaye et al., 2008), so that the given contrast maps were registered with the training contrast maps.
0.919	[*A*]the given contrast maps[*R*]were registered[*A*]with the training contrast maps	context()	negated: False ,passive: True
0.554	[*A*]we[*R*]normalized[*A*]the contrast maps to the infant template space[*A*]first	context()	negated: False ,passive: False
[LINE#344] A 972-D feature vector was then constructed with procedures described above, which was subsequently filtered based on the feature selection results obtained from the training set.
0.992	[*A*]972 - d feature vector[*R*]was constructed with[*A*]procedures described above which was subsequently filtered based on the feature selection results obtained from the training set	context()	negated: False ,passive: False
0.919	[*A*]the feature selection results[*R*]obtained[*A*]from the training set	context()	negated: False ,passive: True
0.910	[*A*]procedures described above[*R*]was filtered[*A*]based on the feature selection results[*A*]subsequently	context()	negated: False ,passive: True
0.941	[*A*]A 972-D feature vector[*R*]was constructed[*A*]with procedures[*A*]then	context()	negated: False ,passive: True
[LINE#345] Finally, the formatted feature vector was fed to the trained classifier, yielding a decision score (fMRI_score) for the new subject based on the functional MRI data alone.
0.925	[*A*]the new subject[*R*]based[*A*]on the functional MRI data alone	context()	negated: False ,passive: True
0.949	[*A*]the formatted feature vector[*R*]yielding[*A*]a decision score (fMRI_score) for the new subject	context()	negated: False ,passive: False
0.975	[*A*]the formatted feature vector[*R*]was fed[*A*]to the trained classifier[*A*]yielding a decision score (fMRI_score) for the new subject[*A*]Finally	context()	negated: False ,passive: True
[LINE#346]  The rule for classification was formulated as:(14)Classlabel=.
0.931	[*A*]The rule for classification[*R*]was formulated[*A*]as:(14)Classlabel=	context()	negated: False ,passive: True
[LINE#347] HI,iffMRI_scorefNH,otherwise. .
[LINE#348+349+350]  Important featuresThe importance of a feature was measured as follows:(15)If=i=1Niwifwhere || was the absolute value function, N was the total number of folds of cross-validation as described in the following part, wif was the SVM weight for feature f during i-th fold of cross-validation, i=1 if the feature f was selected in the i-th fold of cross-validation.
0.480	[*A*]i[*R*]th fold[*A*]of cross-validation	context()	negated: False ,passive: False
0.920	[*A*]Important featuresThe importance of a feature[*R*]was measured[*A*]as follows:(15)If=i=1Niwifwhere || was the absolute value function, N was the total number of folds of cross-validation as described in the following part, wif was the SVM weight for feature f during i-th fold of cross-validation	context(N was wif was)	negated: False ,passive: True
0.868	[*A*]N[*R*]was[*A*]the total number of folds of cross-validation as described in the following part, wif was the SVM weight for feature f during i-th fold of cross-validation, i=1 if the feature f was selected in the i-th fold of cross-validation	context(wif was)	negated: False ,passive: True
0.883	[*A*]wif[*R*]was[*A*]the SVM weight for feature f	context()	negated: False ,passive: True
[LINE#351] For the ROIs that were merged into a joint feature through the hierarchical clustering, the importance of such an ROI was equal to the importance of the feature, to which this ROI belonged. .
0.385	[*A*]such an ROI[*R*]was equal to[*A*]the importance	context()	negated: False ,passive: False
0.732	[*A*]this ROI[*R*]belonged	context()	negated: False ,passive: False
0.948	[*A*]the importance of such an ROI[*R*]was[*A*]equal to the importance of the feature	context()	negated: False ,passive: True
0.914	[*A*]the ROIs[*R*]were merged[*A*]into a joint feature[*A*]through the hierarchical clustering	context()	negated: False ,passive: True
[LINE#352] Integrated modelTo combine the sMRI and fMRI data, we designed a two-layer classification model (Fig. 4).
0.924	[*A*]Integrated modelTo[*R*]combine[*A*]fMRI data	context(we designed)	negated: False ,passive: False
0.924	[*A*]Integrated modelTo[*R*]combine[*A*]the sMRI data	context(we designed)	negated: False ,passive: False
0.397	[*A*]we[*R*]designed[*A*]a two - layer classification model	context()	negated: False ,passive: False
[LINE#353] Given a training set, we trained two classifiers, namely sMRI classifier and fMRI classifier.
0.452	[*A*]we[*R*]trained[*A*]two classifiers	context()	negated: False ,passive: False
[LINE#354] Then we applied these two classifiers to the training set.
0.595	[*A*]we[*R*]applied[*A*]these two classifiers[*A*]to the training set[*A*]Then	context()	negated: False ,passive: False
[LINE#355] As a result, we obtained two predicted scores for each training sample.
0.452	[*A*]we[*R*]obtained[*A*]two predicted scores for each training sample	context()	negated: False ,passive: False
[LINE#356] Thus, the original feature space was transformed into a new two-dimensional feature space through these two classifiers.
0.919	[*A*]the original feature space[*R*]was transformed[*A*]into a new two-dimensional feature space	context()	negated: False ,passive: True
[LINE#357] Finally, we trained a linear SVM classifier (with parameter C=1) in the new feature space to combine the two scores together.
0.949	[*A*]a linear SVM classifier (with parameter C=1[*R*]to combine together[*A*]the two scores	context()	negated: False ,passive: False
0.639	[*A*]we[*R*]trained[*A*]a linear SVM classifier (with parameter C=1[*A*]in the new feature space[*A*]Finally	context()	negated: False ,passive: False
[LINE#358]  When predicting new subjects, we first obtained the two predicted scores from the sMRI classifier and fMRI classifier, then fed these two predicted scores into the second layer classifier to yield the final decision score.
0.549	[*A*]the two[*R*]predicted[*A*]scores from the fMRI classifier	context(we obtained)	negated: False ,passive: False
0.549	[*A*]the two[*R*]predicted[*A*]scores from the sMRI classifier	context(we obtained)	negated: False ,passive: False
0.489	[*A*]we[*R*]obtained[*A*]When predicting new subjects[*A*]first	context()	negated: False ,passive: False
[LINE#359+360]  The decision rule was defined as follows:(16)y=fCsum,fMRI_score=w1Csum+w2fMRI_score+bias(17)Classlabelotherwisewhere w1, w2 and bias were the parameters in the SVM model, which were learnt from the training. .
0.952	[*A*]The decision rule[*R*]was defined[*A*]as follows : ( 16 ) y=fCsum , fMRI_score=w1Csum+w2fMRI_score+bias ( 17 ) Classlabelotherwisewhere w1 , bias were the parameters in the SVM model	context()	negated: False ,passive: True
0.922	[*A*]the SVM model[*R*]were learnt[*A*]from the training	context()	negated: False ,passive: True
0.952	[*A*]The decision rule[*R*]was defined[*A*]as follows : ( 16 ) y=fCsum , fMRI_score=w1Csum+w2fMRI_score+bias ( 17 ) Classlabelotherwisewhere w1 , w2 were the parameters in the SVM model	context()	negated: False ,passive: True
[LINE#361] Validation of the classifierLeave-one-out cross-validation (LOOCV) was employed to validate the three classifiers as follows.
0.955	[*A*]Validation of the classifierLeave-one-out cross-validation[*R*]was employed[*A*]to validate the three classifiers as follows	context()	negated: False ,passive: True
[LINE#362] The total number of subjects was denoted as N.
0.937	[*A*]The total number of subjects[*R*]was denoted[*A*]as N.	context()	negated: False ,passive: True
[LINE#363] We performed N experiments, each of which was called one fold of cross-validation.
0.592	[*A*]each of which[*R*]was called[*A*]one fold of cross-validation	context()	negated: False ,passive: True
0.498	[*A*]We[*R*]performed[*A*]N experiments	context()	negated: False ,passive: False
[LINE#364] In the n-th (n=1,,N) fold of cross-validation, the n-th subject was used for testing; while the others were used for training.
0.903	[*A*]the others[*R*]were used[*A*]for training	context()	negated: False ,passive: True
0.977	[*A*]the n-th subject[*R*]was used[*A*]for testing[*A*]In the n-th (n=1,,N) fold of cross-validation	context()	negated: False ,passive: True
[LINE#365] Threshold s was determined so that the false positive rate and false negative rate for the training brains were equal, while f and i were set to be 0.
0.877	[*A*]the false positive false negative rate for the training brains[*R*]were[*A*]equal	context()	negated: False ,passive: True
0.188	[*A*]i[*R*]were set[*A*]to be 0	context(Threshold s was determined)	negated: False ,passive: True
0.197	[*A*]i[*R*]to be[*A*]0	context()	negated: False ,passive: True
0.565	[*A*]f[*R*]to be[*A*]0	context()	negated: False ,passive: True
0.605	[*A*]f[*R*]were set[*A*]to be 0	context()	negated: False ,passive: True
0.799	[*A*]the false positive rate[*R*]were[*A*]equal	context()	negated: False ,passive: True
0.788	[*A*]Threshold s[*R*]was determined	context()	negated: False ,passive: False
[LINE#366] These thresholds were applied to the test images to assign them to be either NH or HI.
0.859	[*A*]These thresholds[*R*]were applied[*A*]to the test images[*A*]to assign them to be either NH or HI	context()	negated: False ,passive: True
[LINE#367] The classification accuracy for all the N subjects was reported as accuracy.
0.958	[*A*]The classification accuracy for all the N subjects[*R*]was reported[*A*]as accuracy	context()	negated: False ,passive: True
[LINE#368] (EER) accuracies were also determined based purely on the predicted scores of the testing brain images, e.g. the threshold s/f/i were chosen so that the false positive rate was equal to false negative rate for the testing brains.
0.385	[*A*]the false positive rate[*R*]was equal to[*A*]false negative rate	context()	negated: False ,passive: False
0.937	[*A*]the false positive rate[*R*]was[*A*]equal to false negative rate for the testing brains	context()	negated: False ,passive: True
0.227	[*A*]f/i[*R*]were chosen	context()	negated: False ,passive: False
0.899	[*A*]accuracies[*R*]were determined[*A*]based purely on the predicted scores of the testing brain images	context()	negated: False ,passive: True
[LINE#369] In addition, area under curve (AUC) was also calculated to evaluate the performance of classifiers.
0.850	[*A*]area under curve[*R*]was calculated[*A*]to evaluate the performance of classifiers	context()	negated: False ,passive: True
[LINE#370]  Classifier performancePerformances of the three classifiers are shown in Table 1, and receiver operating curves (ROCs) are plotted in Fig..
0.913	[*A*]receiver operating curves[*R*]are plotted[*A*]in Fig	context()	negated: False ,passive: True
0.894	[*A*]receiver[*R*]operating[*A*]curves	context()	negated: False ,passive: True
0.943	[*A*]Classifier performancePerformances of the three classifiers[*R*]are shown[*A*]in Table 1	context()	negated: False ,passive: True
[LINE#371] While the sMRI classifier and fMRI classifier performed well individually, their combination achieved a significant improvement in performance.
0.638	[*A*]their combination[*R*]achieved[*A*]a significant improvement in performance	context()	negated: False ,passive: False
0.758	[*A*]fMRI[*R*]performed well individually[*A*]classifier	context()	negated: False ,passive: False
0.791	[*A*]their combination[*R*]achieved[*A*]a significant improvement in performance[*A*]While the sMRI classifier performed well individually	context()	negated: False ,passive: False
0.803	[*A*]the sMRI classifier[*R*]performed well individually	context()	negated: False ,passive: False
[LINE#372] The combined classifier yielded AUC and EER as high as 0.90 and 0.89, respectively.
0.925	[*A*]The combined classifier[*R*]yielded[*A*]EER as high as 0.89[*A*]respectively	context()	negated: False ,passive: False
0.925	[*A*]The combined classifier[*R*]yielded[*A*]EER as high as 0.90[*A*]respectively	context()	negated: False ,passive: False
0.925	[*A*]The combined classifier[*R*]yielded[*A*]AUC as high as 0.89[*A*]respectively	context()	negated: False ,passive: False
0.925	[*A*]The combined classifier[*R*]yielded[*A*]AUC as high as 0.90[*A*]respectively	context()	negated: False ,passive: False
[LINE#373+374]  From the ROC, we can see that the sMRI classifier could not predict some of the positive subjects(HI) correctly even when the decision threshold was set to be very low, because the classifier did not reach 100% true positive rate even when the false positive rate approached 100%.
0.903	[*A*]the classifier[*R*]did not reach[*A*]100%	context()	negated: True ,passive: False
0.754	[*A*]the decision threshold[*R*]to be[*A*]very low	context()	negated: False ,passive: True
0.919	[*A*]the false positive rate[*R*]approached[*A*]100%	context()	negated: False ,passive: True
0.945	[*A*]the sMRI classifier[*R*]could not predict[*A*]some of the positive subjects[*A*]because the classifier did not reach 100% true positive rate even when the false positive rate approached 100%	context(we can see)	negated: True ,passive: False
0.309	[*A*]we[*R*]can see[*A*]that the sMRI classifier could not predict some of the positive subjects	context()	negated: False ,passive: False
[LINE#375] However, the ROC for fMRI was in an opposite situation.
0.913	[*A*]the ROC for fMRI[*R*]was[*A*]in an opposite situation	context()	negated: False ,passive: True
[LINE#376] The ROC did not reach 0% false positive rate even when the true positive rate approached 0%, suggesting that the fMRI classifier had difficulty in classifying some of the negative subjects (NH) correctly.
0.999	[*A*]The ROC[*R*]did not reach[*A*]0 %	context()	negated: False ,passive: False
0.888	[*A*]the true positive rate[*R*]approached[*A*]0%[*A*]suggesting that the fMRI classifier had difficulty in classifying some of the negative subjects (NH) correctly	context()	negated: False ,passive: True
0.899	[*A*]The ROC[*R*]did not reach[*A*]0%[*A*]even when the true positive rate approached 0%, suggesting that the fMRI classifier had difficulty in classifying some of the negative subjects (NH) correctly	context()	negated: True ,passive: False
[LINE#377] As sMRI and fMRI classifiers were vulnerable to different types of errors, it was possible to combine them to overcome their individual limitations.
0.927	[*A*]fMRI classifiers[*R*]were[*A*]vulnerable to different types of errors	context()	negated: False ,passive: True
0.927	[*A*]sMRI classifiers[*R*]were[*A*]vulnerable to different types of errors	context()	negated: False ,passive: True
[LINE#378] To illustrate the reason why the combination can be successful, we plotted sMRI-fMRI scores in Figs.
0.498	[*A*]we[*R*]plotted[*A*]sMRI-fMRI scores[*A*]in Figs	context()	negated: False ,passive: False
0.767	[*A*]the combination[*R*]can be[*A*]successful	context()	negated: False ,passive: True
[LINE#379] Simply speaking, the fMRI classifier draws a horizontal line to separate the two groups of subjects based on the fMRI data, while the sMRI classifier draws a vertical line to separate the two groups based on the sMRI data.
0.949	[*A*]the sMRI classifier[*R*]draws[*A*]a vertical line to separate the two groups	context()	negated: False ,passive: False
0.911	[*A*]subjects[*R*]based[*A*]on the fMRI data	context()	negated: False ,passive: True
0.925	[*A*]the two groups[*R*]based[*A*]on the sMRI data	context()	negated: False ,passive: True
0.973	[*A*]the fMRI classifier[*R*]draws[*A*]a horizontal line to separate the two groups of subjects[*A*]while the sMRI classifier draws a vertical line	context()	negated: False ,passive: False
0.925	[*A*]a vertical line[*R*]to separate[*A*]the two groups based on the sMRI data	context()	negated: False ,passive: False
[LINE#380] Obviously, the two groups could not be perfectly separated by either a horizontal or a vertical line in Figs.
0.952	[*A*]the two groups[*R*]could not be perfectly separated[*A*]by either a horizontal or a vertical line in Figs	context()	negated: True ,passive: True
[LINE#381] However, by combining the fMRI and sMRI classifiers, the two groups of subjects were separable with a diagonal line as shown in the figures.
0.926	[*A*]the two groups of subjects[*R*]were[*A*]separable with a diagonal line	context()	negated: False ,passive: True
[LINE#382]  Performances of the three classifiers are shown in Table 1, and receiver operating curves (ROCs) are plotted in Fig..
0.913	[*A*]receiver operating curves[*R*]are plotted[*A*]in Fig	context()	negated: False ,passive: True
0.894	[*A*]receiver[*R*]operating[*A*]curves	context()	negated: False ,passive: True
0.937	[*A*]Performances of the three classifiers[*R*]are shown[*A*]in Table 1	context()	negated: False ,passive: True
[LINE#383] While the sMRI classifier and fMRI classifier performed well individually, their combination achieved a significant improvement in performance.
0.638	[*A*]their combination[*R*]achieved[*A*]a significant improvement in performance	context()	negated: False ,passive: False
0.758	[*A*]fMRI[*R*]performed well individually[*A*]classifier	context()	negated: False ,passive: False
0.791	[*A*]their combination[*R*]achieved[*A*]a significant improvement in performance[*A*]While the sMRI classifier performed well individually	context()	negated: False ,passive: False
0.803	[*A*]the sMRI classifier[*R*]performed well individually	context()	negated: False ,passive: False
[LINE#384] The combined classifier yielded AUC and EER as high as 0.90 and 0.89, respectively.
0.925	[*A*]The combined classifier[*R*]yielded[*A*]EER as high as 0.89[*A*]respectively	context()	negated: False ,passive: False
0.925	[*A*]The combined classifier[*R*]yielded[*A*]EER as high as 0.90[*A*]respectively	context()	negated: False ,passive: False
0.925	[*A*]The combined classifier[*R*]yielded[*A*]AUC as high as 0.89[*A*]respectively	context()	negated: False ,passive: False
0.925	[*A*]The combined classifier[*R*]yielded[*A*]AUC as high as 0.90[*A*]respectively	context()	negated: False ,passive: False
[LINE#385+386]  From the ROC, we can see that the sMRI classifier could not predict some of the positive subjects(HI) correctly even when the decision threshold was set to be very low, because the classifier did not reach 100% true positive rate even when the false positive rate approached 100%.
0.903	[*A*]the classifier[*R*]did not reach[*A*]100%	context()	negated: True ,passive: False
0.754	[*A*]the decision threshold[*R*]to be[*A*]very low	context()	negated: False ,passive: True
0.919	[*A*]the false positive rate[*R*]approached[*A*]100%	context()	negated: False ,passive: True
0.945	[*A*]the sMRI classifier[*R*]could not predict[*A*]some of the positive subjects[*A*]because the classifier did not reach 100% true positive rate even when the false positive rate approached 100%	context(we can see)	negated: True ,passive: False
0.309	[*A*]we[*R*]can see[*A*]that the sMRI classifier could not predict some of the positive subjects	context()	negated: False ,passive: False
[LINE#387] However, the ROC for fMRI was in an opposite situation.
0.913	[*A*]the ROC for fMRI[*R*]was[*A*]in an opposite situation	context()	negated: False ,passive: True
[LINE#388] The ROC did not reach 0% false positive rate even when the true positive rate approached 0%, suggesting that the fMRI classifier had difficulty in classifying some of the negative subjects (NH) correctly.
0.999	[*A*]The ROC[*R*]did not reach[*A*]0 %	context()	negated: False ,passive: False
0.888	[*A*]the true positive rate[*R*]approached[*A*]0%[*A*]suggesting that the fMRI classifier had difficulty in classifying some of the negative subjects (NH) correctly	context()	negated: False ,passive: True
0.899	[*A*]The ROC[*R*]did not reach[*A*]0%[*A*]even when the true positive rate approached 0%, suggesting that the fMRI classifier had difficulty in classifying some of the negative subjects (NH) correctly	context()	negated: True ,passive: False
[LINE#389] As sMRI and fMRI classifiers were vulnerable to different types of errors, it was possible to combine them to overcome their individual limitations.
0.927	[*A*]fMRI classifiers[*R*]were[*A*]vulnerable to different types of errors	context()	negated: False ,passive: True
0.927	[*A*]sMRI classifiers[*R*]were[*A*]vulnerable to different types of errors	context()	negated: False ,passive: True
[LINE#390]  To illustrate the reason why the combination can be successful, we plotted sMRI-fMRI scores in Fig..
0.498	[*A*]we[*R*]plotted[*A*]sMRI-fMRI scores[*A*]in Fig	context()	negated: False ,passive: False
0.767	[*A*]the combination[*R*]can be[*A*]successful	context()	negated: False ,passive: True
[LINE#391] Simply speaking, the fMRI classifier draws a horizontal line to separate the two groups of subjects based on the fMRI data, while the sMRI classifier draws a vertical line to separate the two groups based on the sMRI data.
0.949	[*A*]the sMRI classifier[*R*]draws[*A*]a vertical line to separate the two groups	context()	negated: False ,passive: False
0.911	[*A*]subjects[*R*]based[*A*]on the fMRI data	context()	negated: False ,passive: True
0.925	[*A*]the two groups[*R*]based[*A*]on the sMRI data	context()	negated: False ,passive: True
0.973	[*A*]the fMRI classifier[*R*]draws[*A*]a horizontal line to separate the two groups of subjects[*A*]while the sMRI classifier draws a vertical line	context()	negated: False ,passive: False
0.925	[*A*]a vertical line[*R*]to separate[*A*]the two groups based on the sMRI data	context()	negated: False ,passive: False
[LINE#392]  Obviously, the two groups could not be perfectly separated by either a horizontal or a vertical line in Fig..
0.952	[*A*]the two groups[*R*]could not be perfectly separated[*A*]by either a horizontal or a vertical line in Fig	context()	negated: True ,passive: True
[LINE#393] However, by combining the fMRI and sMRI classifiers, the two groups of subjects were separable with a diagonal line as shown in the figures..
0.926	[*A*]the two groups of subjects[*R*]were[*A*]separable with a diagonal line	context()	negated: False ,passive: True
[LINE#394+395]  Feature selection in sMRI analysisInthe analysis of sMRI data, image features were selected based on their likelihood scores.
0.916	[*A*]image features[*R*]were selected[*A*]based on their likelihood scores[*A*]Feature selection in sMRI analysisInthe analysis of sMRI data	context()	negated: False ,passive: True
[LINE#396] The total number of image features in a brain image ranged from 35,000 to 52,000.
0.877	[*A*]The total number of image features in a brain image[*R*]ranged[*A*]from 35,000 to 52,000	context()	negated: False ,passive: True
[LINE#397] Most of these image features were noise features.
0.926	[*A*]Most of these image features[*R*]were[*A*]noise features	context()	negated: False ,passive: True
[LINE#398] The total number of selected features, i.e., healthy and patient features, ranged from 300 to 1400 for different brains with a likelihood threshold of 0.9.
0.921	[*A*]The total number of selected features[*R*]ranged[*A*]from 300 to 1400[*A*]for different brains	context()	negated: False ,passive: True
[LINE#399] Different choices of likelihood threshold for the sMRI feature selection resulted in different numbers of selected features and therefore different classification accuracies.
0.965	[*A*]Different choices of likelihood threshold for the sMRI feature selection[*R*]resulted[*A*]in different numbers of selected therefore different classification accuracies	context()	negated: False ,passive: True
0.965	[*A*]Different choices of likelihood threshold for the sMRI feature selection[*R*]resulted[*A*]in different numbers of selected features	context()	negated: False ,passive: True
[LINE#400] Table 2 shows the relation between classification accuracy and the likelihood threshold.
0.636	[*A*]Table 2[*R*]shows[*A*]the relation between classification accuracy and the likelihood threshold	context()	negated: False ,passive: False
[LINE#401] The classification accuracy did not change for likelihood threshold ranging from 0.7 to 1.1.
0.767	[*A*]likelihood threshold[*R*]ranging[*A*]from 0.7[*A*]to 1.1	context()	negated: False ,passive: True
0.911	[*A*]The classification accuracy[*R*]did not change[*A*]for likelihood threshold	context()	negated: True ,passive: True
[LINE#402] The AUC changed within a range of 0.09 with a peak where the likelihood threshold equaled 0.9.
0.948	[*A*]the likelihood threshold[*R*]equaled[*A*]0.9[*A*]a peak	context()	negated: False ,passive: True
0.927	[*A*]The AUC[*R*]changed[*A*]within a range of 0.09[*A*]with a peak	context()	negated: False ,passive: True
[LINE#403] The EER accuracy varied within a range of 0.08.
0.933	[*A*]The EER accuracy[*R*]varied[*A*]within a range of 0.08	context()	negated: False ,passive: True
[LINE#404] All three classification performance measures were stable with different likelihood thresholds. .
0.926	[*A*]All three classification performance measures[*R*]were[*A*]stable with different likelihood thresholds	context()	negated: False ,passive: True
[LINE#405] Stability of feature selection in fMRI analysisWe have analyzed the stability of feature selection in the analysis of fMRI data.
0.975	[*A*]Stability of feature selection in fMRI analysisWe[*R*]have analyzed[*A*]the stability of feature selection in the analysis of fMRI data	context()	negated: False ,passive: False
[LINE#406] There were in total 972 features as the input for feature selection.
[LINE#407] Only 6.2% of the features (with a total number of 60) were selected at least once.
0.889	[*A*]Only 6.2% of the features (with a total number of 60[*R*]were selected[*A*]at least once	context()	negated: False ,passive: True
[LINE#408] For each fold of cross-validation, there were usually about 20 features selected for the training, generally 30% of which were consistently present in all folds of cross-validation.
0.926	[*A*]generally 30% of which[*R*]were consistently[*A*]present in all folds of cross-validation	context()	negated: False ,passive: True
0.911	[*A*]about 20 features[*R*]selected[*A*]for the training	context()	negated: False ,passive: True
[LINE#409+410+411]  We calculated a stability index as follows (Kalousis et al., 2007):(18)Simsisj=sisjsisj(19)index=2cc-1i=1c-1j=c was the total number of rounds of feature selection, si and sj were two sets of features selected during two runs, |sisj| was the cardinality of the intersection between si and sj, and |sisj| was the cardinality of the union of si and sj.
0.894	[*A*]features[*R*]selected[*A*]during two runs	context()	negated: False ,passive: True
0.934	[*A*]index=2cc-1i=1c-1j=c[*R*]were[*A*]two sets of features	context()	negated: False ,passive: True
0.973	[*A*]index=2cc-1i=1c-1j=c[*R*]was[*A*]the total number of rounds of feature selection, si and sj	context()	negated: False ,passive: True
0.498	[*A*]We[*R*]calculated[*A*]a stability index[*A*]as follows (Kalousis et al	context()	negated: False ,passive: False
[LINE#412] Our feature selection yielded a stability index of 66.2%, which indicated that 66.2% of the selected features, on average, were common between any two runs of feature selection.
0.899	[*A*]66.2% of the selected features[*R*]were[*A*]common between any two runs of feature selection	context(a stability index of 66.2 % indicated)	negated: False ,passive: True
0.839	[*A*]a stability index of 66.2%[*R*]indicated[*A*]that 66.2% of the selected features, on average, were common between any two runs of feature selection	context()	negated: False ,passive: False
0.532	[*A*]Our feature selection[*R*]yielded[*A*]a stability index of 66.2%, which indicated that 66.2% of the selected features, on average, were common between any two runs of feature selection	context()	negated: False ,passive: False
[LINE#413] Since the Euclidean distance was used in the hierarchical clustering, only very similar ROIs were merged.
0.818	[*A*]only very similar ROIs[*R*]were merged	context()	negated: False ,passive: False
0.933	[*A*]the Euclidean distance[*R*]was used[*A*]in the hierarchical clustering	context()	negated: False ,passive: True
[LINE#414] There was still considerable redundancy among features.
[LINE#415] For example, two ROIs, e.g. one from the contrast speech vs. silence and the other from the contrast tones vs. silence, were significantly correlated with class labels, and meanwhile they were also highly correlated with each other.
0.914	[*A*]two ROIs[*R*]were significantly correlated[*A*]with class labels	context()	negated: False ,passive: True
0.323	[*A*]they[*R*]highly correlated[*A*]with each other	context()	negated: False ,passive: True
0.502	[*A*]they[*R*]were[*A*]also[*A*]highly correlated with each other[*A*]meanwhile	context()	negated: False ,passive: True
[LINE#416] Due to the large Euclidean distance between them, however, they were not merged during the hierarchical clustering.
0.616	[*A*]they[*R*]were not merged[*A*]during the hierarchical clustering	context()	negated: True ,passive: True
[LINE#417] In feature selection, these two ROIs were treated as different features and selected interchangeably.
0.939	[*A*]these two ROIs[*R*]were selected interchangeably[*A*]In feature selection	context()	negated: False ,passive: True
0.948	[*A*]these two ROIs[*R*]were treated[*A*]as different features[*A*]In feature selection	context()	negated: False ,passive: True
[LINE#418] This caused the calculated stability index to be lower than the actual value.
0.900	[*A*]the calculated stability index[*R*]to be[*A*]lower than the actual value	context(This caused)	negated: False ,passive: True
0.441	[*A*]This[*R*]caused[*A*]the calculated stability index to be lower than the actual value	context()	negated: False ,passive: False
[LINE#419] In this regard, 66.2% represented very high stability. .
0.991	[*A*]66.2 %[*R*]represented[*A*]very high stability	context()	negated: False ,passive: False
0.943	[*A*]66.2%[*R*]represented[*A*]very high stability[*A*]In this regard	context()	negated: False ,passive: False
[LINE#420+421]  Discriminative brain regionsFor sMRI, we measured the importance of a SIFT feature with its likelihood score.
0.607	[*A*]we[*R*]measured[*A*]the importance of a SIFT feature with its likelihood score[*A*]Discriminative brain regionsFor sMRI	context()	negated: False ,passive: False
[LINE#422] In our project, however, the SIFT features usually had a scale of 10mm or even larger, and correspondingly the side length of the appearance matrices was larger than 40mm.
0.938	[*A*]the SIFT features[*R*]had[*A*]a scale of 10mm or even larger[*A*]In our project[*A*]usually	context()	negated: False ,passive: False
[LINE#423] Due to the large size of the SIFT features, it was more difficult and less useful to interpret the medical implications of such large brain regions.
0.411	[*A*]it[*R*]to interpret[*A*]the medical implications of such large brain regions	context()	negated: False ,passive: False
0.637	[*A*]it[*R*]was[*A*]less useful to interpret the medical implications of such large brain regions	context()	negated: False ,passive: True
[LINE#424] With those considerations, we only focused on the highly predictive brain regions identified by the fMRI classifier.
0.937	[*A*]the highly predictive brain regions[*R*]identified[*A*]by the fMRI classifier	context()	negated: False ,passive: True
0.411	[*A*]we[*R*]focused[*A*]on the highly predictive brain regions	context()	negated: False ,passive: False
[LINE#425] 7 shows the top 10 functional features extracted from fMRI data that differentiate the HI and NH groups.
0.928	[*A*]fMRI data[*R*]differentiate[*A*]the NH groups	context()	negated: False ,passive: False
0.928	[*A*]fMRI data[*R*]differentiate[*A*]the HI groups	context()	negated: False ,passive: False
0.937	[*A*]the top 10 functional features[*R*]extracted[*A*]from fMRI data	context()	negated: False ,passive: True
0.495	[*A*]7[*R*]shows[*A*]the top 10 functional features extracted from fMRI data	context()	negated: False ,passive: False
[LINE#426] Features are numbered from A to J in order.
0.911	[*A*]Features[*R*]are numbered[*A*]from A[*A*]in order	context()	negated: False ,passive: True
[LINE#427]  ROI A1 and A2 were merged during hierarchical clustering into a joint feature.
0.894	[*A*]A2[*R*]were merged[*A*]during hierarchical clustering[*A*]into a joint feature	context()	negated: False ,passive: True
0.927	[*A*]ROI A1[*R*]were merged[*A*]during hierarchical clustering[*A*]into a joint feature	context()	negated: False ,passive: True
[LINE#428] A. Similar procedures were performed for features C, E, F, I and J.
0.925	[*A*]A. Similar procedures[*R*]were performed[*A*]for features[*A*]J.	context()	negated: False ,passive: True
0.848	[*A*]A. Similar procedures[*R*]were performed[*A*]for features , I	context()	negated: False ,passive: True
0.925	[*A*]A. Similar procedures[*R*]were performed[*A*]for features F	context()	negated: False ,passive: True
0.925	[*A*]A. Similar procedures[*R*]were performed[*A*]for features C[*A*]E	context()	negated: False ,passive: True
[LINE#429] We can see that ROIs grouped together during hierarchical clustering are always from the same type of contrast maps (Table 3) and encompass adjoining or sometimes overlapping brain regions as designated by Brodmann's Areas in the 4th column of Table 3.
0.898	[*A*]ROIs[*R*]grouped together[*A*]during hierarchical clustering	context(We can see)	negated: False ,passive: True
0.218	[*A*]We[*R*]can see[*A*]that ROIs grouped together during hierarchical clustering	context()	negated: False ,passive: False
