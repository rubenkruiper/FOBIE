[LINE#0] To guarantee the vision of Cloud Computing QoS goals between the Cloud provider and the customer have to be dynamically met.
0.909	[*A*]the vision of Cloud Computing QoS goals between the Cloud provider and the customer[*R*]to be dynamically met	context()	negated: False ,passive: False
[LINE#1] This so-called Service Level Agreement (SLA) enactment should involve little human-based interaction in order to guarantee the scalability and efficient resource utilization of the system.
0.939	[*A*]This so - called Service Level Agreement ( SLA ) enactment[*R*]should involve[*A*]little human - based interaction	context()	negated: False ,passive: True
[LINE#2] To achieve this we start from Autonomic Computing, examine the autonomic control loop and adapt it to govern Cloud Computing infrastructures.
0.568	[*A*]we[*R*]start[*A*]from Autonomic Computing	context()	negated: False ,passive: False
[LINE#3] We first hierarchically structure all possible adaptation actions into so-called escalation levels.
0.452	[*A*]We[*R*]first hierarchically structure[*A*]all possible adaptation actions[*A*]into so-called escalation levels	context()	negated: False ,passive: False
[LINE#4] We then focus on one of these levels by analyzing monitored data from virtual machines and making decisions on their resource configuration with the help of knowledge management (KM).
0.554	[*A*]We[*R*]focus[*A*]on one of these levels[*A*]then	context()	negated: False ,passive: False
[LINE#5] The monitored data stems both from synthetically generated workload categorized in different workload volatility classes and from a real-world scenario: scientific workflow applications in bioinformatics.
0.895	[*A*]synthetically generated workload[*R*]categorized[*A*]from a real - world scenario	context()	negated: False ,passive: True
0.911	[*A*]synthetically generated workload[*R*]categorized[*A*]in different workload volatility classes	context()	negated: False ,passive: True
0.932	[*A*]The monitored data[*R*]stems[*A*]both from synthetically generated workload	context()	negated: False ,passive: True
[LINE#6] As KM techniques, we investigate two methods, Case-Based Reasoning and a rule-based approach.
0.452	[*A*]we[*R*]investigate[*A*]two methods	context()	negated: False ,passive: False
[LINE#7] We design and implement both of them and evaluate them with the help of a simulation engine.
0.309	[*A*]We[*R*]implement[*A*]both of them	context()	negated: False ,passive: False
0.195	[*A*]We[*R*]design	context()	negated: False ,passive: False
[LINE#8] Simulation reveals the feasibility of the CBR approach and major improvements by the rule-based approach considering SLA violations, resource utilization, the number of necessary reconfigurations and time performance for both, synthetically generated and real-world data.
0.805	[*A*]the number of necessary time performance for both[*R*]synthetically generated	context()	negated: False ,passive: False
0.756	[*A*]the number of necessary reconfigurations[*R*]synthetically generated	context()	negated: False ,passive: False
0.948	[*A*]Simulation[*R*]reveals[*A*]the feasibility of major improvements by the rule - based approach	context()	negated: False ,passive: False
0.932	[*A*]Simulation[*R*]reveals[*A*]the feasibility of the CBR approach	context()	negated: False ,passive: False
[LINE#9] In this section we describe how the KM approach can be integrated within a more holistic Cloud management project that, e.g., also consists of a monitoring component.
0.928	[*A*]the KM approach[*R*]can be integrated[*A*]within a more holistic Cloud management project	context(we describe)	negated: False ,passive: True
0.686	[*A*]we[*R*]describe[*A*]how the KM approach can be integrated within a more holistic Cloud management project[*A*]In this section	context()	negated: False ,passive: False
0.940	[*A*]a more holistic Cloud management project[*R*]consists[*A*]of a monitoring component	context()	negated: False ,passive: True
[LINE#10] Yet, the KM approach does not depend on the specific used monitoring framework, as long as it correctly measures the current values of the parameters specified in the SLA.In this case, the FoSII project will serve as a running example.
0.903	[*A*]the KM approach[*R*]does not depend[*A*]on the specific used monitoring framework[*A*]as long as it correctly measures the current values of the parameters	context(the FoSII project will serve)	negated: True ,passive: False
0.915	[*A*]the FoSII project[*R*]will serve[*A*]as a running example	context()	negated: False ,passive: False
0.918	[*A*]the parameters[*R*]specified[*A*]in the SLA.In[*A*]this case	context()	negated: False ,passive: True
0.452	[*A*]it[*R*]correctly measures[*A*]the current values of the parameters	context()	negated: False ,passive: False
[LINE#11] We will describe how the KM approach relates to other components of the FoSII project.
0.928	[*A*]the KM approach[*R*]relates[*A*]to other components of the FoSII project	context(We will describe)	negated: False ,passive: True
0.550	[*A*]We[*R*]will describe[*A*]how the KM approach relates to other components of the FoSII project	context()	negated: False ,passive: False
[LINE#12] Generally, the project distinguishes between system set-up and run time.
0.903	[*A*]the project[*R*]distinguishes[*A*]between system set - up	context()	negated: False ,passive: False
[LINE#13] During system set-up, applications, their corresponding SLAs and used infrastructure are tailored and adapted.
0.944	[*A*]applications , used infrastructure[*R*]are tailored[*A*]During system set - up	context()	negated: False ,passive: True
0.743	[*A*]their corresponding SLAs[*R*]are tailored[*A*]During system set - up , applications	context()	negated: False ,passive: True
[LINE#14] Once the application is deployed, we consider monitoring, knowledge management and execution phases during run time.
0.595	[*A*]we[*R*]consider[*A*]execution phases[*A*]during run time[*A*]Once the application is deployed	context()	negated: False ,passive: False
0.595	[*A*]we[*R*]consider[*A*]knowledge management during run time[*A*]Once the application is deployed	context()	negated: False ,passive: False
0.388	[*A*]we[*R*]consider monitoring[*A*]during run time	context(we consider)	negated: False ,passive: False
0.531	[*A*]we[*R*]consider[*A*]monitoring during run time[*A*]Once the application is deployed	context()	negated: False ,passive: False
0.830	[*A*]the application[*R*]is deployed[*A*]Once	context()	negated: False ,passive: True
[LINE#15]  In this section, in particular, we focus on the adaptation, monitoring, and knowledge management phases, as shown in Fig..
0.639	[*A*]we[*R*]focus[*A*]on the knowledge management phases[*A*]as shown in Fig[*A*]In this section	context()	negated: False ,passive: False
0.639	[*A*]we[*R*]focus[*A*]on the monitoring[*A*]as shown in Fig[*A*]In this section	context()	negated: False ,passive: False
0.639	[*A*]we[*R*]focus[*A*]on the adaptation[*A*]as shown in Fig[*A*]In this section	context()	negated: False ,passive: False
[LINE#16] Thus, the MAPE-K loop is extended to the A-MAPE-K loop, where the additional A stands for the adaptation phase during system set-up.
0.949	[*A*]the additional A[*R*]stands[*A*]for the adaptation phase	context()	negated: False ,passive: True
0.953	[*A*]the MAPE-K loop[*R*]is extended[*A*]to the A-MAPE-K loop	context()	negated: False ,passive: True
[LINE#17] This adaptation phase, however, should not be confused with later adaptation and re-configuration of resources during system run time.
0.878	[*A*]This adaptation phase[*R*]should not be confused[*A*]during system run time	context()	negated: True ,passive: True
0.897	[*A*]This adaptation phase[*R*]should not be confused[*A*]with later adaptation[*A*]during system[*A*]run time	context()	negated: True ,passive: True
[LINE#18] Quite evidently, we especially focus on the knowledge management phase in this paper.
0.411	[*A*]we[*R*]focus[*A*]on the knowledge management phase in this paper	context()	negated: False ,passive: False
[LINE#19]  The three mentioned phases are described as follows:.
0.799	[*A*]The three mentioned phases[*R*]are described[*A*]as follows:.	context()	negated: False ,passive: True
[LINE#20] AdaptationAs shown in Fig. 1, part 1, the adaptation phase comprises all steps necessary to be done before successful deployment and start of the application.
0.943	[*A*]the adaptation phase[*R*]comprises[*A*]all steps necessary to be done before successful start of the application	context()	negated: False ,passive: True
0.943	[*A*]the adaptation phase[*R*]comprises[*A*]all steps necessary to be done before successful deployment of the application	context()	negated: False ,passive: True
0.931	[*A*]AdaptationAs[*R*]shown[*A*]in Fig	context()	negated: False ,passive: False
[LINE#21] This includes SLA contract establishment and tailoring of the monitoring systems for the particular application.
0.381	[*A*]This[*R*]includes[*A*]tailoring of the monitoring systems for the particular application	context()	negated: False ,passive: True
0.543	[*A*]This[*R*]includes[*A*]SLA contract establishment of the monitoring systems for the particular application	context()	negated: False ,passive: True
[LINE#22] We assume that Cloud providers register their resources to particular databases containing public SLA templates.
0.846	[*A*]Cloud providers[*R*]register[*A*]their resources[*A*]to particular databases	context(We assume)	negated: False ,passive: False
0.136	[*A*]We[*R*]assume[*A*]that Cloud providers register their resources to particular databases	context()	negated: False ,passive: False
0.918	[*A*]particular databases[*R*]containing[*A*]public SLA templates	context()	negated: False ,passive: False
[LINE#23] Thereafter, Cloud users can look up resources that they want to use for the deployment of their applications.
0.756	[*A*]resources[*R*]to use[*A*]for the deployment of their applications	context(they want)	negated: False ,passive: True
0.480	[*A*]they[*R*]want[*A*]to use for the deployment of their applications	context()	negated: False ,passive: False
0.801	[*A*]Cloud users[*R*]can look up[*A*]resources that they want to use for the deployment of their applications	context()	negated: False ,passive: False
[LINE#24] Similar to the providers, Cloud users also have an SLA template utilized for their private business processes.
0.883	[*A*]an SLA template[*R*]utilized[*A*]for their private business processes	context()	negated: False ,passive: True
0.928	[*A*]Cloud users[*R*]have[*A*]an SLA template	context()	negated: False ,passive: False
[LINE#25] We assume that the private SLA template cannot be changed, since it could also be part of some other local business processes and has usually to comply with different legal and security guidelines.
0.301	[*A*]it[*R*]has to comply[*A*]with different security guidelines	context(it has)	negated: False ,passive: False
0.301	[*A*]it[*R*]has to comply[*A*]with different legal guidelines	context(it has)	negated: False ,passive: False
0.236	[*A*]it[*R*]has[*A*]usually	context()	negated: False ,passive: False
0.783	[*A*]the private SLA template[*R*]can not be changed	context(We assume)	negated: True ,passive: False
0.225	[*A*]We[*R*]assume[*A*]that the private SLA template can not be changed	context()	negated: False ,passive: False
0.350	[*A*]it[*R*]could be[*A*]part of some other local business processes	context()	negated: False ,passive: True
[LINE#26] If matching SLA templates are found, an SLA contract can be negotiated and established and the application can be deployed.
0.732	[*A*]the application[*R*]can be deployed	context()	negated: False ,passive: False
0.803	[*A*]an SLA contract[*R*]can be negotiated	context()	negated: False ,passive: False
0.803	[*A*]matching SLA templates[*R*]are found	context()	negated: False ,passive: False
[LINE#27] Thus, during this phase it has to be ensured that private templates of the provider and consumers match publicly available templates.
[LINE#28] However, public and private templates may differ.
0.732	[*A*]private templates[*R*]may differ	context()	negated: False ,passive: False
0.732	[*A*]public templates[*R*]may differ	context()	negated: False ,passive: False
[LINE#29] A typical mismatch between templates would be between different measurement units of attributes, as for example for the SLO clock speed or missing attributes.
0.960	[*A*]A typical mismatch between templates[*R*]would be[*A*]between different measurement units of attributes, as for example for the SLO clock speed or missing attributes	context()	negated: False ,passive: True
[LINE#30] Therefore, a mechanism is required for the automatic adaptation between different templates without changing the templates themselves.
0.903	[*A*]a mechanism[*R*]is required[*A*]for the automatic adaptation between different templates	context()	negated: False ,passive: True
[LINE#31] A possible solution for this is the so called SLA mapping approach presented in [33].
0.868	[*A*]the so called SLA mapping approach[*R*]presented[*A*]in [33	context()	negated: False ,passive: True
0.952	[*A*]A possible solution for this[*R*]is[*A*]the so called SLA mapping approach	context()	negated: False ,passive: True
[LINE#32] This approach can include handling of missing SLA parameters, inconsistencies between attributes and translation between different attributes.
0.947	[*A*]This approach[*R*]can include[*A*]handling of missing SLA parameters, inconsistencies between attributes and translation between different attributes	context()	negated: False ,passive: True
[LINE#33] More complex adaptations would include automatic service aggregation, including third party services, if, for example, the clock speed attribute is completely missing in the public template, but required in the private template.
0.919	[*A*]the clock speed attribute[*R*]is required[*A*]in the private template	context()	negated: False ,passive: True
0.881	[*A*]the clock speed attribute[*R*]is missing[*A*]in the public template	context()	negated: False ,passive: True
0.911	[*A*]More complex adaptations[*R*]would include[*A*]automatic service aggregation , including third party services	context()	negated: False ,passive: True
[LINE#34] A third party provider (e.g., a computer hardware reseller) could be integrated to deliver information about the clock speed attribute.
0.905	[*A*]A third party provider[*R*]could be integrated[*A*]to deliver information about the clock speed attribute	context()	negated: False ,passive: True
[LINE#35+36]  Detailed information on the adaptation phase including the SLA mapping approach are found in [33,34].MonitoringCurrent monitoring systems (e.g., ganglia [35])facilitate monitoring only of low-level systems resources, such as free_disk or packets_sent, but SLA parameters typically are, e.g., storage and outgoing bandwidth.
0.993	[*A*]Detailed information on the adaptation phase including the SLA mapping approach[*R*]are found in[*A*]3334 ].monitoringcurrent monitoring systems	context()	negated: False ,passive: False
0.899	[*A*]SLA parameters[*R*]are[*A*]e.g.[*A*]storage and outgoing bandwidth	context()	negated: False ,passive: True
0.932	[*A*]ganglia[*R*]facilitate monitoring[*A*]only of low-level systems resources, such as free_disk or packets_sent	context()	negated: False ,passive: False
0.914	[*A*]Detailed information on the adaptation phase including the SLA mapping approach[*R*]are found[*A*]in [33,34	context()	negated: False ,passive: True
[LINE#37] Thus, SLA parameters required by an application usually differ from the parameters measured by the monitoring tools.
0.903	[*A*]the parameters[*R*]measured[*A*]by the monitoring tools	context()	negated: False ,passive: True
0.870	[*A*]SLA parameters[*R*]differ[*A*]usually	context()	negated: False ,passive: True
0.927	[*A*]SLA parameters[*R*]required[*A*]by an application	context()	negated: False ,passive: True
[LINE#38]  To achieve a mapping from the low-level metrics to the high-level SLA parameters, the monitoring phase should comprise two core components, namely the host monitor and the run-time monitor (.
[LINE#39] The former is responsible for monitoring low-level resource metrics, whereas the latter is responsible for metric mapping, and consequently for the monitoring of SLAs and informing the KM phase about SLA violations.
0.960	[*A*]the latter[*R*]is[*A*]responsible consequently for informing the KM phase about SLA violations	context()	negated: False ,passive: True
0.771	[*A*]The former[*R*]is[*A*]responsible for monitoring low - level resource metrics[*A*]whereas the latter is responsible consequently for informing the KM phase about SLA violations	context()	negated: False ,passive: True
0.937	[*A*]the latter[*R*]is[*A*]responsible consequently for the monitoring of SLAs	context()	negated: False ,passive: True
0.771	[*A*]The former[*R*]is[*A*]responsible for monitoring low - level resource metrics[*A*]whereas the latter is responsible consequently for the monitoring of SLAs	context()	negated: False ,passive: True
0.925	[*A*]the latter[*R*]is[*A*]responsible for metric mapping	context()	negated: False ,passive: True
0.636	[*A*]The former[*R*]is[*A*]responsible for monitoring low - level resource metrics[*A*]whereas the latter is responsible for metric mapping	context()	negated: False ,passive: True
[LINE#40] This monitoring framework has proven to be highly scalable and is presented in more detail in [3].Knowledge ManagementSince the analysis, plan and KB parts are highly interweaved with each other, we call the ensemble of these phases the Knowledge Management Phase (see Fig. 1, part 3).
0.797	[*A*]the KB parts[*R*]are[*A*]highly interweaved with each other	context(we call)	negated: False ,passive: True
0.783	[*A*]the plan parts[*R*]are[*A*]highly interweaved with each other	context()	negated: False ,passive: True
0.993	[*A*]This monitoring[*R*]is presented in[*A*]3 ]	context()	negated: False ,passive: False
0.783	[*A*]the analysis parts[*R*]are[*A*]highly interweaved with each other	context()	negated: False ,passive: True
0.903	[*A*]This monitoring[*R*]is presented[*A*]in more detail[*A*]in [ 3	context()	negated: False ,passive: True
0.791	[*A*]the KB parts[*R*]are[*A*]highly interweaved with each other	context(we call)	negated: False ,passive: True
0.778	[*A*]Knowledge ManagementSince the plan parts[*R*]are[*A*]highly interweaved with each other	context(we call)	negated: False ,passive: True
0.778	[*A*]Knowledge ManagementSince the analysis parts[*R*]are[*A*]highly interweaved with each other	context(we call)	negated: False ,passive: True
0.467	[*A*]we[*R*]call[*A*]the ensemble of these phases	context()	negated: False ,passive: False
0.754	[*A*]This monitoring framework[*R*]to be[*A*]highly scalable	context()	negated: False ,passive: True
[LINE#41] The knowledge management component receives current information about SLA parameters of each running application from the run-time monitor of the monitoring component.
0.956	[*A*]The knowledge management component[*R*]receives[*A*]current information about SLA parameters of each running application from the run-time monitor of the monitoring component	context()	negated: False ,passive: False
[LINE#42] Depending on the KM technique in use, the KM phase analyzes this data to determine critical situations, where either SLA parameters are about to be violated or too many resources are wasted.
0.776	[*A*]either SLA parameters[*R*]to be violated	context()	negated: False ,passive: False
0.976	[*A*]either SLA parameters[*R*]are[*A*]about to be violated or too many resources are wasted[*A*]critical situations	context()	negated: False ,passive: True
0.933	[*A*]the KM phase[*R*]analyzes[*A*]this data[*A*]to determine critical situations	context()	negated: False ,passive: False
[LINE#43] The analysis component receives the monitoring data, stores it in the KB and queries it to recommend an action to be executed.
0.397	[*A*]it[*R*]to recommend[*A*]an action to be executed	context(The analysis component receives queries)	negated: False ,passive: False
0.744	[*A*]The analysis component[*R*]receives the monitoring data queries[*A*]it to recommend an action	context(The analysis component receives)	negated: False ,passive: False
0.732	[*A*]an action[*R*]to be executed	context()	negated: False ,passive: False
0.778	[*A*]The analysis component[*R*]receives the monitoring data stores[*A*]it[*A*]in the KB	context(The analysis component receives)	negated: False ,passive: False
0.891	[*A*]The analysis component[*R*]receives[*A*]the monitoring data	context()	negated: False ,passive: False
[LINE#44] The plan phase maps these actions onto PMs or plans outsourcing them to other Cloud providers.
0.870	[*A*]PMs or plans[*R*]outsourcing[*A*]them[*A*]to other Cloud providers	context()	negated: False ,passive: False
0.932	[*A*]The plan phase[*R*]maps[*A*]these actions	context()	negated: False ,passive: False
[LINE#45] Finally, the actions are executed (Execution phase) with the help of actuators.
0.830	[*A*]the actions[*R*]are executed[*A*]Finally	context()	negated: False ,passive: True
[LINE#46] Additionally, the KB does not only enable decision making out of current data, i.e., suggesting actions to be executed, but also improving the quality of decisions by keeping track of the success or failure of previous decisions, i.e., learning.
0.769	[*A*]i.e., suggesting actions[*R*]to be executed	context()	negated: False ,passive: False
0.809	[*A*]the KB[*R*]does enable[*A*]decision making out of current data,	context()	negated: False ,passive: False
[LINE#47] The goal of this research field is to enact SLAs in a resource-efficient way with little human-based interaction in order to guarantee the scalability and strengthen the dynamic behavior and adaptation of the system.
0.972	[*A*]The goal of this research field[*R*]is[*A*]to enact SLAs in a resource - efficient way with little human - based interaction in order	context()	negated: False ,passive: True
0.972	[*A*]The goal of this research field[*R*]is[*A*]to enact SLAs in a resource - efficient way with little human - based interaction	context()	negated: False ,passive: True
[LINE#48] Autonomically governing Cloud Computing infrastructures is the investigated method leading to this goal.
0.911	[*A*]the investigated method[*R*]leading[*A*]to this goal	context()	negated: False ,passive: False
0.957	[*A*]Autonomically governing Cloud Computing infrastructures[*R*]is[*A*]the investigated method leading to this goal	context()	negated: False ,passive: True
[LINE#49]  In this paper we have hierarchically structured all possible reallocation actions, and designed, implemented, and evaluated two knowledge management techniques,.
0.595	[*A*]we[*R*]have evaluated[*A*]two knowledge management techniques[*A*]In this paper	context()	negated: False ,passive: False
0.551	[*A*]we[*R*]have implemented[*A*]In this paper	context()	negated: False ,passive: False
0.551	[*A*]we[*R*]have designed[*A*]In this paper	context()	negated: False ,passive: False
0.595	[*A*]we[*R*]have hierarchically structured[*A*]all possible reallocation actions[*A*]In this paper	context()	negated: False ,passive: False
[LINE#50] Case Based Reasoning and a rule-based approach to achieve the aforementioned goal for one reallocation level, i.e., VM reconfiguration.
0.957	[*A*]Case[*R*]Based[*A*]a rule - based approach to achieve the aforementioned goal for one reallocation level , i.e. , VM reconfiguration	context()	negated: False ,passive: False
[LINE#51] After a comparison, we determined the rule-based approach to outperform CBR with respect to violations and utilization, but also to time performance.
0.639	[*A*]we[*R*]determined[*A*]the rule - based approach to outperform CBR[*A*]After a comparison	context()	negated: False ,passive: False
[LINE#52] Furthermore, we applied the rule-based approach to a real-world use case evaluating a scientific workflow from the area of bioinformatics.
0.932	[*A*]a real-world use case[*R*]evaluating[*A*]a scientific workflow from the area of bioinformatics	context()	negated: False ,passive: False
0.452	[*A*]we[*R*]applied[*A*]the rule-based approach[*A*]to a real-world use case	context()	negated: False ,passive: False
[LINE#53] We showed by simulation that the rule-based approach can effectively guarantee the execution of a workload with unpredictably large resource consumptions.
0.939	[*A*]the rule-based approach[*R*]can effectively guarantee[*A*]the execution of a workload with unpredictably large resource consumptions	context(We showed)	negated: False ,passive: False
0.236	[*A*]We[*R*]showed[*A*]that the rule-based approach can effectively guarantee the execution of a workload with unpredictably large resource consumptions	context()	negated: False ,passive: False
[LINE#54] The next step will be to move from simulation to a real Cloud testbed.
0.913	[*A*]The next step[*R*]to move[*A*]from simulation[*A*]to a real Cloud testbed	context()	negated: False ,passive: True
0.925	[*A*]The next step[*R*]will be[*A*]to move from simulation to a real Cloud testbed	context()	negated: False ,passive: True
[LINE#55] Furthermore, the presented methods still involve some user-interaction for parameter tuning.
0.939	[*A*]the presented methods[*R*]involve[*A*]some user-interaction for parameter tuning[*A*]still	context()	negated: False ,passive: True
[LINE#56] Thus, it will be of great interest to autonomically determine crucial parameters of the presented methods and to adapt them based on current performance.
0.309	[*A*]it[*R*]will be[*A*]of great interest[*A*]to adapt them based on current performance	context()	negated: False ,passive: True
0.452	[*A*]it[*R*]will be[*A*]of great interest[*A*]to autonomically determine crucial parameters of the presented methods	context()	negated: False ,passive: True
[LINE#57] Another related field is the autonomic generation of IaaS SLA out of SaaS or PaaS SLAs.
0.963	[*A*]Another related field[*R*]is[*A*]the autonomic generation of IaaS SLA out of SaaS or PaaS SLAs	context()	negated: False ,passive: True
[LINE#58] Theoretically, SaaS or PaaS applications can be perfectly set up on top of IaaS platforms.
0.949	[*A*]SaaS or PaaS applications[*R*]can be perfectly set up[*A*]on top of IaaS platforms	context()	negated: False ,passive: True
[LINE#59] The crucial point is to extract an SLA for the IaaS parameters like bandwidth, storage, CPU power and memory that fit to SaaS/PaaS parameters like response time.
0.736	[*A*]memory[*R*]fit	context()	negated: False ,passive: False
0.963	[*A*]The crucial point[*R*]is[*A*]to extract an SLA for the IaaS parameters like memory	context()	negated: False ,passive: True
0.754	[*A*]CPU power[*R*]fit	context()	negated: False ,passive: False
0.963	[*A*]The crucial point[*R*]is[*A*]to extract an SLA for the IaaS parameters like CPU power	context()	negated: False ,passive: True
0.736	[*A*]storage[*R*]fit	context()	negated: False ,passive: False
0.963	[*A*]The crucial point[*R*]is[*A*]to extract an SLA for the IaaS parameters like storage	context()	negated: False ,passive: True
0.736	[*A*]bandwidth[*R*]fit	context()	negated: False ,passive: False
0.963	[*A*]The crucial point[*R*]is[*A*]to extract an SLA for the IaaS parameters like bandwidth	context()	negated: False ,passive: True
[LINE#60] It is obvious that response time directly relates to the mentioned IaaS parameters and user interaction.
[LINE#61] It is not that obvious, however, how this translation should take place.
0.878	[*A*]this translation[*R*]should take[*A*]place	context(It is not)	negated: False ,passive: True
0.076	[*A*]It[*R*]is not[*A*]that obvious[*A*]however	context()	negated: True ,passive: True
[LINE#62]  E.g., does the SLO " response time<2 s" translate into " memory>512 MB" and " CPU power>8000 MIPS" or rather " memory>4096 MB" and " CPU power>1000 MIPS"?.
0.999	[*A*]the SLO response time[*R*]does s translate[*A*]512 mb "	context()	negated: False ,passive: False
[LINE#63] Once the autonomic governance of IaaS infrastructures is up and running, the autonomic translation of these SLAs will probably leverage the usage and usability of IaaS even more.
0.845	[*A*]the autonomic governance of IaaS infrastructures[*R*]is running	context()	negated: False ,passive: False
0.897	[*A*]the autonomic governance of IaaS infrastructures[*R*]is[*A*]up	context()	negated: False ,passive: True
[LINE#64] this section we evaluate the two presented approaches with several different synthetic and real-world workload data.
0.702	[*A*]we[*R*]evaluate[*A*]the two presented approaches with several different real - world workload data[*A*]this section	context()	negated: False ,passive: False
0.702	[*A*]we[*R*]evaluate[*A*]the two presented approaches with several different synthetic workload data[*A*]this section	context()	negated: False ,passive: False
[LINE#65] For this purpose, we present a KM-agnostic simulation engine that implements the autonomic control loop and simulates executed actions and evaluates their quality responding to the workload data at stake..
0.576	[*A*]their quality[*R*]responding[*A*]to the workload data at stake	context(we present a KM - agnostic simulation engine evaluates)	negated: False ,passive: False
0.886	[*A*]a KM - agnostic simulation engine[*R*]evaluates[*A*]their quality responding to the workload data at stake	context(we present)	negated: False ,passive: False
0.399	[*A*]we[*R*]present[*A*]a KM - agnostic simulation engine evaluates their quality responding to the workload data at stake	context()	negated: False ,passive: False
0.940	[*A*]a KM - agnostic simulation engine[*R*]simulates[*A*]executed actions	context()	negated: False ,passive: False
0.940	[*A*]a KM - agnostic simulation engine[*R*]implements[*A*]the autonomic control loop	context()	negated: False ,passive: False
0.498	[*A*]we[*R*]present[*A*]a KM - agnostic simulation engine	context()	negated: False ,passive: False
[LINE#66] Simulation engine implementing the MAPE-K loopThe goal of the simulation engine is to evaluate the quality of a KM system with respect to the number of SLA violations, the utilization of the resources and the number of required reallocation actions.
0.947	[*A*]Simulation engine[*R*]implementing[*A*]the MAPE - K loopThe goal of the simulation engine	context()	negated: False ,passive: False
[LINE#67+68+69]  Furthermore, the simulation engine serves as an evaluation tool for any KM technique in the field of Cloud Computing, as long as it can implement the two methods of the KB management interface: 1.public void receiveMeasurement(int slaID, String[] provided,String[] measurements,.
0.849	[*A*]the two methods of the KB management interface[*R*]provided	context()	negated: False ,passive: False
0.498	[*A*]it[*R*]can implement[*A*]the two methods of the KB management interface	context()	negated: False ,passive: False
0.951	[*A*]the simulation engine[*R*]serves as long[*A*]as an evaluation tool for any KM technique in the field of Cloud Computing	context()	negated: False ,passive: False
[LINE#70+71]  List<String> violations); and2.public Actions recommendAction(intslaID describes the ID of the SLA that is tied to the specific VM, whose provided and measured values are stored in the arrays provided and measurements, respectively (cf.
0.732	[*A*]the arrays[*R*]provided	context()	negated: False ,passive: False
0.881	[*A*]the specific VM[*R*]provided[*A*]whose	context()	negated: False ,passive: True
0.807	[*A*]the ID of the SLA[*R*]is tied	context()	negated: False ,passive: False
0.932	[*A*]intslaID[*R*]describes[*A*]the ID of the SLA	context()	negated: False ,passive: False
[LINE#72] The list violations contains all SLA parameters being violated for the current measurements.
0.803	[*A*]all SLA parameters[*R*]being violated	context()	negated: False ,passive: False
0.925	[*A*]The list violations[*R*]contains[*A*]all SLA parameters	context()	negated: False ,passive: False
[LINE#73] The method receiveMeasurement inputs new data into the KB, whereas the method recommendActions outputs an action specific to the current measurement of the specified SLA.
0.952	[*A*]the method recommendActions[*R*]outputs[*A*]an action specific to the current measurement of the specified SLA	context()	negated: False ,passive: False
0.952	[*A*]The method receiveMeasurement[*R*]inputs[*A*]new data[*A*]into the KB[*A*]whereas the method recommendActions outputs an action specific to the current measurement of the specified SLA	context()	negated: False ,passive: False
[LINE#74] The simulation engine traverses all parts of the MAPE-K loop as can be seen in Fig. 6 and described in Section 3.
0.903	[*A*]The simulation[*R*]described[*A*]in Section 3	context()	negated: False ,passive: False
0.925	[*A*]The simulation engine[*R*]traverses[*A*]all parts of the MAPE - K loop[*A*]as can be seen in Fig	context()	negated: False ,passive: False
[LINE#75] The simulation engine is iteration based, meaning that in one iteration the MAPE-K loop is traversed exactly once.
0.875	[*A*]The simulation engine[*R*]is based[*A*]meaning that in one iteration the MAPE-K loop is traversed exactly once[*A*]iteration	context()	negated: False ,passive: True
[LINE#76]  (In reality, one iteration could last from some minutes to about an hour depending on the speed of the measurements, the length of time the decision making takes, and the duration of the execution of the actions, for example migrating a resource intensive VM to another PM.).
0.905	[*A*]the actions[*R*]migrating[*A*]a resource intensive[*A*]VM	context()	negated: False ,passive: False
0.943	[*A*]one iteration[*R*]could last[*A*]from some minutes[*A*]to about an hour[*A*]In reality	context()	negated: False ,passive: True
0.930	[*A*]one iteration[*R*]could last[*A*]from some minutes[*A*]In reality	context(the length of time takes)	negated: False ,passive: True
0.691	[*A*]the length of time[*R*]takes	context()	negated: False ,passive: False
0.911	[*A*]about an hour[*R*]depending[*A*]on the speed of the measurements	context()	negated: False ,passive: False
[LINE#77] The Monitoring component receives monitoring information from either synthetic or real-world workload from the current iteration.
0.947	[*A*]The Monitoring component[*R*]receives monitoring[*A*]information[*A*]from either synthetic or real-world workload from the current iteration	context(The Monitoring component receives)	negated: False ,passive: False
0.947	[*A*]The Monitoring component[*R*]receives[*A*]monitoring information from either synthetic or real-world workload from the current iteration	context()	negated: False ,passive: False
[LINE#78] It forwards the data into the Knowledge base (1).
0.498	[*A*]It[*R*]forwards[*A*]the data[*A*]into the Knowledge base	context()	negated: False ,passive: False
[LINE#79] The Knowledge base contains representations of all important objects in the Cloud and their characteristic information.
0.848	[*A*]The Knowledge base[*R*]contains[*A*]representations of all important objects in their characteristic information	context()	negated: False ,passive: False
0.925	[*A*]The Knowledge base[*R*]contains[*A*]representations of all important objects in the Cloud	context()	negated: False ,passive: False
[LINE#80] These objects are the running applications, the virtual machines, and the physical machines with the current state of their CPU power, memory, storage, etc., the corresponding SLAs with their SLOs, and information about other Clouds in the same federation.
0.890	[*A*]These objects[*R*]are[*A*]the physical machines with the current state of their CPU power , memory , storage , etc.	context()	negated: False ,passive: True
0.903	[*A*]These objects[*R*]are[*A*]the virtual machines	context()	negated: False ,passive: True
0.903	[*A*]These objects[*R*]are[*A*]the running applications	context()	negated: False ,passive: True
[LINE#81+82]  Furthermore, the KB also has representations of the inserted measurements, and the available actions to execute(these have to be pre-defined).
0.229	[*A*]these[*R*]to be pre-defined	context()	negated: False ,passive: False
0.879	[*A*]the KB[*R*]has[*A*]representations of the inserted measurements	context()	negated: False ,passive: False
[LINE#83] Finally, the KB also contains a decision mechanism that interprets the state of available objects in order to recommend a reconfiguration action.
0.897	[*A*]a decision mechanism[*R*]interprets[*A*]the state of available objects in order	context()	negated: False ,passive: False
0.852	[*A*]the KB[*R*]contains[*A*]a decision mechanism that interprets the state of available objects in order[*A*]Finally	context()	negated: False ,passive: False
[LINE#84] This mechanism can be substituted by any KM technique; as already mentioned, we used CBR and a rule-based mechanism.
0.388	[*A*]we[*R*]used[*A*]a rule - based mechanism	context()	negated: False ,passive: False
0.896	[*A*]This mechanism[*R*]can be substituted[*A*]by any KM technique	context(we used)	negated: False ,passive: True
0.433	[*A*]we[*R*]used[*A*]CBR	context()	negated: False ,passive: False
[LINE#85+86]  The next step in the MAPE loop is the Analysis component, which queries the KB for actions to recommend (for a specific SLA id); these actions are then returned to the analysis component (3).
0.962	[*A*]The next step in the MAPE loop[*R*]is[*A*]the Analysis component	context(these actions are returned)	negated: False ,passive: True
0.893	[*A*]these actions[*R*]are returned[*A*]to the analysis component[*A*]then	context()	negated: False ,passive: True
0.934	[*A*]the Analysis component[*R*]queries[*A*]the KB[*A*]for actions	context()	negated: False ,passive: False
[LINE#87] The Planning component schedules the suggested actions, and the Execution component executes them.
0.848	[*A*]the Execution component[*R*]executes[*A*]them	context()	negated: False ,passive: False
[LINE#88] The changed state configuration of the Cloud objects are automatically reflected in the KB (4).
0.964	[*A*]The changed state configuration of the Cloud objects[*R*]are automatically reflected[*A*]in the KB (4	context()	negated: False ,passive: True
[LINE#89] The Monitoring and the Execution components are simulated.
0.751	[*A*]the Execution components[*R*]are simulated	context()	negated: False ,passive: False
0.817	[*A*]The Monitoring[*R*]are[*A*]simulated	context()	negated: False ,passive: True
[LINE#90] This means that the monitoring data is not measured on a real system during the simulation, even though it handles input measured at a real system or synthetic workloads generated beforehand (see Sections 6.3 and 6.4).
0.829	[*A*]a real system or synthetic workloads[*R*]generated[*A*]beforehand	context()	negated: False ,passive: True
0.894	[*A*]input[*R*]measured[*A*]at a real system or synthetic workloads	context()	negated: False ,passive: True
0.877	[*A*]the monitoring data[*R*]is not measured[*A*]on a real system[*A*]during the simulation[*A*]even though it handles input measured at a real system or synthetic workloads generated beforehand (see Sections 6.3 and 6.4	context(This means)	negated: True ,passive: True
0.135	[*A*]This[*R*]means[*A*]that the monitoring data is not measured on a real system during the simulation, even though it handles input measured at a real system or synthetic workloads generated beforehand (see Sections 6.3 and 6.4)	context()	negated: False ,passive: False
[LINE#91] The Execution component updates the object representation of the manipulated objects in the KB, but obviously does not actually manipulate real-world objects.
0.837	[*A*]The Execution[*R*]does not manipulate[*A*]real - world objects	context()	negated: True ,passive: False
0.952	[*A*]The Execution component[*R*]updates[*A*]the object representation of the manipulated objects in the KB	context()	negated: False ,passive: False
[LINE#92] The quality of the decision making can ultimately be judged by the number of occurred SLA violations, resource wastage and the number of needed reallocation actions. .
0.917	[*A*]The quality of the decision[*R*]can be judged[*A*]by the number of the number of needed reallocation actions	context()	negated: False ,passive: True
0.873	[*A*]The quality of the decision[*R*]can be judged[*A*]by the number of resource wastage	context()	negated: False ,passive: True
0.892	[*A*]The quality of the decision[*R*]can be judged[*A*]by the number of occurred SLA violations	context()	negated: False ,passive: True
[LINE#93] Performance indicatorsThe subsequent evaluations will be based on the following performance indicators: violations, utilization, actions, resource allocation efficiency (RAE), costs, and time efficiency.
0.919	[*A*]Performance indicatorsThe subsequent evaluations[*R*]will be based[*A*]on the following performance indicators	context()	negated: False ,passive: True
[LINE#94] Whereas the first three and the last one are rather self-explanatory, costs and RAE need a little more explanation.
0.911	[*A*]the last one[*R*]are[*A*]rather self - explanatory	context()	negated: False ,passive: True
0.920	[*A*]RAE[*R*]need[*A*]a little more explanation	context()	negated: False ,passive: False
0.813	[*A*]costs[*R*]need[*A*]a little more explanation	context()	negated: False ,passive: False
0.592	[*A*]the first three[*R*]are[*A*]rather self - explanatory	context()	negated: False ,passive: True
[LINE#95+96]  So violations and actions measure (as a percentage)the amount of occurring violations/actions in relation to all possible violations/actions, and utilization the average utilization over all iterations (and over all SLA parameters, if they are not shown explicitly).
0.320	[*A*]they[*R*]are not shown explicitly	context()	negated: True ,passive: False
[LINE#97] Time efficiency measures the average time that is needed to handle one VM in one iteration.
0.897	[*A*]the average time[*R*]is needed[*A*]to handle one VM in one iteration	context()	negated: False ,passive: True
[LINE#98] For resource allocation efficiency we want to relate violations and utilization.
0.388	[*A*]we[*R*]want to relate[*A*]utilization	context(we want)	negated: False ,passive: False
0.457	[*A*]we[*R*]want[*A*]to relate utilization	context()	negated: False ,passive: False
0.388	[*A*]we[*R*]want to relate[*A*]violations	context(we want)	negated: False ,passive: False
0.457	[*A*]we[*R*]want[*A*]to relate violations	context()	negated: False ,passive: False
[LINE#99+100+101]  is that RAE should equal utilization (100%-w, where w stands for wastage, see below) if no violations occur (p=0%, where p stands for penalty, see below), equal 0if the violation rate is at 100%, and follow a linear decrease in between.
0.852	[*A*]p[*R*]stands[*A*]for penalty	context()	negated: False ,passive: True
0.732	[*A*]no violations[*R*]occur	context()	negated: False ,passive: False
0.449	[*A*]w[*R*]stands[*A*]for wastage	context()	negated: False ,passive: True
[LINE#102] Thus, we define (7)RAE=(100-w)(100-p)100.A more general approach also taking into account the cost of actions represents the definition of a generic cost function that maps SLA violations, resource wastage and the costs of executed actions into a monetary unit, which we want to call Cloud EUR.
0.999	[*A*]we[*R*]define[*A*]7	context()	negated: False ,passive: False
0.893	[*A*]a monetary unit[*R*]to call[*A*]Cloud EUR	context(we want)	negated: False ,passive: True
0.884	[*A*]100.A more general approach[*R*]taking[*A*]into account[*A*]the cost of actions	context(we define)	negated: False ,passive: False
0.162	[*A*]we[*R*]define	context()	negated: False ,passive: False
0.893	[*A*]a monetary unit[*R*]to call[*A*]Cloud EUR	context(we want)	negated: False ,passive: True
0.513	[*A*]we[*R*]want[*A*]to call Cloud EUR	context()	negated: False ,passive: False
0.938	[*A*]a generic cost function[*R*]maps[*A*]SLA violations	context()	negated: False ,passive: False
0.897	[*A*]more general approach[*R*]taking[*A*]into account[*A*]the cost of actions	context()	negated: False ,passive: False
[LINE#103+104+105]  First, we define a penalty function pr(p):[0,100]R+ that defines the relationship between the percentage of violations p (as opposed to all possible violations) and the penalty for a violation of resource r. Secondthat relates the percentage of unused resources w to the energy in terms of money that these resources unnecessarily consume.
0.640	[*A*]these resources[*R*]consume	context(we define Secondthat relates)	negated: False ,passive: False
0.898	[*A*]Secondthat[*R*]relates[*A*]the percentage of unused resources[*A*]in terms of money	context(we define)	negated: False ,passive: False
0.388	[*A*]we[*R*]define[*A*]a penalty function pr	context()	negated: False ,passive: False
0.889	[*A*]R+[*R*]defines[*A*]the relationship between the percentage of violations p (as opposed to all possible violations) and the penalty for a violation of resource	context()	negated: False ,passive: False
[LINE#106] Third, we define a cost function ar(a):[0,100]R+ from the percentage of executed actions a (as opposed to all possible actions that could have been executed) to the energy and time costs in terms of money.
0.326	[*A*]we[*R*]define[*A*]a cost function ar[*A*]a ( as opposed to all possible actions that could have been executed ) to the time costs in terms of money	context()	negated: False ,passive: False
0.718	[*A*]all possible actions[*R*]could have been executed	context()	negated: False ,passive: False
0.452	[*A*]we[*R*]define[*A*]a cost function ar	context()	negated: False ,passive: False
[LINE#107] The total cost c is then defined as (8)c(p,w,c)=rpr(p)+wr(w)+ar(a).
0.929	[*A*]The total cost c[*R*]is defined[*A*]as (8)c(p,w[*A*]then	context()	negated: False ,passive: True
[LINE#108] We assume functions pr,wr and ar for this evaluation with pr(p)=100p, wr(w)=5w, and ar(a)=a for all r.
0.514	[*A*]We[*R*]assume[*A*]functions pr , ar for this evaluation with pr ar	context()	negated: False ,passive: False
0.514	[*A*]We[*R*]assume[*A*]functions pr , ar for this evaluation with pr wr ( w ) =5w	context()	negated: False ,passive: False
0.397	[*A*]We[*R*]assume[*A*]functions pr , ar for this evaluation with pr	context()	negated: False ,passive: False
0.725	[*A*]functions[*R*]pr	context(We assume)	negated: False ,passive: False
0.397	[*A*]We[*R*]assume[*A*]functions pr , wr	context()	negated: False ,passive: False
0.736	[*A*]functions[*R*]wr	context()	negated: False ,passive: False
[LINE#109] The intention behind choosing these functions is (i) to impose very strict fines in order to proclaim SLA adherence as top priority, (ii) to weigh resource wastage a little more than the cost of actions.
[LINE#110] The cost function is currently not evaluated within the simulation engine, it is a value calculated after the simulation for comparison reasons.
0.905	[*A*]The cost function[*R*]is not evaluated[*A*]within the simulation engine[*A*]currently	context(it is)	negated: True ,passive: True
0.467	[*A*]it[*R*]is[*A*]a value calculated after the simulation for comparison reasons	context()	negated: False ,passive: True
0.903	[*A*]a value[*R*]calculated[*A*]after the simulation for comparison reasons	context()	negated: False ,passive: True
[LINE#111] Thus, the recommended actions do not depend on the specific functions we assumed.
0.894	[*A*]the specific functions[*R*]assumed[*A*]we	context()	negated: False ,passive: True
0.911	[*A*]the recommended actions[*R*]do not depend[*A*]on the specific functions	context()	negated: True ,passive: False
[LINE#112] However, it could be incorporated into the KB in order to adjust and learn the TTs for every resource r. .
0.498	[*A*]it[*R*]could be incorporated[*A*]into the KB[*A*]in order	context()	negated: False ,passive: True
[LINE#113] Evaluation and comparison of CBR and rules using synthetic dataTo evaluate a great variety of workload data, one approach is to create them synthetically.
0.927	[*A*]synthetic dataTo[*R*]evaluate[*A*]a great variety of workload data	context()	negated: False ,passive: False
0.911	[*A*]rules[*R*]using[*A*]synthetic dataTo evaluate a great variety of workload data	context()	negated: False ,passive: False
0.870	[*A*]one approach[*R*]is[*A*]to create them synthetically	context()	negated: False ,passive: True
[LINE#114] For this, we extended the workload generator as described in [7] to allow a categorization of data volatility.
0.569	[*A*]we[*R*]extended[*A*]the workload generator[*A*]as described in [7] to allow a categorization of data volatility	context()	negated: False ,passive: False
[LINE#115] The workload generator is intended to generate very general workloads for IaaS platforms dealing with slower developments as well as rapid changes.
0.927	[*A*]IaaS platforms[*R*]dealing[*A*]with rapid changes	context()	negated: False ,passive: False
0.927	[*A*]IaaS platforms[*R*]dealing[*A*]with slower developments	context()	negated: False ,passive: False
0.913	[*A*]The workload generator[*R*]to generate[*A*]very general workloads for IaaS platforms	context()	negated: False ,passive: False
0.925	[*A*]The workload generator[*R*]is intended[*A*]to generate very general workloads for IaaS platforms	context()	negated: False ,passive: True
[LINE#116]  For one parameter, the workload is generated as follows:.
0.767	[*A*]the workload[*R*]is generated[*A*]as follows:.	context()	negated: False ,passive: True
[LINE#117+118]  The initial value of the workloads is randomly drawn from a Gaussian distribution with =SLO2 and =SLO8, where SLO represents the Service Level Objective value agreed in the SLA.
0.877	[*A*]SLO[*R*]represents[*A*]the Service Level Objective value	context()	negated: False ,passive: False
0.932	[*A*]The initial value of the workloads[*R*]is randomly drawn[*A*]from a Gaussian distribution with =SLO2 and =SLO8	context()	negated: False ,passive: True
[LINE#119] Then, an up- or down-trend is randomly drawn, as well as a duration of this trend between a pre-defined number of iterations (for our evaluation this interval of iterations equals [2,6]), both with equal probability.
[LINE#120] For every iteration, as long as the trend lasts, the current measured value is increased or decreased (depending on the trend) by a percentage evenly drawn from the interval [iBegin,iEnd].
0.903	[*A*]a percentage[*R*]evenly drawn[*A*]from the interval	context()	negated: False ,passive: True
0.934	[*A*]the current measured value[*R*]decreased[*A*]depending on the trend) by a percentage[*A*]as long as the trend lasts	context()	negated: False ,passive: True
0.944	[*A*]the current measured value[*R*]is increased[*A*]as long as the trend lasts	context()	negated: False ,passive: True
0.784	[*A*]the trend[*R*]lasts	context()	negated: False ,passive: False
[LINE#121] After the trend is over, a new trend is drawn and the iterations continue as described before.
0.767	[*A*]the iterations[*R*]continue[*A*]as described before	context()	negated: False ,passive: True
0.939	[*A*]a new trend[*R*]is drawn[*A*]After the trend is over	context()	negated: False ,passive: True
0.813	[*A*]the trend[*R*]is[*A*]over	context()	negated: False ,passive: True
[LINE#122] Clearly, the values for iBegin and iEnd determine the difficulty for handling the workload.
0.850	[*A*]the values for iEnd[*R*]determine for handling[*A*]the workload	context(the values for iEnd determine)	negated: False ,passive: False
0.897	[*A*]the values for iEnd[*R*]determine[*A*]the difficulty for handling the workload	context()	negated: False ,passive: False
0.885	[*A*]the values for iBegin[*R*]determine for handling[*A*]the workload	context(the values for iBegin determine)	negated: False ,passive: False
0.922	[*A*]the values for iBegin[*R*]determine[*A*]the difficulty for handling the workload	context()	negated: False ,passive: False
[LINE#123] A workload that operates with low iBegin and iEnd values exhibits only very slight changes and does not, consequently, need a lot of dynamic adaptations.
0.698	[*A*]A workload[*R*]operates	context()	negated: False ,passive: False
0.859	[*A*]A workload[*R*]does not need[*A*]a lot of dynamic adaptations	context()	negated: True ,passive: False
[LINE#124] Large iEnd values, on the contrary, need the enforcement mechanisms to be very elastically tuned.
0.718	[*A*]Large iEnd values[*R*]very elastically tuned	context()	negated: False ,passive: False
0.754	[*A*]Large iEnd values[*R*]to be[*A*]very elastically tuned	context()	negated: False ,passive: True
0.897	[*A*]Large iEnd values[*R*]need[*A*]the enforcement mechanisms[*A*]to be very elastically tuned	context()	negated: False ,passive: False
[LINE#125] For the evaluation and comparison of CBR and the rule-based approach we defined a LOW_MEDIUM workload volatility class with iEnd=18%.
0.639	[*A*]we[*R*]defined[*A*]a LOW_MEDIUM workload volatility class[*A*]with iEnd=18 %[*A*]For the rule - based approach	context()	negated: False ,passive: False
0.639	[*A*]we[*R*]defined[*A*]a LOW_MEDIUM workload volatility class[*A*]with iEnd=18 %[*A*]For comparison of CBR	context()	negated: False ,passive: False
0.639	[*A*]we[*R*]defined[*A*]a LOW_MEDIUM workload volatility class[*A*]with iEnd=18 %[*A*]For the evaluation	context()	negated: False ,passive: False
[LINE#126] For the further evaluation of the rule-based approach we defined and tested LOW, MEDIUM, MEDIUM_HIGH and HIGH workload volatility classes (not shown here) with iEnd=10%, 50%, 75%, and 100%, respectively.
0.413	[*A*]workload volatility classes not shown here respectively[*R*]have % of[*A*]100 %	context()	negated: False ,passive: False
0.413	[*A*]workload volatility classes not shown here respectively[*R*]have % of[*A*]75 %	context()	negated: False ,passive: False
0.413	[*A*]workload volatility classes not shown here respectively[*R*]have % of[*A*]50 %	context()	negated: False ,passive: False
0.754	[*A*]workload volatility classes[*R*]not shown[*A*]here	context()	negated: True ,passive: True
0.911	[*A*]the rule - based approach[*R*]defined[*A*]we	context()	negated: False ,passive: True
[LINE#127] As a minimum change we set iBegin=2% for all classes.
0.999	[*A*]we[*R*]set[*A*]2 %	context()	negated: False ,passive: False
0.522	[*A*]we[*R*]set[*A*]iBegin=2%	context()	negated: False ,passive: False
[LINE#128] As the crucial parameters for CBR and the rule-based approach differ, we define scenarios for both approaches separately, but still compare them to the aforementioned six performance indicators.
0.403	[*A*]we[*R*]compare[*A*]them[*A*]to the aforementioned six performance indicators[*A*]still	context()	negated: False ,passive: False
0.843	[*A*]the crucial parameters for the rule - based approach[*R*]differ	context()	negated: False ,passive: False
0.445	[*A*]we[*R*]define separately[*A*]scenarios for both approaches	context()	negated: False ,passive: False
0.832	[*A*]the crucial parameters for CBR[*R*]differ	context()	negated: False ,passive: False
[LINE#129] As resources for IaaS one can use all parameters that can be adapted on a VM.
0.905	[*A*]all parameters[*R*]can be adapted[*A*]on a VM	context()	negated: False ,passive: True
0.413	[*A*]one[*R*]can use[*A*]all parameters that can be adapted on a VM	context()	negated: False ,passive: False
[LINE#130+131]  For the evaluation we chose to take the following parameters and SLOs for CBR: storage1000GB,incomingbandwidth20Mbit/s, and the following parameters and SLOs for the rule-based approach: storage1000GB,incomingbandwidth20Mbit/s,outgoing bandwidth50Mbit/s,memory512MB, and CPU power100MIPS(Million Instructions Per Second).As far as CBR is concerned, its behavior differs by the  value in Eq.
0.634	[*A*]CBR[*R*]is concerned	context()	negated: False ,passive: False
0.341	[*A*]its behavior[*R*]differs	context()	negated: False ,passive: False
0.560	[*A*]we[*R*]chose to take[*A*]the following parameters and SLOs for CBR: storage1000GB,incomingbandwidth20Mbit/s, and the following parameters and SLOs for the rule-based approach	context(we chose)	negated: False ,passive: False
0.560	[*A*]we[*R*]chose[*A*]to take the following parameters and SLOs for CBR: storage1000GB,incomingbandwidth20Mbit/s, and the following parameters and SLOs for the rule-based approach	context()	negated: False ,passive: False
[LINE#132] (setting importance to avoiding violations or achieving high utilization), by the number of executed iterations, because of its inherent learning feature, and the initial cases.
[LINE#133] At the beginning, we configure all 50 VMs exactly equally with 80% of the storage SLO value and two-thirds of the bandwidth SLO value provided.
0.999	[*A*]we[*R*]configure[*A*]50 vms	context()	negated: False ,passive: False
0.818	[*A*]the bandwidth SLO value[*R*]provided	context()	negated: False ,passive: False
0.740	[*A*]we[*R*]configure[*A*]all 50 VMs[*A*]exactly equally with 80% of the storage SLO value and two-thirds of the bandwidth SLO value[*A*]At the beginning	context()	negated: False ,passive: False
[LINE#134] Then, we execute 2, 5, 10 and 20 iterations with values for  being 0.1, 0.2, 0.3, 0.4, 0.5, 0.6 and 0.8.
0.595	[*A*]we[*R*]execute[*A*]20 iterations with values[*A*]for being 0.8[*A*]Then	context()	negated: False ,passive: False
0.595	[*A*]we[*R*]execute[*A*]20 iterations with values[*A*]for being 0.6[*A*]Then	context()	negated: False ,passive: False
0.595	[*A*]we[*R*]execute[*A*]20 iterations with values[*A*]for being 0.5[*A*]Then	context()	negated: False ,passive: False
0.595	[*A*]we[*R*]execute[*A*]20 iterations with values[*A*]for being 0.4[*A*]Then	context()	negated: False ,passive: False
0.595	[*A*]we[*R*]execute[*A*]20 iterations with values[*A*]for being 0.3[*A*]Then	context()	negated: False ,passive: False
0.595	[*A*]we[*R*]execute[*A*]20 iterations with values[*A*]for being 0.2[*A*]Then	context()	negated: False ,passive: False
0.999	[*A*]we[*R*]execute[*A*]20 iterations	context()	negated: False ,passive: False
0.595	[*A*]we[*R*]execute[*A*]20 iterations with values[*A*]for being 0.1[*A*]Then	context()	negated: False ,passive: False
0.595	[*A*]we[*R*]execute[*A*]10 iterations with values[*A*]for being 0.8[*A*]Then	context()	negated: False ,passive: False
0.595	[*A*]we[*R*]execute[*A*]10 iterations with values[*A*]for being 0.6[*A*]Then	context()	negated: False ,passive: False
0.595	[*A*]we[*R*]execute[*A*]10 iterations with values[*A*]for being 0.5[*A*]Then	context()	negated: False ,passive: False
0.595	[*A*]we[*R*]execute[*A*]10 iterations with values[*A*]for being 0.4[*A*]Then	context()	negated: False ,passive: False
0.595	[*A*]we[*R*]execute[*A*]10 iterations with values[*A*]for being 0.3[*A*]Then	context()	negated: False ,passive: False
0.595	[*A*]we[*R*]execute[*A*]10 iterations with values[*A*]for being 0.2[*A*]Then	context()	negated: False ,passive: False
0.999	[*A*]we[*R*]execute[*A*]10 iterations	context()	negated: False ,passive: False
0.595	[*A*]we[*R*]execute[*A*]10 iterations with values[*A*]for being 0.1[*A*]Then	context()	negated: False ,passive: False
0.595	[*A*]we[*R*]execute[*A*]5 iterations with values[*A*]for being 0.8[*A*]Then	context()	negated: False ,passive: False
0.595	[*A*]we[*R*]execute[*A*]5 iterations with values[*A*]for being 0.6[*A*]Then	context()	negated: False ,passive: False
0.595	[*A*]we[*R*]execute[*A*]5 iterations with values[*A*]for being 0.5[*A*]Then	context()	negated: False ,passive: False
0.595	[*A*]we[*R*]execute[*A*]5 iterations with values[*A*]for being 0.4[*A*]Then	context()	negated: False ,passive: False
0.595	[*A*]we[*R*]execute[*A*]5 iterations with values[*A*]for being 0.3[*A*]Then	context()	negated: False ,passive: False
0.595	[*A*]we[*R*]execute[*A*]5 iterations with values[*A*]for being 0.2[*A*]Then	context()	negated: False ,passive: False
0.999	[*A*]we[*R*]execute[*A*]5 iterations	context()	negated: False ,passive: False
0.595	[*A*]we[*R*]execute[*A*]5 iterations with values[*A*]for being 0.1[*A*]Then	context()	negated: False ,passive: False
0.595	[*A*]we[*R*]execute[*A*]2 iterations with values[*A*]for being 0.8[*A*]Then	context()	negated: False ,passive: False
0.595	[*A*]we[*R*]execute[*A*]2 iterations with values[*A*]for being 0.6[*A*]Then	context()	negated: False ,passive: False
0.595	[*A*]we[*R*]execute[*A*]2 iterations with values[*A*]for being 0.5[*A*]Then	context()	negated: False ,passive: False
0.595	[*A*]we[*R*]execute[*A*]2 iterations with values[*A*]for being 0.4[*A*]Then	context()	negated: False ,passive: False
0.595	[*A*]we[*R*]execute[*A*]2 iterations with values[*A*]for being 0.3[*A*]Then	context()	negated: False ,passive: False
0.595	[*A*]we[*R*]execute[*A*]2 iterations with values[*A*]for being 0.2[*A*]Then	context()	negated: False ,passive: False
0.999	[*A*]we[*R*]execute[*A*]2 iterations	context()	negated: False ,passive: False
0.595	[*A*]we[*R*]execute[*A*]2 iterations with values[*A*]for being 0.1[*A*]Then	context()	negated: False ,passive: False
[LINE#135] We omit values 0.2 and 0.4 in the evaluation because their outcomes do not differ enough from the values shown, and all values > 0.5, because they reveal unacceptable high SLA violation rates.
0.350	[*A*]We[*R*]omit[*A*]0.4[*A*]in the evaluation[*A*]because all values >[*A*]0.5[*A*]because they reveal unacceptable high SLA violation rates	context()	negated: False ,passive: False
0.999	[*A*]We[*R*]omit[*A*]0.4	context()	negated: False ,passive: False
0.463	[*A*]We[*R*]omit[*A*]0.4[*A*]in the evaluation[*A*]because their outcomes do not differ enough from the values shown 0.5 , because they reveal unacceptable high SLA violation rates	context()	negated: False ,passive: False
0.350	[*A*]We[*R*]omit[*A*]values[*A*]in the evaluation[*A*]because all values >[*A*]because they reveal unacceptable high SLA violation rates	context()	negated: False ,passive: False
0.658	[*A*]they[*R*]reveal[*A*]unacceptable high SLA violation rates	context()	negated: False ,passive: False
0.784	[*A*]the values[*R*]shown	context()	negated: False ,passive: False
0.341	[*A*]their outcomes[*R*]do not differ enough	context()	negated: True ,passive: False
0.463	[*A*]We[*R*]omit[*A*]values[*A*]in the evaluation[*A*]because their outcomes do not differ enough from the values shown 0.5 , because they reveal unacceptable high SLA violation rates	context()	negated: False ,passive: False
[LINE#136] Setting up the initial cases was done by choosing one representative case for each action that could be triggered.
0.698	[*A*]each action[*R*]could be triggered	context()	negated: False ,passive: False
0.785	[*A*]Setting up the initial cases[*R*]was done	context()	negated: False ,passive: False
[LINE#137] For our evaluation the SLA parameters bandwidth and storage (even though not being tied to them in any way-we could have also named them, e.g., memory and CPU time) were taken into consideration resulting in nine possible actions "Increase/Decrease bandwidth by 10%/20%", "Increase/Decrease storage by 10%/20%", and "Do nothing".
0.303	[*A*]we[*R*]could have named e.g.[*A*]them	context()	negated: False ,passive: False
0.310	[*A*]we[*R*]could have named e.g.[*A*]memory time	context()	negated: False ,passive: False
[LINE#138]  Taking storage for example, we divide the range of distances for storage St between measured and provided resources into five parts as depicted in Fig..
0.550	[*A*]we[*R*]divide[*A*]the range of distances for storage St between measured and provided resources into five parts	context()	negated: False ,passive: False
0.905	[*A*]five parts[*R*]depicted[*A*]in Fig	context()	negated: False ,passive: True
[LINE#139]  We choose some reasonable threshold for every action as follows:.
0.452	[*A*]We[*R*]choose[*A*]some reasonable threshold for every action as follows:.	context()	negated: False ,passive: False
[LINE#140+141+142]  If pSt-mSt=-10 then action "Increase Storage by 20%" as this already is a violation; if pSt--mSt=+50 then action "Increase Storage by 10%" as resources are already scarce but not so problematic as in the previous case; if pSt-mSt=+100 then action "Do nothing" as resources are neither very over- nor under-provisioned; if pSt-mSt=+200 then action "Decrease Storage by 10%" as now resources are over-provisioned; and we set action "Decrease Storage by 20%" when we are over the latest threshold as thenresources are extremely over-provisioned.
0.913	[*A*]then action[*R*]Do[*A*]nothing	context()	negated: False ,passive: False
0.452	[*A*]we[*R*]are[*A*]over the latest threshold	context()	negated: False ,passive: True
0.749	[*A*]resources[*R*]are[*A*]already[*A*]scarce	context()	negated: False ,passive: True
0.672	[*A*]we[*R*]set[*A*]action[*A*]pSt-mSt=+100 then action "Do nothing" as resources are neither very over- nor under-provisioned; if pSt-mSt=+200 then action "Decrease Storage by 10%" as now resources are over-provisioned; and we set action "Decrease Storage by 20%" when we are over the latest threshold as thenresources are extremely over-provisioned	context()	negated: False ,passive: False
0.765	[*A*]pSt[*R*]then Increase[*A*]Storage[*A*]by 10%	context()	negated: False ,passive: False
0.749	[*A*]thenresources[*R*]are[*A*]extremely over-provisioned	context()	negated: False ,passive: True
0.816	[*A*]resources[*R*]are over-provisioned[*A*]now	context()	negated: False ,passive: True
0.552	[*A*]this[*R*]is[*A*]a violation[*A*]then[*A*]already	context()	negated: False ,passive: True
0.749	[*A*]resources[*R*]are[*A*]neither very over- nor under-provisioned	context()	negated: False ,passive: True
[LINE#143] We choose the values for our initial cases from the center of the respective intervals.
0.418	[*A*]We[*R*]choose[*A*]the values for our initial cases from the center of the respective intervals	context()	negated: False ,passive: False
[LINE#144+145]  Ultimately, for the initial case for the action, e.g., "Increase Storage by 20%" we take the just mentioned value for storage and the "Do nothing" value for bandwidth.
0.614	[*A*]we[*R*]take[*A*]the just mentioned value for storage and the "Do nothing" value for bandwidth	context()	negated: False ,passive: False
[LINE#146] This leads to c=(id,0,-10,0,7.5), and because only the differences between the values matter, it is equivalent to, e.g., c=(id,200,190,7.5,15.0).As far as the rule-based approach is concerned, its behavior differs by the set threat thresholds.
0.785	[*A*]the rule-based approach[*R*]is concerned	context()	negated: False ,passive: False
0.392	[*A*]This[*R*]leads[*A*]to c=(id,0,-10,0,7.5[*A*]because only the differences between the values matter, it is equivalent to, e.g., c=(id,200,190,7.5,15.0).As far as the rule-based approach is concerned, its behavior differs by the set threat thresholds	context()	negated: False ,passive: False
[LINE#147] Thus, we investigate low, middle and high values for TTlowr and TThighr (as defined in Section 5.3), where TTlowr{30%,50%,70%} and TThighr{60%,75%,90%} for all resources stated above.
0.767	[*A*]all resources[*R*]stated[*A*]above	context()	negated: False ,passive: True
0.614	[*A*]we[*R*]investigate[*A*]low, middle and high values for TTlowr and TThighr (as defined in Section 5.3), where TTlowr{30%,50%,70%} and TThighr{60%,75%,90%} for all resources	context()	negated: False ,passive: False
[LINE#148] We combine the TTs to form eight different scenarios as depicted in Table 4.
0.433	[*A*]We[*R*]combine the TTs to form[*A*]eight different scenarios as depicted in Table 4	context(We combine)	negated: False ,passive: False
0.433	[*A*]We[*R*]combine[*A*]the TTs[*A*]to form eight different scenarios	context()	negated: False ,passive: False
0.913	[*A*]eight different scenarios[*R*]depicted[*A*]in Table 4	context()	negated: False ,passive: True
[LINE#149] We execute 100 iterations with 500 applications, and set the "safety slack" =5% (cf.
0.452	[*A*]We[*R*]execute[*A*]100 iterations	context()	negated: False ,passive: False
[LINE#150] 8 presents the aforementioned performance indicators of CBR.
0.425	[*A*]8[*R*]presents[*A*]the aforementioned performance indicators of CBR	context()	negated: False ,passive: False
[LINE#151] The "No CBR" line means that the autonomic manager is turned off, which implies that the configuration of the VMs is left as set at the beginning, i.e., no adaptation actions due to changing demands are executed.
0.707	[*A*]the autonomic manager[*R*]is turned off	context(The " No CBR " line means)	negated: False ,passive: False
0.913	[*A*]The "No CBR" line[*R*]means[*A*]that the autonomic manager is turned off, which implies that the configuration of the VMs is left as set at the beginning, i.e., no adaptation actions due to changing demands	context()	negated: False ,passive: False
0.737	[*A*]set at the beginning[*R*]are executed	context()	negated: False ,passive: False
[LINE#152] we see that up to more than half of the violations can be avoided when using {0.1,0.3} instead of no autonomic management.
0.796	[*A*]up to more than half of the violations[*R*]can be avoided	context(we see)	negated: False ,passive: False
0.078	[*A*]we[*R*]see[*A*]that	context()	negated: False ,passive: False
[LINE#153] However, fewer SLA violations result in lower resource utilization (cf.
0.933	[*A*]fewer SLA violations[*R*]result[*A*]in lower resource utilization	context()	negated: False ,passive: True
[LINE#154] Fig. 8(b)), as more resources have to be provided than can actually be utilized.
0.698	[*A*]more resources[*R*]to be provided	context()	negated: False ,passive: False
[LINE#155+156]  Reconfiguration actions as depicted in Fig.8(c) lie slightly below or at 50%, except for "No CBR", of course.
0.940	[*A*]Reconfiguration actions as depicted in Fig.8[*R*]lie[*A*]slightly below or at 50%	context()	negated: False ,passive: True
[LINE#157] Another point that can be observed is that after a certain amount of iterations the quality of the recommended actions decreases.
0.756	[*A*]a certain amount of iterations[*R*]decreases	context()	negated: False ,passive: False
0.938	[*A*]Another point that can be observed[*R*]is[*A*]after a certain amount of iterations	context()	negated: False ,passive: True
0.698	[*A*]Another point[*R*]can be observed	context()	negated: False ,passive: False
[LINE#158] This is probably due to the fact that the initial cases get more and more blurred when more cases are stored into CBR, as all new cases are being learned and there is no distinction made between "interesting" and "uninteresting" cases.
0.942	[*A*]the initial cases[*R*]get[*A*]more blurred when more cases are stored into CBR	context()	negated: False ,passive: True
0.903	[*A*]no distinction[*R*]made[*A*]between " uninteresting " cases	context()	negated: False ,passive: True
0.903	[*A*]no distinction[*R*]made[*A*]between " interesting " cases	context()	negated: False ,passive: True
0.828	[*A*]the initial cases[*R*]get[*A*]more	context()	negated: False ,passive: False
0.238	[*A*]This[*R*]is[*A*]probably[*A*]due to the fact that the initial cases get more when more cases are stored into CBR , there is no distinction	context()	negated: False ,passive: True
0.828	[*A*]the initial cases[*R*]get[*A*]more blurred	context()	negated: False ,passive: True
0.323	[*A*]This[*R*]is[*A*]probably[*A*]due to the fact that the initial cases get more blurred	context()	negated: False ,passive: True
0.751	[*A*]all new cases[*R*]are being learned	context()	negated: False ,passive: False
0.918	[*A*]more cases[*R*]are stored[*A*]into CBR	context()	negated: False ,passive: True
0.942	[*A*]the initial cases[*R*]get[*A*]more[*A*]when more cases are stored into CBR	context()	negated: False ,passive: False
0.323	[*A*]This[*R*]is[*A*]probably[*A*]due to the fact that the initial cases get more	context()	negated: False ,passive: True
[LINE#159] Nevertheless, when we relate SLA violations and resource utilization in terms of RAE, all CBR methods are generally better than the default method, especially for {0.3,0.5} after five iterations.
0.942	[*A*]all CBR methods[*R*]are[*A*]generally better than the default method[*A*]when we relate resource utilization in terms of RAE	context()	negated: False ,passive: True
0.452	[*A*]we[*R*]relate[*A*]resource utilization	context()	negated: False ,passive: False
0.942	[*A*]all CBR methods[*R*]are[*A*]generally better than the default method[*A*]when we relate SLA violations in terms of RAE	context()	negated: False ,passive: True
0.498	[*A*]we[*R*]relate[*A*]SLA violations	context()	negated: False ,passive: False
[LINE#160] Yet, RAE decreases strictly monotonically for all .
0.802	[*A*]RAE[*R*]decreases strictly monotonically[*A*]for all	context()	negated: False ,passive: True
[LINE#161] Furthermore, costs-relating violations, utilization and reconfiguration actions-can also be reduced to half for {0.1,0.3}.
0.993	[*A*]reconfiguration actions[*R*]can be reduced for[*A*]0.10.3 }	context()	negated: False ,passive: False
0.602	[*A*]reconfiguration actions[*R*]can be reduced[*A*]for { 0.1,0.3	context()	negated: False ,passive: True
0.824	[*A*]utilization[*R*]can be reduced[*A*]to half[*A*]for { 0.1,0.3	context()	negated: False ,passive: True
0.993	[*A*]costs relating violations[*R*]can be reduced for[*A*]0.10.3 }	context()	negated: False ,passive: False
0.647	[*A*]costs - relating violations[*R*]can be reduced[*A*]for { 0.1,0.3	context()	negated: False ,passive: True
[LINE#162] However, there is a seemingly exponential increase in the average execution time per VM (cf.
[LINE#163+164]  due to higher number of cases stored in the KB.Summing up, the simulation shows that learning did take place (and cost some time) and that CBR is able to recommend right actions for many cases, i.e., to correctly handle and interpret the measurement information that is based on a random distribution not known to CBR.Fig.9 shows the same evaluation for the rule-based approach evaluating the aforementioned eight scenarios.
0.784	[*A*]the simulation[*R*]shows	context()	negated: False ,passive: False
0.489	[*A*]learning[*R*]did take[*A*]place	context(the simulation shows)	negated: False ,passive: True
0.783	[*A*]the simulation[*R*]shows[*A*]that learning did take place	context()	negated: False ,passive: False
0.926	[*A*]the rule - based approach[*R*]evaluating[*A*]the aforementioned eight scenarios	context()	negated: False ,passive: False
0.925	[*A*]the simulation[*R*]shows[*A*]the same evaluation for the rule - based approach	context()	negated: False ,passive: False
0.925	[*A*]a random distribution[*R*]not known[*A*]to CBR.Fig.9	context()	negated: True ,passive: True
0.897	[*A*]the measurement information[*R*]is based[*A*]on a random distribution	context()	negated: False ,passive: True
0.845	[*A*]the simulation[*R*]interpret[*A*]the measurement information that is based on a random distribution	context()	negated: False ,passive: False
0.911	[*A*]cases[*R*]stored[*A*]in the KB.Summing up	context()	negated: False ,passive: True
0.858	[*A*]CBR[*R*]is[*A*]able to recommend right actions for many cases	context(the simulation i.e. to correctly handle)	negated: False ,passive: True
0.538	[*A*]the simulation[*R*]i.e. to correctly handle	context()	negated: False ,passive: False
0.833	[*A*]CBR[*R*]to recommend[*A*]right actions	context()	negated: False ,passive: False
0.908	[*A*]cases[*R*]stored up[*A*]in the KB.Summing	context()	negated: False ,passive: True
[LINE#165] we learn that in terms of SLA violations Scenario 1 achieves the best result, where only 0.0908% of all possible violations occur, and Scenario 8 yields the worst result, with a still very low violation rate of 1.2040%.
0.942	[*A*]Scenario 1[*R*]achieves[*A*]the best result , where only 0.0908 % Scenario 8 yields the worst result , with a still very low violation rate of 1.2040 %	context(we learn)	negated: False ,passive: False
0.317	[*A*]we[*R*]learn[*A*]that in terms of SLA violations Scenario 1 achieves the best result	context()	negated: False ,passive: False
0.910	[*A*]Scenario 1[*R*]achieves[*A*]the best result	context(we learn)	negated: False ,passive: False
0.317	[*A*]we[*R*]learn[*A*]that in terms of SLA violations Scenario 1 achieves the best result , where only 0.0908 % of all possible violations occur the worst result , with a still very low violation rate of 1.2040 %	context()	negated: False ,passive: False
[LINE#166] In general, the higher the values are for TThigh, the worse is the outcome.
0.614	[*A*]the higher[*R*]are[*A*]the values	context(the worse is)	negated: False ,passive: True
0.583	[*A*]the worse[*R*]is[*A*]the outcome	context()	negated: False ,passive: True
[LINE#167] The best result achieved with CBR was at 7.5%.
0.961	[*A*]The best result achieved with CBR[*R*]was[*A*]at 7.5%	context()	negated: False ,passive: True
0.751	[*A*]The best result[*R*]achieved	context()	negated: False ,passive: False
[LINE#168] Thus, the rule-based approach achieves an up to 82 times better performance with the right TTs set, and still a six times better performance in the worst case.
0.926	[*A*]the rule - based approach[*R*]achieves[*A*]an up to 82 times better performance	context()	negated: False ,passive: False
0.960	[*A*]the rule - based approach[*R*]achieves[*A*]an up to 82 times better performance with the right TTs set	context()	negated: False ,passive: False
[LINE#169+170]  We see that the combination of high TTlow and high TThigh(Scenario 8) gives the best utilization (84.0%), whereas low values for TTlow and TThigh lead to the worst utilization (62.0% in Scenario 1).
0.957	[*A*]the combination of high TThigh[*R*]gives[*A*]the best utilization[*A*]whereas low values for TThigh lead to the worst utilization	context(We see)	negated: False ,passive: False
0.957	[*A*]the combination of high TThigh[*R*]gives[*A*]the best utilization[*A*]whereas low values for TTlow lead to the worst utilization	context(We see)	negated: False ,passive: False
0.317	[*A*]We[*R*]see[*A*]that the combination of high TThigh ( Scenario 8) gives the best utilization	context()	negated: False ,passive: False
0.966	[*A*]the combination of high TTlow 8)[*R*]gives[*A*]the best utilization[*A*]whereas low values for TThigh lead to the worst utilization	context(We see)	negated: False ,passive: False
0.939	[*A*]low values for TThigh[*R*]lead[*A*]to the worst utilization	context()	negated: False ,passive: False
0.966	[*A*]the combination of high TTlow 8)[*R*]gives[*A*]the best utilization[*A*]whereas low values for TTlow lead to the worst utilization	context(We see)	negated: False ,passive: False
0.317	[*A*]We[*R*]see[*A*]that the combination of high TTlow 8) gives the best utilization	context()	negated: False ,passive: False
0.939	[*A*]low values for TTlow[*R*]lead[*A*]to the worst utilization	context()	negated: False ,passive: False
[LINE#171] Still, compared to CBR which scored a maximum of 80.4% and a minimum of 51.8%, the rule-based approach generally achieves better results.
0.833	[*A*]CBR[*R*]scored[*A*]a minimum of 51.8 %	context()	negated: False ,passive: False
0.833	[*A*]CBR[*R*]scored[*A*]a maximum of 80.4 %	context()	negated: False ,passive: False
[LINE#172] The percentage of all executed actions as compared to all possible actions that could have been executed is shown in Fig. 9(c).
0.933	[*A*]The percentage of all executed actions[*R*]is shown[*A*]in Fig[*A*]c	context()	negated: False ,passive: True
0.718	[*A*]all possible actions[*R*]could have been executed	context()	negated: False ,passive: False
[LINE#173] One observes that the greater the span between TTlow and TThigh is, the fewer actions have to be executed.
0.403	[*A*]One[*R*]observes[*A*]that the greater the span between TTlow and TThigh is, the fewer actions have to be executed	context()	negated: False ,passive: False
0.718	[*A*]the fewer actions[*R*]to be executed	context()	negated: False ,passive: False
0.898	[*A*]the greater the span between TTlow and TThigh[*R*]is	context()	negated: False ,passive: False
[LINE#174] Most actions (60.8%) are executed for Scenario 7 (span of only 5% between TT values), whereas least actions (5.5%) are executed for Scenario 3 (span of 60% between TT values).
0.992	[*A*]whereas least actions[*R*]are executed for[*A*]Scenario 7	context()	negated: False ,passive: False
0.887	[*A*]least actions[*R*]are executed[*A*]for Scenario 3	context()	negated: False ,passive: True
0.927	[*A*]Most actions[*R*]are executed[*A*]for Scenario 7[*A*]whereas least actions (5.5%) are executed for Scenario 3	context()	negated: False ,passive: True
[LINE#175] CBR almost always recommended exactly one (out of two possible) actions and hardly ever (in about 1% of the cases) recommended no action.
0.899	[*A*]CBR[*R*]recommended[*A*]exactly one[*A*]out of two possible ) actions[*A*]almost always	context()	negated: False ,passive: False
[LINE#176] As violations are very low in general, the resource allocation efficiency is very similar to the utilization.
0.937	[*A*]the resource allocation efficiency[*R*]is[*A*]very similar to the utilization	context()	negated: False ,passive: True
0.749	[*A*]violations[*R*]are[*A*]very low[*A*]in general	context()	negated: False ,passive: True
[LINE#177] The best value can be achieved with Scenario 8 (84.0%), the worst with Scenario 1 (62.0%).
0.751	[*A*]The best value[*R*]can be achieved	context()	negated: False ,passive: False
[LINE#178+179]  CBR achieves a RAE of at most 69.7% (=0.5 at iteration 2), and at least 45.5% (=0.1 at iteration 20).Fig.8(e) shows the costs for each scenario using Eq.
0.991	[*A*]at least 45.5 %[*R*]shows[*A*]the costs for each scenario using Eq	context()	negated: False ,passive: False
0.918	[*A*]each scenario[*R*]using[*A*]Eq	context()	negated: False ,passive: False
0.927	[*A*]at least 45.5 %[*R*]shows[*A*]the costs for each scenario	context()	negated: False ,passive: False
0.877	[*A*]CBR[*R*]achieves[*A*]a RAE of at most 69.7 %	context()	negated: False ,passive: False
[LINE#180] The best trade-off between the three terms is achieved by Scenario 5 that has medium values for TTlowr and TThighr.
0.926	[*A*]Scenario 5[*R*]has[*A*]medium values for TTlowr and TThighr	context()	negated: False ,passive: False
0.816	[*A*]The best trade-off between the three terms[*R*]is achieved	context()	negated: False ,passive: False
[LINE#181] It has a very low violation rate of 0.0916%, a quite elaborate utilization of 72.9%, but achieves this with only 19.8% of actions.
0.225	[*A*]It[*R*]achieves[*A*]this	context()	negated: False ,passive: False
0.997	[*A*]It[*R*]has a low violation rate of[*A*]0.0916 %	context()	negated: False ,passive: False
0.522	[*A*]It[*R*]has[*A*]a very low violation rate of 0.0916 %	context()	negated: False ,passive: False
[LINE#182] Scenario 7 achieves a better violation and utilization rate but at the cost of an action rate of 60.8%, and consequently has higher costs.
0.903	[*A*]Scenario 7[*R*]achieves[*A*]a better utilization rate	context()	negated: False ,passive: False
0.903	[*A*]Scenario 7[*R*]achieves[*A*]a better violation	context()	negated: False ,passive: False
0.913	[*A*]Scenario 7[*R*]has[*A*]higher costs	context()	negated: False ,passive: False
0.732	[*A*]Scenario 7[*R*]achieves	context()	negated: False ,passive: False
[LINE#183+184]  The lowest cost value for CBR is 923.0 Cloud EUR, the highest 2985.3 Cloud EUR.Ifthe utility of the decision decreases for a certain time frame (as cost increases), the KB could determine the cost summand in Eq.
0.887	[*A*]the KB[*R*]could determine[*A*]the cost summand in Eq	context()	negated: False ,passive: False
0.967	[*A*]The lowest cost value for CBR[*R*]is[*A*]923.0 Cloud EUR	context()	negated: False ,passive: True
[LINE#185] (8) that contributes most to this decrease.
0.136	[*A*]that[*R*]contributes[*A*]most[*A*]to this decrease	context()	negated: False ,passive: False
[LINE#186] For any resource r, if the term is p, then decrease TThighr.
0.784	[*A*]the term[*R*]is p	context()	negated: False ,passive: False
[LINE#187] If the term is w, then increase TTlowr.
0.813	[*A*]the term[*R*]is[*A*]w	context()	negated: False ,passive: True
[LINE#188] Otherwise, if the term is c, then widen the span of TThighr and TTlowr, i.e., increase TThighr and decrease TTlowr.
0.784	[*A*]the term[*R*]is c	context()	negated: False ,passive: False
0.784	[*A*]the term[*R*]is	context()	negated: False ,passive: False
[LINE#189] We plan to investigate this in our future research.
0.189	[*A*]We[*R*]plan to investigate[*A*]this	context(We plan)	negated: False ,passive: False
0.322	[*A*]We[*R*]plan[*A*]to investigate this in our future research	context()	negated: False ,passive: False
[LINE#190] As far as time performance and scalability are concerned, the performance tests are very encouraging.
0.713	[*A*]scalability[*R*]are concerned	context()	negated: False ,passive: False
0.783	[*A*]the performance tests[*R*]are[*A*]very encouraging	context()	negated: False ,passive: True
0.732	[*A*]time performance[*R*]are concerned	context()	negated: False ,passive: False
[LINE#191] We executed 100 iterations from 100 to 3000 VMs.
0.999	[*A*]We[*R*]executed[*A*]100 iterations	context()	negated: False ,passive: False
0.452	[*A*]We[*R*]executed[*A*]100 iterations[*A*]from 100[*A*]to 3000 VMs	context()	negated: False ,passive: False
[LINE#192] We performed every test twice and calculated the average execution time as well as the average time it took for the simulation engine to handle one VM.
0.925	[*A*]the simulation engine[*R*]to handle[*A*]one VM	context()	negated: False ,passive: False
0.913	[*A*]the average time[*R*]took[*A*]for the simulation engine to handle one VM	context()	negated: False ,passive: True
0.528	[*A*]We[*R*]calculated[*A*]the average execution time as well as the average time	context()	negated: False ,passive: False
0.452	[*A*]We[*R*]performed[*A*]every test[*A*]twice	context()	negated: False ,passive: False
[LINE#193] the execution time per VM stays quite constant for up to 1500 VMs, and thus average execution time is about linear.
0.828	[*A*]average execution time[*R*]is[*A*]about linear	context()	negated: False ,passive: True
0.944	[*A*]the execution time per VM[*R*]stays[*A*]quite constant[*A*]for up to 1500 VMs	context()	negated: False ,passive: True
[LINE#194] For 3000 VMs, it took 647s/100=6.47s for one iteration to treat all VMs.
0.999	[*A*]it[*R*]took[*A*]100 = 6.47s	context()	negated: False ,passive: False
0.905	[*A*]100=6.47s[*R*]to treat[*A*]all VMs	context()	negated: False ,passive: False
[LINE#195+196]  The high time consumption per VM for 100 VMs in Fig.9(f) is due to the initialization of the rule knowledge base which takes over-proportionally long for just a small number of VMs and does not weigh so much for more VMs.
0.920	[*A*]the rule knowledge base[*R*]takes[*A*]over-proportionally long[*A*]for just a small number of VMs	context()	negated: False ,passive: False
0.946	[*A*]The high time consumption per VM for 100 VMs in Fig.9[*R*]is[*A*]due to the initialization of the rule knowledge base	context()	negated: False ,passive: True
[LINE#197] CBR took 240 s for 50 VMs and 20 iterations.
0.855	[*A*]CBR[*R*]took[*A*]240 s[*A*]for 20 iterations	context()	negated: False ,passive: False
0.999	[*A*]CBR[*R*]took[*A*]240 s	context()	negated: False ,passive: False
0.855	[*A*]CBR[*R*]took[*A*]240 s[*A*]for 50 VMs	context()	negated: False ,passive: False
[LINE#198] Thus, CBR took 240s/20=12s for one iteration to treat all VMs, which is twice as long as the rule-based approach takes, which even has 60 times more VMs.
0.999	[*A*]CBR[*R*]took[*A*]20 = 12s	context()	negated: False ,passive: False
0.879	[*A*]all VMs[*R*]has[*A*]60 times more VMs	context()	negated: False ,passive: False
0.785	[*A*]the rule-based approach[*R*]takes	context()	negated: False ,passive: False
0.921	[*A*]all VMs[*R*]is[*A*]twice as long as the rule-based approach takes	context()	negated: False ,passive: True
0.855	[*A*]CBR[*R*]took[*A*]240s[*A*]for one iteration	context()	negated: False ,passive: False
[LINE#199] However, CBR implements learning features, which the rule-based approach currently does not, and could be sped up by choosing only specific cases to be stored in the KB.Summarizing, the rule-based approach highly outperforms CBR with respect to violations (up to 82 times better results), actions, cost, and time performance.
0.949	[*A*]the rule - based approach[*R*]does not[*A*]the rule - based time performance[*A*]currently	context()	negated: True ,passive: False
0.961	[*A*]However , CBR implements[*R*]learning[*A*]features , which the rule - based approach currently does not , the rule - based time performance .	context()	negated: False ,passive: False
0.973	[*A*]CBR implements[*R*]learning[*A*]However , CBR implements learning features , which the rule - based approach currently does not , the rule - based cost .	context()	negated: False ,passive: False
0.973	[*A*]CBR implements[*R*]learning[*A*], CBR implements learning features , which the rule could be sped up by choosing only specific cases	context()	negated: False ,passive: False
0.939	[*A*]However , CBR implements[*R*]learning[*A*]features	context()	negated: False ,passive: False
0.925	[*A*]only specific cases[*R*]to be stored[*A*]in the KB.Summarizing	context()	negated: False ,passive: True
0.927	[*A*]features[*R*]could be sped up[*A*]the rule	context()	negated: False ,passive: True
0.927	[*A*]the rule - based approach[*R*]outperforms[*A*]CBR	context()	negated: False ,passive: False
0.869	[*A*]the rule - based approach[*R*]does not[*A*]currently	context()	negated: True ,passive: False
0.927	[*A*]CBR implements[*R*]learning[*A*]features	context()	negated: False ,passive: False
[LINE#200] The rule-based approach also achieves better "best case" and better "worst case" results for the remaining performance indicators utilization and resource allocations efficiency.
0.913	[*A*]The rule - based approach[*R*]achieves[*A*]better " worst case	context()	negated: False ,passive: False
0.944	[*A*]The rule - based approach[*R*]achieves[*A*]better " best case " " worst case " results for the remaining resource allocations efficiency	context()	negated: False ,passive: False
0.944	[*A*]The rule - based approach[*R*]achieves[*A*]better " best case " " worst case " results for the remaining performance indicators utilization allocations efficiency	context()	negated: False ,passive: False
[LINE#201] In more detail, seven out of eight scenarios were better than the worst CBR value for utilization, whereas only one scenario was better than the best CBR utilization value.
0.381	[*A*]only one scenario[*R*]was better than[*A*]the best CBR utilization value	context()	negated: False ,passive: False
0.381	[*A*]eight scenarios[*R*]were better than[*A*]the worst CBR value	context()	negated: False ,passive: False
0.942	[*A*]only one scenario[*R*]was[*A*]better than the best CBR utilization value	context()	negated: False ,passive: True
0.977	[*A*]seven out of eight scenarios[*R*]were[*A*]better than the worst CBR value for utilization[*A*]whereas only one scenario was better than the best CBR utilization value[*A*]In more detail	context()	negated: False ,passive: True
[LINE#202+203]  Again, accumulating these results into cost, all rule-based scenarios outperform CBR by a factor of at least 4 (worst rule-based scenario (236)compared to the best CBR result (923)), which to a large extent is due to the huge number of violations that the rule-based approach is able to prevent and the high number of actions it can save.
0.756	[*A*]the rule-based approach[*R*]to prevent	context()	negated: False ,passive: False
0.853	[*A*]the rule-based approach[*R*]is[*A*]able to prevent	context()	negated: False ,passive: True
0.945	[*A*]the best CBR result[*R*]is[*A*]due to the huge number of violations	context()	negated: False ,passive: True
0.937	[*A*]all rule-based scenarios[*R*]outperform[*A*]CBR[*A*]compared to the best CBR result	context()	negated: False ,passive: False
0.911	[*A*]the high number of actions[*R*]can save[*A*]it	context()	negated: False ,passive: True
[LINE#204] Consequently, we consider the rule-based approach as the better technique to deal with VM reconfiguration in Cloud Computing infrastructures, and we will focus the remaining part of this article on a deeper investigation and understanding of the rule-based approach by evaluating it with real world workload.
0.418	[*A*]we[*R*]will focus[*A*]the remaining part of this article on a deeper understanding of the rule - based approach[*A*]by evaluating it with real world workload	context()	negated: False ,passive: False
0.418	[*A*]we[*R*]will focus[*A*]the remaining part of this article on a deeper investigation of the rule - based approach by evaluating it with real world workload	context()	negated: False ,passive: False
0.452	[*A*]we[*R*]consider[*A*]the rule - based approach as the better technique	context()	negated: False ,passive: False
[LINE#205] A deeper investigation of synthetic workload also suggests the self-adaptation of the TTs from the rule-based approach.
0.957	[*A*]A deeper investigation of synthetic workload[*R*]suggests[*A*]the self-adaptation of the TTs from the rule-based approach	context()	negated: False ,passive: False
[LINE#206] A successful self-adaptation has been presented in [42]. .
0.993	[*A*]A successful self adaptation[*R*]has been presented in[*A*]42 ]	context()	negated: False ,passive: False
0.814	[*A*]A successful self-adaptation[*R*]has been presented[*A*]in [42	context()	negated: False ,passive: True
[LINE#207] Applying and evaluating a bioinformatics workflow to the rule-based approachAs detailed in [43,44], bioinformatics workflows have gained a great need for large-scale data analysis.
0.814	[*A*]the rule - based approachAs[*R*]detailed[*A*]in [ 43,44	context()	negated: False ,passive: True
0.903	[*A*]bioinformatics workflows[*R*]have gained[*A*]a great need for large - scale data analysis	context()	negated: False ,passive: False
[LINE#208] Due to the fact that these scientific workflows are very resource intensive and can take hours if not days to complete, provisioning them in an environment with fixed resources leads to poor performance.
0.732	[*A*]not days[*R*]to complete	context()	negated: False ,passive: False
0.544	[*A*]these[*R*]can take[*A*]hours[*A*]if not days to complete	context()	negated: False ,passive: False
0.759	[*A*]provisioning them in an environment with fixed resources[*R*]leads[*A*]to poor performance	context()	negated: False ,passive: False
0.911	[*A*]these scientific workflows[*R*]are[*A*]very resource intensive	context()	negated: False ,passive: True
[LINE#209] On the one hand, the workflow might run out of resources and thus may have to be restarted on a larger system.
0.732	[*A*]the workflow[*R*]might run thus	context()	negated: False ,passive: False
0.732	[*A*]the workflow[*R*]might run out	context()	negated: False ,passive: False
[LINE#210] On the other hand, too many resources might be provisioned in order not to take risks of a premature abort, which may cause a lot of resources to be wasted.
0.719	[*A*]a lot of resources[*R*]to be wasted	context(a premature abort may cause)	negated: False ,passive: False
0.870	[*A*]a premature abort[*R*]may cause[*A*]a lot of resources to be wasted	context()	negated: False ,passive: False
0.911	[*A*]too many resources[*R*]might be provisioned[*A*]in order	context()	negated: False ,passive: True
[LINE#211] Thus, Cloud computing infrastructures offer a promising way to host these sorts of applications [10].
0.957	[*A*]Cloud computing infrastructures[*R*]offer[*A*]a promising way to host these sorts of applications [10]	context()	negated: False ,passive: False
[LINE#212] The monitoring data presented in this Section was gathered with the help of the Cloud monitoring framework Lom2His [3].
0.816	[*A*]The monitoring data presented in this Section[*R*]was gathered	context()	negated: False ,passive: False
0.911	[*A*]The monitoring data[*R*]presented[*A*]in this Section	context()	negated: False ,passive: True
[LINE#213+214]  we measured utilized resources of TopHat [45], a typical bioinformatics workflow application analyzing RNA-Seq data [46], for a duration of about three hours [9].Inthe following we briefly describe the bioinformatics workflow in more detail.
0.908	[*A*]a typical bioinformatics[*R*]workflow application analyzing[*A*]RNA-Seq data	context(a typical bioinformatics workflow)	negated: False ,passive: False
0.891	[*A*]a typical bioinformatics[*R*]workflow[*A*]application	context()	negated: False ,passive: False
0.498	[*A*]we[*R*]measured[*A*]utilized resources of TopHat	context()	negated: False ,passive: False
[LINE#215] We here consider Next Generation Sequencing (NGS), a recently introduced high-throughput technology for the identification of nucleotide molecules like RNA or DNA in biomedical samples.
0.498	[*A*]We[*R*]here consider[*A*]Next Generation Sequencing	context()	negated: False ,passive: False
[LINE#216] The output of the sequencing process is a list of billions of character sequences called 'reads', each typically holds up to 35-200 letters that represent the individual DNA bases determined.
0.933	[*A*]The output of the sequencing process[*R*]is[*A*]a list of billions of character sequences	context(each holds)	negated: False ,passive: True
0.421	[*A*]each[*R*]holds[*A*]up to 35-200 letters that represent the individual DNA bases	context()	negated: False ,passive: False
0.818	[*A*]the individual DNA bases[*R*]determined	context()	negated: False ,passive: False
0.920	[*A*]up to 35-200 letters[*R*]represent[*A*]the individual DNA bases	context()	negated: False ,passive: False
[LINE#217] Lately, this technology has also been used to identify and count the abundances of RNA molecules that reflect new gene activity.
0.914	[*A*]RNA molecules[*R*]reflect[*A*]new gene activity	context()	negated: False ,passive: True
0.905	[*A*]this technology[*R*]to count[*A*]the abundances of RNA molecules	context()	negated: False ,passive: False
0.929	[*A*]this technology[*R*]has been used[*A*]to count the abundances of RNA molecules[*A*]Lately	context()	negated: False ,passive: True
0.698	[*A*]this technology[*R*]to identify	context()	negated: False ,passive: False
0.793	[*A*]this technology[*R*]has been used[*A*]to identify[*A*]Lately	context()	negated: False ,passive: True
[LINE#218] We use the approach, called RNA-Seq, as a typical example of a scientific workflow application in the field of bioinformatics.
0.905	[*A*]the approach[*R*]called[*A*]RNA-Seq	context()	negated: False ,passive: True
0.614	[*A*]We[*R*]use[*A*]the approach, called RNA-Seq, as a typical example of a scientific workflow application in the field of bioinformatics	context()	negated: False ,passive: False
[LINE#219] At first, in the analysis of RNA-Seq data, the obtained sequences are aligned to the reference genome.
0.957	[*A*]the obtained sequences[*R*]are aligned[*A*]to the reference genome[*A*]At first[*A*]in the analysis of RNA-Seq data	context()	negated: False ,passive: True
[LINE#220] The aligner presented here, TopHat [45], consists of many sub-tasks, some of them have to be executed sequentially, whereas others can run in parallel (Fig. 10).
0.713	[*A*]others[*R*]can run	context()	negated: False ,passive: False
0.325	[*A*]some of them[*R*]to be executed sequentially	context()	negated: False ,passive: False
0.906	[*A*]TopHat[*R*]consists[*A*]of many sub-tasks	context()	negated: False ,passive: True
0.767	[*A*]The aligner[*R*]presented[*A*]here	context()	negated: False ,passive: False
[LINE#221] These sub-tasks can have different resource-demand characteristics: needing extensive computational power, demanding high I/O access, or requiring extensive memory size.
0.824	[*A*]These sub-tasks[*R*]can have different resource-demand characteristics demanding requiring[*A*]extensive memory size	context(These sub-tasks can have demanding)	negated: False ,passive: False
0.803	[*A*]These sub-tasks[*R*]can have different resource-demand characteristics demanding[*A*]high I/O access, or requiring extensive memory size	context(These sub-tasks can have)	negated: False ,passive: False
0.824	[*A*]These sub-tasks[*R*]can have different resource-demand characteristics needing[*A*]extensive computational power	context(These sub-tasks can have)	negated: False ,passive: False
0.878	[*A*]These sub-tasks[*R*]can have[*A*]different resource-demand characteristics	context()	negated: False ,passive: False
[LINE#222] 10, the green boxes represent simplified sub-tasks of the workflow application, whereas the blue boxes represent the data transferred between the sub-tasks.
0.903	[*A*]the data[*R*]transferred[*A*]between the sub-tasks	context()	negated: False ,passive: True
0.911	[*A*]the blue boxes[*R*]represent[*A*]the data transferred between the sub-tasks	context()	negated: False ,passive: False
0.911	[*A*]the green boxes[*R*]represent[*A*]simplified sub-tasks of the workflow application[*A*]whereas the blue boxes represent the data	context()	negated: False ,passive: False
[LINE#223] The first sub-task aligns input reads to the given genome using the Bowtie program [47].
0.925	[*A*]the given genome[*R*]using[*A*]the Bowtie program	context()	negated: False ,passive: False
0.926	[*A*]The first sub-task aligns input[*R*]reads[*A*]to the given genome	context()	negated: False ,passive: True
[LINE#224] Unaligned reads are then divided into shorter sub-sequences which are further aligned to the reference genome in the next sub-task.
0.887	[*A*]shorter sub-sequences[*R*]aligned[*A*]to the reference genome in the next sub-task	context()	negated: False ,passive: True
0.927	[*A*]shorter sub-sequences[*R*]are[*A*]further aligned to the reference genome in the next sub-task	context()	negated: False ,passive: True
0.916	[*A*]Unaligned reads[*R*]are divided[*A*]into shorter sub-sequences[*A*]then	context()	negated: False ,passive: True
[LINE#225] If sub-sequences coming from the same read were aligned successfully to the genome, that may indicate that this read was straddling a 'gap' in the gene, falling on a so-called splice-junction.
0.932	[*A*]sub-sequences coming from the same read[*R*]were aligned successfully[*A*]to the genome	context()	negated: False ,passive: True
0.894	[*A*]sub-sequences[*R*]coming[*A*]from the same read	context()	negated: False ,passive: True
[LINE#226] After verification of candidate reads falling on splice junctions, these and the reads that were aligned in the first sub-task are combined to create an output with a comprehensive list of localized alignments.
0.959	[*A*]the reads that were aligned in the first sub-task[*R*]are combined[*A*]to create an output with a comprehensive list of localized alignments	context()	negated: False ,passive: True
0.939	[*A*]the reads that were aligned in the first sub-task[*R*]to create[*A*]an output with a comprehensive list of localized alignments	context()	negated: False ,passive: False
0.887	[*A*]the reads[*R*]were aligned[*A*]in the first sub-task	context()	negated: False ,passive: True
0.657	[*A*]these[*R*]are combined[*A*]to create an output with a comprehensive list of localized alignments	context()	negated: False ,passive: True
[LINE#227] We demonstrate by simulation that the rule-based approach can guarantee the resource requirements in terms of CPU, memory and storage for the execution of the workflow in a resource-efficient way.
0.952	[*A*]the rule - based approach[*R*]can guarantee[*A*]the resource requirements in terms of storage for the execution of the workflow in a resource - efficient way	context()	negated: False ,passive: False
0.287	[*A*]We[*R*]demonstrate[*A*]that the rule - based approach can guarantee the resource requirements in terms of storage for the execution of the workflow in a resource - efficient way	context()	negated: False ,passive: False
0.926	[*A*]the rule - based approach[*R*]can guarantee[*A*]the resource requirements in terms of memory	context()	negated: False ,passive: False
0.287	[*A*]We[*R*]demonstrate[*A*]that the rule - based approach can guarantee the resource requirements in terms of memory	context()	negated: False ,passive: False
0.926	[*A*]the rule - based approach[*R*]can guarantee[*A*]the resource requirements in terms of CPU	context()	negated: False ,passive: False
0.287	[*A*]We[*R*]demonstrate[*A*]that the rule - based approach can guarantee the resource requirements in terms of CPU	context()	negated: False ,passive: False
[LINE#228] Therefore, we define the SLA shown in Table 5 for TopHat with the maximum amount of available resources on the physical machine on which we are executing it.
0.309	[*A*]we[*R*]are executing[*A*]it	context()	negated: False ,passive: False
0.953	[*A*]the SLA[*R*]shown[*A*]in Table 5[*A*]for TopHat	context()	negated: False ,passive: True
0.498	[*A*]we[*R*]define[*A*]the SLA	context()	negated: False ,passive: False
[LINE#229] The physical machine has a Linux/Ubuntu OS with a Intel Xeon(R) 3 GHz CPU, two cores, 9 GB of memory, and 19 GB of storage.
0.942	[*A*]The physical machine[*R*]has[*A*]a Linux / Ubuntu OS	context()	negated: False ,passive: False
0.942	[*A*]The physical machine[*R*]has[*A*]a Linux / Ubuntu OS with a Intel Xeon	context()	negated: False ,passive: False
[LINE#230] For CPU power, we convert CPU utilization into MIPS based on the assumption that an Intel Xeon(R) 3 GHz processor delivers 10000 MIPS for 100% resource utilization of one core, and linearly degrades with CPU utilization.
0.922	[*A*]an Intel Xeon[*R*]linearly degrades[*A*]with CPU utilization	context()	negated: False ,passive: False
0.933	[*A*]3 GHz processor[*R*]delivers[*A*]10000 MIPS[*A*]for 100 %	context()	negated: False ,passive: False
0.965	[*A*]that an Intel Xeon ( R ) 3 GHz processor[*R*]delivers[*A*]10000 MIPS[*A*]for 100 % resource utilization of one core	context()	negated: False ,passive: False
0.498	[*A*]we[*R*]convert[*A*]CPU utilization[*A*]into MIPS	context()	negated: False ,passive: False
[LINE#231]  In order to validate our approach, we make three simulation categories, where we set up and manage our VMs differently:.
0.551	[*A*]we[*R*]manage[*A*]di fferently:.[*A*]three simulation categories	context()	negated: False ,passive: False
0.463	[*A*]we[*R*]make[*A*]three simulation categories , where we manage our VMs di fferently:.	context()	negated: False ,passive: False
0.350	[*A*]we[*R*]set up[*A*]our VMs	context()	negated: False ,passive: False
0.463	[*A*]we[*R*]make[*A*]three simulation categories , where we set up our VMs	context()	negated: False ,passive: False
[LINE#232] In the first category (Scenario 1) we assume a static configuration with a fixed initial resource configuration of the VMs.
0.740	[*A*]we[*R*]assume[*A*]a static configuration with a fixed initial resource configuration of the VMs[*A*]In the first category	context()	negated: False ,passive: False
[LINE#233] Normally, when setting up such a testbed as described in [9], an initial guess of possible resource consumption is done based on early monitoring data.
0.973	[*A*]an initial guess of possible resource consumption[*R*]is done[*A*]when setting up such a testbed as described in [9]	context()	negated: False ,passive: True
[LINE#234] From this data on, we assume quite generous resource limits.
0.595	[*A*]we[*R*]assume[*A*]quite generous resource limits[*A*]From this data on	context()	negated: False ,passive: False
[LINE#235]  The first ten measurements of CPU, memory, and storage lie in the range of [140, 12500] MIPS, [172, 1154].
0.964	[*A*]The first ten measurements of storage[*R*]lie[*A*]in the range of [ 140 , 12500 ] MIPS , [ 172 , 1154	context()	negated: False ,passive: True
0.964	[*A*]The first ten measurements of memory[*R*]lie[*A*]in the range of [ 140 , 12500 ] MIPS , [ 172 , 1154	context()	negated: False ,passive: True
0.964	[*A*]The first ten measurements of CPU[*R*]lie[*A*]in the range of [ 140 , 12500 ] MIPS , [ 172 , 1154	context()	negated: False ,passive: True
[LINE#236] MB, [15.6, 15.7] GB, respectively.
[LINE#237] So we initially configured our VM with 15000 MIPS, 4096 MB, and 17.1 GB, respectively.
0.448	[*A*]we[*R*]configured[*A*]our VM[*A*]with 15000 17.1 GB[*A*]respectively[*A*]initially	context()	negated: False ,passive: False
0.448	[*A*]we[*R*]configured[*A*]our VM[*A*]with 15000 MIPS , 4096 MB , respectively[*A*]initially	context()	negated: False ,passive: False
[LINE#238] The second category subsumes several scenarios, where we apply our autonomic management approach to the initial configuration in the first category.
0.309	[*A*]we[*R*]apply[*A*]our autonomic management approach[*A*]to the initial configuration in the first category	context()	negated: False ,passive: False
0.899	[*A*]The second category[*R*]subsumes[*A*]several scenarios, where we apply our autonomic management approach to the initial configuration in the first category	context()	negated: False ,passive: True
[LINE#239] The eight scenarios in this category depend on the chosen TTs.
0.943	[*A*]The eight scenarios in this category[*R*]depend[*A*]on the chosen TTs	context()	negated: False ,passive: False
[LINE#240] According to Table 4 we define these scenarios as Scenario 2.1, 2.2,,2.8, respectively.
0.445	[*A*]we[*R*]define respectively[*A*]these scenarios[*A*]as Scenario 2.1	context()	negated: False ,passive: False
[LINE#241] As the third category (Scenario 3), we consider a best case scenario, where we assume we have an oracle that predicts the maximal resource consumption that we statically set our VM configuration to.
0.188	[*A*]we[*R*]have[*A*]an oracle that predicts the maximal resource consumption	context(we assume)	negated: False ,passive: False
0.381	[*A*]we[*R*]assume[*A*]we have an oracle[*A*]a best case scenario	context()	negated: False ,passive: False
0.350	[*A*]we[*R*]statically set[*A*]our VM configuration[*A*]to	context()	negated: False ,passive: False
0.751	[*A*]an oracle[*R*]predicts[*A*]the maximal resource consumption that we statically set our VM configuration to	context()	negated: False ,passive: False
0.418	[*A*]we[*R*]consider[*A*]a best case scenario, where we assume we have an oracle	context()	negated: False ,passive: False
[LINE#242] Moreover, according to the first measurements we decide to enforce a minimum of 1 MIPS CPU, 768 MB memory, and 1 GB storage.
0.896	[*A*]a minimum[*R*]has MIPS GB storage of[*A*]1 mips 1 gb storage	context()	negated: False ,passive: False
0.433	[*A*]we[*R*]decide to enforce[*A*]a minimum of 1 MIPS 1 GB storage	context(we decide)	negated: False ,passive: False
0.550	[*A*]we[*R*]decide[*A*]to enforce a minimum of 1 MIPS 1 GB storage	context()	negated: False ,passive: False
0.896	[*A*]a minimum[*R*]has MIPS MB memory of[*A*]1 mips 768 mb memory	context()	negated: False ,passive: False
0.433	[*A*]we[*R*]decide to enforce[*A*]a minimum of 1 MIPS 768 MB memory	context(we decide)	negated: False ,passive: False
0.550	[*A*]we[*R*]decide[*A*]to enforce a minimum of 1 MIPS 768 MB memory	context()	negated: False ,passive: False
0.433	[*A*]we[*R*]decide to enforce[*A*]a minimum of 1 MIPS CPU	context(we decide)	negated: False ,passive: False
0.433	[*A*]we[*R*]decide[*A*]to enforce a minimum of 1 MIPS CPU	context()	negated: False ,passive: False
[LINE#243] one sees violations, utilization, as well as the number of reconfiguration actions, respectively, for every parameter (together with an average value) in the different scenarios.
0.657	[*A*]one[*R*]sees[*A*]violations, utilization, as well as the number of reconfiguration actions, respectively, for every parameter (together with an average value) in the different scenarios	context()	negated: False ,passive: False
[LINE#244]  Generally, the bars are naturally ordered beginning from Scenario 1, over Scenarios 2.1,.
0.903	[*A*]the bars[*R*]are naturally ordered[*A*]beginning from Scenario 1	context()	negated: False ,passive: True
[LINE#245] The number of violations in Scenario 1 reach 41.7% for CPU and memory, and 49.4% for storage, which leads to an average of 44.3%.
0.999	[*A*]The number of violations in Scenario 1[*R*]reach[*A*]41.7 %	context()	negated: False ,passive: False
0.905	[*A*]49.4% for storage[*R*]leads[*A*]to an average of 44.3%	context()	negated: False ,passive: False
0.960	[*A*]The number of violations in Scenario 1[*R*]reach[*A*]41.7% for CPU and memory, and 49.4% for storage	context()	negated: False ,passive: False
[LINE#246]  (For better visibility, these results have been excluded from Fig..
0.918	[*A*]these results[*R*]have been excluded[*A*]from Fig	context()	negated: False ,passive: True
[LINE#247] Thus, we experience violations in almost half of the cases.
0.452	[*A*]we[*R*]experience[*A*]violations in almost half of the cases	context()	negated: False ,passive: False
[LINE#248] This is especially crucial for parameters memory and storage, where program execution could fail, if it runs out of memory or storage, whereas for a violation of the parameter CPU, we would "only" delay the successful termination of the workflow.
0.243	[*A*]it[*R*]runs	context()	negated: False ,passive: False
0.732	[*A*]program execution[*R*]could fail	context()	negated: False ,passive: False
0.415	[*A*]This[*R*]is[*A*]especially crucial for parameters memory and storage, where program execution could fail[*A*]if it runs out of memory or storage, whereas for a violation of the parameter CPU, we would "only" delay the successful termination of the workflow	context()	negated: False ,passive: True
[LINE#249] we can reduce the SLA violations to a minimum.
0.498	[*A*]we[*R*]can reduce[*A*]the SLA violations[*A*]to a minimum	context()	negated: False ,passive: False
[LINE#250] We completely avoid violations for storage in all sub-scenarios, as well as for memory in all but one sub-scenarios.
0.569	[*A*]We[*R*]completely avoid[*A*]violations for storage for memory in all but one sub-scenarios	context()	negated: False ,passive: False
0.452	[*A*]We[*R*]completely avoid[*A*]violations for storage in all sub-scenarios	context()	negated: False ,passive: False
[LINE#251] Also CPU violations can be reduced to 0.6% for sub-scenarios 2.1 and 2.4, and still achieve a maximum SLA violation rate of 2.8% with Scenario 2.8.
0.993	[*A*]CPU violations[*R*]can be reduced for[*A*]2.4	context()	negated: False ,passive: False
0.903	[*A*]CPU violations[*R*]can be reduced[*A*]to 0.6 %[*A*]for sub-scenarios 2.4	context()	negated: False ,passive: True
0.993	[*A*]CPU violations[*R*]can be reduced for[*A*]2.1	context()	negated: False ,passive: False
0.903	[*A*]CPU violations[*R*]can be reduced[*A*]to 0.6 %[*A*]for sub-scenarios 2.1	context()	negated: False ,passive: True
0.929	[*A*]CPU violations[*R*]can achieve[*A*]a maximum SLA violation rate of 2.8 %[*A*]still	context()	negated: False ,passive: False
[LINE#252] The average SLA violation rate can be lowered to 0.2% in the best case.
0.993	[*A*]The average SLA violation rate[*R*]can be lowered to[*A*]0.2 %	context()	negated: False ,passive: False
0.944	[*A*]The average SLA violation rate[*R*]can be lowered[*A*]to 0.2% in the best case	context()	negated: False ,passive: True
[LINE#253] Scenario 3, of course, shows no violations.
0.913	[*A*]Scenario 3[*R*]shows[*A*]no violations	context()	negated: False ,passive: False
[LINE#254] However, it is unlikely to know the maximum resource consumption before workflow execution.
0.637	[*A*]it[*R*]is[*A*]unlikely to know the maximum resource consumption before workflow execution	context()	negated: False ,passive: True
[LINE#255] As to the utilization of the resources, it is clearly higher when a lot of violations occur, so Scenario 1 naturally achieves high utilization.
0.769	[*A*]a lot of violations[*R*]occur	context()	negated: False ,passive: False
[LINE#256] This is the case, because when a parameter is violated, then the resource is already fully used up, but even more of the resource would be needed to fulfill the needs.
0.926	[*A*]even more of the resource[*R*]would be needed[*A*]to fulfill the needs	context()	negated: False ,passive: True
0.567	[*A*]This[*R*]is[*A*]the case[*A*]even more of the resource would be needed to fulfill the needs	context()	negated: False ,passive: True
0.901	[*A*]the resource[*R*]is used up[*A*]when a parameter is violated[*A*]then[*A*]already	context()	negated: False ,passive: True
0.732	[*A*]a parameter[*R*]is violated	context()	negated: False ,passive: False
0.567	[*A*]This[*R*]is[*A*]the case[*A*]because when a parameter is violated , then the resource is already fully used up	context()	negated: False ,passive: True
[LINE#257] On the opposite, Scenario 3 naturally achieves low utilization, as a lot of resources are over-provisioned.
0.934	[*A*]Scenario 3[*R*]achieves[*A*]low utilization[*A*]as a lot of resources are over-provisioned[*A*]On the opposite	context()	negated: False ,passive: False
[LINE#258] * achieve a good utilization that is on average in between the two extremes and ranges from 70.6% (Scenario 2.1) to 86.2% (Scenario 2.8).
0.949	[*A*]a good utilization[*R*]is[*A*]on average[*A*]in between the two extremes and ranges from 70.6% (Scenario 2.1) to 86.2%	context()	negated: False ,passive: True
[LINE#259] Furthermore, we observe some exceptions to this "rule" when considering individual parameters.
0.293	[*A*]we[*R*]observe some exceptions considering[*A*]individual parameters	context(we observe)	negated: False ,passive: False
0.388	[*A*]we[*R*]observe[*A*]some exceptions[*A*]to this "rule[*A*]when considering individual parameters	context()	negated: False ,passive: False
[LINE#260] So, e.g., for memory we achieve a utilization of 85.0% with Scenario 2.8 or 80.0% with Scenario 2.6, which is higher than the utilization in Scenario 1 (77.4%).
0.913	[*A*]Scenario 2.6[*R*]is[*A*]higher than the utilization in Scenario 1	context()	negated: False ,passive: True
0.569	[*A*]we[*R*]achieve[*A*]a utilization of 85.0% with Scenario 2.8 or 80.0% with Scenario 2.6	context()	negated: False ,passive: False
[LINE#261] The same is true for CPU utilization rates of 85.5% as compared to 84.3% for the Scenario 1 and 2.8, respectively.
0.381	[*A*]The same[*R*]is[*A*]true	context()	negated: False ,passive: True
[LINE#262] Only for storage the utilization of all but one of the Scenarios 2.
[LINE#263] *, which is at 85.9%, is smaller than for Scenario 3 (90.1%).A huge advantage of Scenarios 2.
[LINE#264] * is that they do not run into any crucial SLA violation (except for Scenario 2.3), but achieve a higher utilization as compared to Scenario 3.
[LINE#265] As to the reallocation actions, of course, Scenario 1 and 3 do not execute any, but also for the autonomic management in Scenarios 2.
0.767	[*A*]Scenario 3[*R*]do not execute[*A*]any	context()	negated: True ,passive: False
0.767	[*A*]Scenario 1[*R*]do not execute[*A*]any	context()	negated: True ,passive: False
[LINE#266] , the amount of executed reallocation actions for most scenarios stays below 10%.
0.948	[*A*]the amount of executed reallocation actions for most scenarios[*R*]stays[*A*]below 10%	context()	negated: False ,passive: True
[LINE#267] Only Scenario 2.7 executes actions in 19.8% of the cases on average of the time.
0.943	[*A*]Only Scenario 2.7[*R*]executes[*A*]actions[*A*]in 19.8% of the cases on average of the time	context()	negated: False ,passive: False
[LINE#268] Five out of eight scenarios stay below 5% on average.
0.926	[*A*]Five out of eight scenarios[*R*]stay[*A*]below 5%	context()	negated: False ,passive: True
[LINE#269] When it comes to the overall costs of the scenarios (cf.
0.195	[*A*]it[*R*]comes	context()	negated: False ,passive: False
[LINE#270] scenarios approach the result achieved by the best case scenario 3.
0.903	[*A*]the result[*R*]achieved[*A*]by the best case scenario 3	context()	negated: False ,passive: True
0.894	[*A*]scenarios[*R*]approach[*A*]the result achieved by the best case scenario 3	context()	negated: False ,passive: True
[LINE#271] Scenario 1 sums up costs of 4493.6, and has therefore been omitted in the figure.
0.847	[*A*]Scenario[*R*]has been omitted[*A*]in the figure	context()	negated: False ,passive: True
[LINE#272] Furthermore, the lowest cost is achieved using Scenario 2.6, which is even lower than the cost for Scenario 3.
0.913	[*A*]Scenario 2.6[*R*]is[*A*]even lower than the cost for Scenario 3	context()	negated: False ,passive: True
0.751	[*A*]the lowest cost[*R*]is achieved	context()	negated: False ,passive: False
[LINE#273] This is possible, because Scenario 2.6 achieves a very good utilization and SLA violation rate with a very low number of reallocation actions.
0.918	[*A*]Scenario 2.6[*R*]achieves[*A*]SLA violation rate	context()	negated: False ,passive: False
0.612	[*A*]This[*R*]is[*A*]possible[*A*]because Scenario 2.6 achieves SLA violation rate with a very low number of reallocation actions	context()	negated: False ,passive: True
0.903	[*A*]Scenario 2.6[*R*]achieves[*A*]a very good utilization	context()	negated: False ,passive: False
0.567	[*A*]This[*R*]is[*A*]possible[*A*]because Scenario 2.6 achieves a very good utilization with a very low number of reallocation actions	context()	negated: False ,passive: True
[LINE#274] Also resource allocation efficiency for Scenarios 2.
[LINE#275] 12(b) achieves unambiguously better results than for Scenario 1 (RAE of 48.2%).
0.897	[*A*]12(b[*R*]achieves[*A*]unambiguously better results than for Scenario 1	context()	negated: False ,passive: False
[LINE#276+277]  Furthermore, all scenarios of the second category achieve a better RAE than the RAE of Scenario 3(69.3%).Thus, we conclude that by using the suggested autonomic management technique, we can avoid most costly SLA violations, and thus ensure workflow execution, together with a focus on resource-efficient usage.
0.293	[*A*]we[*R*]can ensure[*A*]workflow execution	context(we conclude)	negated: False ,passive: False
0.168	[*A*]we[*R*]conclude[*A*]that by using the suggested autonomic management technique , we can thus ensure workflow execution , together with a focus on resource - efficient usage	context()	negated: False ,passive: False
0.433	[*A*]we[*R*]can avoid[*A*]most costly SLA violations	context(we conclude)	negated: False ,passive: False
0.927	[*A*]all scenarios of the second category[*R*]achieve[*A*]a better RAE than the RAE of Scenario 3	context(we conclude)	negated: False ,passive: False
0.195	[*A*]we[*R*]conclude[*A*]that by using the suggested autonomic management technique , we can avoid most costly SLA violations	context()	negated: False ,passive: False
[LINE#278] All this can be achieved by a very low number of time- and energy-consuming VM reallocation actions for many of the autonomic management scenarios.
0.718	[*A*]All this[*R*]can be achieved[*A*]by a very low number of energy - consuming VM reallocation actions for many of the autonomic management scenarios	context()	negated: False ,passive: True
0.568	[*A*]All this[*R*]can be achieved[*A*]by a very low number of time	context()	negated: False ,passive: True
[LINE#279+280]  Implementing the knowledge management phaseInthis section we present the implementation of the Knowledge Management phase using CBR and a rule-based approach..
0.433	[*A*]we[*R*]present the implementation of the Knowledge Management phase using[*A*]CBR	context(we present)	negated: False ,passive: False
0.433	[*A*]we[*R*]present[*A*]the implementation of the Knowledge Management phase	context()	negated: False ,passive: False
[LINE#281] This subsection subsumes all the common assumptions for both approaches.
0.903	[*A*]This subsection[*R*]subsumes[*A*]all the common assumptions for both approaches	context()	negated: False ,passive: True
[LINE#282] We assume that customers deploy applications on an IaaS Cloud infrastructure.
0.891	[*A*]customers[*R*]deploy[*A*]applications on an IaaS Cloud infrastructure	context(We assume)	negated: False ,passive: False
0.225	[*A*]We[*R*]assume[*A*]that customers deploy applications on an IaaS Cloud infrastructure	context()	negated: False ,passive: False
[LINE#283] SLOs are defined within an SLA between the customer and the Cloud provider for every application.
0.894	[*A*]SLOs[*R*]are defined[*A*]within an SLA[*A*]between the customer and the Cloud provider for every application	context()	negated: False ,passive: True
[LINE#284] Furthermore, there is a 1:1 relationship between applications and VMs.
[LINE#285] One VM runs on exactly one PM, but one PM can host an arbitrary number of VMs with respect to supplied vs.
0.918	[*A*]one PM[*R*]can host[*A*]an arbitrary number of VMs	context()	negated: False ,passive: False
0.944	[*A*]One VM[*R*]runs[*A*]on exactly one PM	context()	negated: False ,passive: False
[LINE#286] After allocating VMs with an initial capacity (by estimating initial resource demand) for every application, we continuously monitor actually used resources and re-allocate resources according to these measurements.
0.740	[*A*]we[*R*]continuously monitor[*A*]actually used resources[*A*]After allocating VMs with an initial capacity ( by estimating initial resource demand ) for every application	context()	negated: False ,passive: False
[LINE#287] For tackling the resource allocation for VMs, we need to define how measured, provided and agreed values interrelate, and what actually constitutes an SLA violation.
0.433	[*A*]we[*R*]need to define[*A*]what actually constitutes an SLA violation	context(we need)	negated: False ,passive: False
0.433	[*A*]we[*R*]need[*A*]to define what actually constitutes an SLA violation	context()	negated: False ,passive: False
0.678	[*A*]agreed values[*R*]interrelate	context(we need to define)	negated: False ,passive: False
0.388	[*A*]we[*R*]need to define agreed[*A*]values	context(we need to define)	negated: False ,passive: False
0.388	[*A*]we[*R*]need to define[*A*]agreed values interrelate	context(we need)	negated: False ,passive: False
0.388	[*A*]we[*R*]need[*A*]to define agreed values interrelate	context()	negated: False ,passive: False
0.183	[*A*]we[*R*]need to define[*A*]how provided	context(we need)	negated: False ,passive: False
0.183	[*A*]we[*R*]need[*A*]to define how provided	context()	negated: False ,passive: False
0.183	[*A*]we[*R*]need to define[*A*]how measured	context(we need)	negated: False ,passive: False
0.183	[*A*]we[*R*]need[*A*]to define how measured	context()	negated: False ,passive: False
[LINE#288] An example is provided in Table 2.
0.918	[*A*]An example[*R*]is provided[*A*]in Table 2	context()	negated: False ,passive: True
[LINE#289] First, we deal with the measured value (1), which represents the amount of a specific resource that is currently used by the customer.
0.910	[*A*]a specific resource[*R*]is used[*A*]by the customer[*A*]currently	context()	negated: False ,passive: True
0.897	[*A*]the measured value[*R*]represents[*A*]the amount of a specific resource	context()	negated: False ,passive: False
0.595	[*A*]we[*R*]deal[*A*]with the measured value[*A*]First	context()	negated: False ,passive: False
[LINE#290] Second, there is the amount of allocated resource (2) that can be used by the customer, i.e., that is allocated to the VM which hosts the application.
0.879	[*A*]the VM[*R*]hosts[*A*]the application	context()	negated: False ,passive: False
0.913	[*A*]the amount of allocated resource[*R*]can be used[*A*]by the customer	context()	negated: False ,passive: True
[LINE#291] Third, there is the SLO agreed in the SLA (3).
0.938	[*A*]the SLO[*R*]agreed[*A*]in the SLA (3	context()	negated: False ,passive: True
[LINE#292] A violation therefore occurs, if less is provided (2) than the customer utilizes (or wants to utilize) (1) with respect to the limits set in the SLA (3).
0.126	[*A*]less[*R*]is provided	context(A violation occurs)	negated: False ,passive: False
0.649	[*A*]A violation[*R*]occurs	context()	negated: False ,passive: False
0.937	[*A*]the limits[*R*]set[*A*]in the SLA ( 3	context()	negated: False ,passive: True
0.732	[*A*]the customer[*R*]utilizes	context()	negated: False ,passive: False
[LINE#293] Considering Table 2 we can see that rows 1 and 3 do not represent violations, whereas row 2 does represent an SLA violation.
0.944	[*A*]Considering Table 3[*R*]do not represent[*A*]violations[*A*]whereas row 2 does represent an SLA violation	context()	negated: True ,passive: False
0.918	[*A*]row 2[*R*]does represent[*A*]an SLA violation	context()	negated: False ,passive: False
0.944	[*A*]Considering Table 2[*R*]do not represent[*A*]violations[*A*]whereas row 2 does represent an SLA violation	context()	negated: True ,passive: False
[LINE#294]  In order to save resources we envision a speculative approach: Can we allocate less than agreed, but still more than used in order not to violate an SLA?.
[LINE#295] The most demanding questions are how much can we lower the provisioning of resource without risking an SLA violation.
0.905	[*A*]The most demanding questions[*R*]are[*A*]how much can we lower the provisioning of resource without risking an SLA violation	context()	negated: False ,passive: True
[LINE#296] This heavily depends on the characteristics of the workload of an application, especially its volatility. .
0.381	[*A*]This[*R*]heavily depends[*A*]on the characteristics of the workload of an application	context()	negated: False ,passive: False
[LINE#297] Based Reasoning is the process of solving problems based on past experience [39].
0.894	[*A*]problems[*R*]based[*A*]on past experience	context()	negated: False ,passive: True
0.925	[*A*]Based Reasoning[*R*]is[*A*]the process of solving problems	context()	negated: False ,passive: True
[LINE#298] In more detail, it tries to solve a case (a formatted instance of a problem) by looking for similar cases from the past and reusing the solutions of these cases to solve the current one.
0.388	[*A*]it[*R*]tries to solve[*A*]a case[*A*]by reusing the solutions of these cases	context(it tries)	negated: False ,passive: False
0.645	[*A*]it[*R*]tries[*A*]to solve a case ( a formatted instance of a problem ) by reusing the solutions of these cases[*A*]In more detail	context()	negated: False ,passive: False
0.388	[*A*]it[*R*]tries to solve[*A*]a case[*A*]by looking for similar cases from the past	context(it tries)	negated: False ,passive: False
0.645	[*A*]it[*R*]tries[*A*]to solve a case ( a formatted instance of a problem ) by looking for similar cases from the past[*A*]In more detail	context()	negated: False ,passive: False
[LINE#299+300]  In general, a typical CBR cycle consists of the following phases assuming that a new case was just received: 1.Retrieve the most similar case or cases to the new one.2.Reuse the information and knowledge in the similar case(s) to solve the problem.3.Revisethe proposed solution.4.Retain the parts of this experience likely to be useful for future problem solving.
0.934	[*A*]the information and knowledge in the similar case[*R*]to be[*A*]useful for future problem solving	context()	negated: False ,passive: True
0.918	[*A*]the problem.3.Revisethe[*R*]proposed[*A*]solution.4.Retain	context()	negated: False ,passive: True
0.939	[*A*]a typical CBR cycle[*R*]consists[*A*]of the following phases	context()	negated: False ,passive: True
[LINE#301] (Store new case and found solution in KB.)To adapt CBR to our problem, three issues have to be solved.
0.932	[*A*]Store[*R*]found[*A*]solution in KB	context()	negated: False ,passive: False
[LINE#302] First, it has to be decided how to format an instance of the problem.
[LINE#303] Second, it has to be decided when two cases are similar.
0.767	[*A*]two cases[*R*]are[*A*]similar	context()	negated: False ,passive: True
0.411	[*A*]it[*R*]to be decided[*A*]when two cases are similar	context()	negated: False ,passive: True
[LINE#304] Third, good reactions have to be distinguished from bad reactions.
0.887	[*A*]good reactions[*R*]to be[*A*]distinguished from bad reactions	context()	negated: False ,passive: True
[LINE#305] As to the first problem we assume that each SLA has a unique identifier id and a collection of SLOs.
0.939	[*A*]each SLA[*R*]has[*A*]a collection of SLOs	context(we assume)	negated: False ,passive: False
0.218	[*A*]we[*R*]assume[*A*]that each SLA has a collection of SLOs	context()	negated: False ,passive: False
0.928	[*A*]each SLA[*R*]has[*A*]a unique identifier id	context(we assume)	negated: False ,passive: False
0.218	[*A*]we[*R*]assume[*A*]that each SLA has a unique identifier id	context()	negated: False ,passive: False
[LINE#306+307]  SLOs are predicates of the form (1)SLOid(xi,comp,i)with comp{<,,>,,=}, where xiP represents the parameter name for i=1,the parameter goal, and comp the appropriate comparison operator.
0.830	[*A*]SLOs[*R*]comp[*A*]the appropriate comparison operator	context()	negated: False ,passive: False
0.813	[*A*]SLOs[*R*]are[*A*]predicates of the form	context()	negated: False ,passive: True
0.894	[*A*]SLOs[*R*]are[*A*]predicates of the form ( 1 ) SLOid ( xi , comp , and comp the appropriate comparison operator	context()	negated: False ,passive: True
[LINE#308] Then, a CBR case c is defined as (2)c=(id,m1,p1,m2,p2,,mnid,pnid), where id represents the SLA id, and mi and pi the measured (m) and provided (p) value of the SLA parameter xi, respectively.
0.993	[*A*]a CBR case c[*R*]is defined as[*A*]2	context()	negated: False ,passive: False
0.904	[*A*]id[*R*]pi[*A*]the measured (m) and provided (p) value of the SLA parameter xi, respectively	context()	negated: False ,passive: False
0.840	[*A*]id[*R*]represents[*A*]the SLA id, and mi	context()	negated: False ,passive: False
0.906	[*A*]a CBR case c[*R*]is defined[*A*]as (2[*A*]Then	context()	negated: False ,passive: True
[LINE#309] To use the SLA parameters storage and incoming bandwidth for example, a typical use case looks like this: SLA id=1 with SLO1 ("Storage", , 1000) and SLO1 ("Bandwidth", , 50.0).
0.799	[*A*]a typical use case[*R*]looks[*A*]like this	context()	negated: False ,passive: False
[LINE#310] A corresponding case received by the measurement component is therefore written as c=(1,500,700,20.0,30.0).
0.929	[*A*]A corresponding case received by the measurement component[*R*]is written[*A*]as c=	context()	negated: False ,passive: True
0.911	[*A*]A corresponding case[*R*]received[*A*]by the measurement component	context()	negated: False ,passive: True
[LINE#311] A result case rc=(c-,ac,c+,utility) includes the initial case c-, the executed action ac, the resulting case c+ measured some time interval later, which corresponds to one iteration in the simulation engine, and the calculated utility described later.
0.783	[*A*]the calculated utility[*R*]described[*A*]later	context()	negated: False ,passive: True
0.880	[*A*]A result case rc=[*R*]includes[*A*]the initial case	context(the executed action ac , the resulting case measured)	negated: False ,passive: True
0.915	[*A*]the executed action ac , the resulting case[*R*]measured[*A*]some time interval[*A*]later	context()	negated: False ,passive: False
[LINE#312] In order to give the KB some knowledge about what to do in specific situations, several initial cases are stored in the KB as described in [7] in more detail.
0.957	[*A*]several initial cases[*R*]are stored[*A*]in the KB[*A*]as described in [7] in more detail[*A*]specific situations	context()	negated: False ,passive: True
[LINE#313]  Secondly, to define similarity between two cases is not straightforward, because due to their symmetric nature.
0.829	[*A*]to define similarity between two cases[*R*]is not[*A*]straightforward	context()	negated: True ,passive: True
[LINE#314] Euclidean distances, e.g., do not recognize the difference between over- and under-provisioning.
0.887	[*A*]Euclidean distances[*R*]do not recognize[*A*]the difference between over- and under-provisioning	context()	negated: True ,passive: False
[LINE#315+316]  Following the principle of semantic similarity from [40] for the summation part this leads to the following equation (3)d(c-,c+)=min(wid,|id--id+|)+xPwx|(px--mx-)-(px+-mx+)maxx-minx|, where w=(wid,wx1,) is the weight vector; wid is the weight for non-identical SLAs; wx is the weight, and maxx and minx the maximum and minimum values of differences px-mx for parameter x.
0.869	[*A*]w=[*R*]is[*A*]the weight vector	context()	negated: False ,passive: True
0.585	[*A*]this[*R*]leads[*A*]to the following equation[*A*]Following the principle of semantic similarity from [ 40 ] for the summation part	context(wid is wx is)	negated: False ,passive: False
0.440	[*A*]wid[*R*]is[*A*]the weight for non-identical SLAs	context(wx is)	negated: False ,passive: True
0.467	[*A*]wx[*R*]is[*A*]the weight	context()	negated: False ,passive: True
[LINE#317] As far as the third issue is concerned, every action is evaluated by its impact on violations and utilization.
0.835	[*A*]every action[*R*]is evaluated[*A*]by its impact on utilization	context()	negated: False ,passive: True
0.835	[*A*]every action[*R*]is evaluated[*A*]by its impact on violations	context()	negated: False ,passive: True
0.751	[*A*]the third issue[*R*]is concerned	context()	negated: False ,passive: False
[LINE#318] This way CBR is able to learn whether an action was appropriate for a specific measurement or not.
0.908	[*A*]an action[*R*]was[*A*]appropriate for a specific measurement or not	context(CBR to learn)	negated: False ,passive: True
0.865	[*A*]CBR[*R*]to learn[*A*]whether an action was appropriate for a specific measurement or not	context()	negated: False ,passive: False
0.926	[*A*]CBR[*R*]is[*A*]able to learn whether an action was appropriate for a specific measurement or not	context()	negated: False ,passive: True
[LINE#319] The utility of an action is calculated by comparing the initial case c- with the resulting final case c+.
0.952	[*A*]The utility of an action[*R*]is calculated[*A*]by comparing the initial case c- with the resulting final case	context()	negated: False ,passive: True
[LINE#320] The utility function is composed by a violation and a utilization term weighed by the factor 01: (4)utility=xPviolation(x)+utilization(x).
0.911	[*A*]a utilization term[*R*]weighed[*A*]by the factor 01	context()	negated: False ,passive: True
0.911	[*A*]The utility function[*R*]is composed[*A*]by a utilization term	context()	negated: False ,passive: True
0.911	[*A*]The utility function[*R*]is composed[*A*]by a violation ( x ) +utilization ( x	context()	negated: False ,passive: True
[LINE#321] Higher values for  strengthen the utilization of resources, whereas lower values the non-violation of SLA parameters.
[LINE#322] We further note that c(x) describes a case only with respect to parameter x.
0.239	[*A*]We[*R*]note[*A*]that c(x) describes a case only with respect to parameter	context()	negated: False ,passive: False
[LINE#323]  E.g., we say that a violation has occurred in c(x), when in case c.
0.896	[*A*]a violation[*R*]has occurred[*A*]in c	context(we say)	negated: False ,passive: True
0.309	[*A*]we[*R*]say[*A*]that a violation has occurred in c(x), when in case	context()	negated: False ,passive: False
[LINE#324+325+326]  We define the violation function for (5)violation(x)={1,No violation occurred in c+(x),but in c-(x)1/2,No violation occurred in c+(x)and c-(x)-1/2Violation occurred in c+(x) and c-(x)-1Violation occurred in c+(x),but not in c-(x).Theutilization function is calculated by comparing the used resources to the provided ones.
0.891	[*A*]1Violation[*R*]occurred[*A*]in c+	context(x ) . Theutilization function is calculated)	negated: False ,passive: True
0.745	[*A*]x ) . Theutilization function[*R*]is calculated	context()	negated: False ,passive: False
0.918	[*A*]No violation[*R*]occurred[*A*]in c+	context()	negated: False ,passive: True
0.452	[*A*]We[*R*]define[*A*]the violation function[*A*]for ( 5 ) violation	context()	negated: False ,passive: False
[LINE#327] We define the distance (x,y)=|x-y|, and utilization for every parameter as (6)utilization(x)={1,(px-,mx-)>(px+,ux+)-1,(px-,mx-)<(px+,ux+)0,otherwise .
0.452	[*A*]We[*R*]define[*A*]the distance ( x	context()	negated: False ,passive: False
[LINE#328] A utilization utility of 1 is retrieved if less over-provisioning of resources takes place in the final case than in the initial one, and a utilization utility of -1 if more over-provisioning of resources takes place in the final case than in the initial one.
0.919	[*A*]more over-provisioning of resources[*R*]takes[*A*]place[*A*]in the final case	context()	negated: False ,passive: True
0.948	[*A*]less over-provisioning of resources[*R*]takes[*A*]place[*A*]if more over-provisioning of resources takes place in the final case than in the initial one	context()	negated: False ,passive: True
0.952	[*A*]A utilization utility of 1[*R*]is retrieved[*A*]if less over-provisioning of resources takes place if more over-provisioning of resources takes place in the final case than in the initial one	context()	negated: False ,passive: True
0.919	[*A*]less over-provisioning of resources[*R*]takes[*A*]place[*A*]in the final case	context()	negated: False ,passive: True
0.952	[*A*]A utilization utility of 1[*R*]is retrieved[*A*]if less over-provisioning of resources takes place in the final case than in the initial one	context()	negated: False ,passive: True
[LINE#329]  The whole CBR process works as follows:.
0.878	[*A*]The whole CBR process[*R*]works[*A*]as follows:.	context()	negated: False ,passive: False
[LINE#330] Before the first iteration, we store the mentioned initial cases consisting of an initial measurement, an action and a resulting measurement.
0.808	[*A*]Before the first iteration , we store the mentioned initial cases[*R*]consisting[*A*]of a resulting measurement	context()	negated: False ,passive: True
0.452	[*A*]we[*R*]store[*A*]the mentioned initial cases consisting of a resulting measurement	context()	negated: False ,passive: False
0.808	[*A*]Before the first iteration , we store the mentioned initial cases[*R*]consisting[*A*]of an action	context()	negated: False ,passive: True
0.452	[*A*]we[*R*]store[*A*]the mentioned initial cases consisting of an action	context()	negated: False ,passive: False
0.808	[*A*]Before the first iteration , we store the mentioned initial cases[*R*]consisting[*A*]of an initial measurement	context()	negated: False ,passive: True
0.452	[*A*]we[*R*]store[*A*]the mentioned initial cases consisting of an initial measurement	context()	negated: False ,passive: False
[LINE#331] Then, when CBR receives a new measurement, this measurement is compared to all cases in the KB.
0.952	[*A*]this measurement[*R*]is compared[*A*]to all cases in the KB[*A*]Then[*A*]when CBR receives a new measurement	context()	negated: False ,passive: True
0.855	[*A*]CBR[*R*]receives[*A*]a new measurement	context()	negated: False ,passive: False
[LINE#332] From the set of closest cases grouped by a clustering algorithm we choose the one with the highest utility and execute exactly the same action as in the chosen case.
0.702	[*A*]we[*R*]choose[*A*]the one with the highest utility as in the chosen case[*A*]From the set of closest cases	context()	negated: False ,passive: False
0.903	[*A*]closest cases[*R*]grouped[*A*]by a clustering algorithm	context()	negated: False ,passive: True
[LINE#333] Afterwards, this action, the resulting measurement and the utility of the action is added to the initial measurement, and stored as a complete case. .
0.957	[*A*]the utility of the action[*R*]is stored[*A*]as a complete case[*A*]Afterwards	context()	negated: False ,passive: True
0.948	[*A*]the resulting measurement[*R*]is stored[*A*]as a complete case[*A*]Afterwards	context()	negated: False ,passive: True
0.943	[*A*]this action[*R*]is stored[*A*]as a complete case[*A*]Afterwards	context()	negated: False ,passive: True
0.957	[*A*]the utility of the action[*R*]is added[*A*]to the initial measurement[*A*]Afterwards	context()	negated: False ,passive: True
0.948	[*A*]the resulting measurement[*R*]is added[*A*]to the initial measurement[*A*]Afterwards	context()	negated: False ,passive: True
0.943	[*A*]this action[*R*]is added[*A*]to the initial measurement[*A*]Afterwards	context()	negated: False ,passive: True
[LINE#334] the rule-based approach we first introduce several resource policy modes to reflect the overall utilization of the system in the VM configuration rules.
0.706	[*A*]we[*R*]introduce[*A*]several resource policy modes[*A*]to reflect the overall utilization of the system in the VM configuration rules[*A*]first	context()	negated: False ,passive: False
[LINE#335] Dealing with SLA-bound resource management, where resource usage is paid for on a "pay-as-you-go" basis with SLOs that guarantee a minimum capacity of these resources as described above, raises the question, whether the Cloud provider should allow the consumer to use more resources than agreed.
0.952	[*A*]resource usage[*R*]is paid[*A*]for[*A*]SLA-bound resource management	context()	negated: False ,passive: True
0.878	[*A*]the consumer[*R*]to use[*A*]more resources than agreed	context(the Cloud provider should allow)	negated: False ,passive: False
0.915	[*A*]the Cloud provider[*R*]should allow[*A*]the consumer to use more resources	context()	negated: False ,passive: False
[LINE#336] We will refer to this behavior as over-consumption.
0.452	[*A*]We[*R*]will refer[*A*]to this behavior as over-consumption	context()	negated: False ,passive: False
[LINE#337] Since the consumer will pay for every additional resource, it should be in the Cloud provider's interest to allow over-consumption as long as this behavior does not endanger the SLAs of other consumers.
0.918	[*A*]this behavior[*R*]does not endanger[*A*]the SLAs of other consumers	context()	negated: True ,passive: False
0.498	[*A*]it[*R*]should be[*A*]in the Cloud provider's interest[*A*]to allow over-consumption as long	context()	negated: False ,passive: True
0.903	[*A*]the consumer[*R*]will pay[*A*]for every additional resource	context()	negated: False ,passive: False
[LINE#338] Thus, Cloud providers should not allow over-consumption when the resulting penalties they have to pay are higher than the expected revenue from over-consumption.
0.741	[*A*]the resulting penalties they have to pay[*R*]are[*A*]higher than the expected revenue from over-consumption	context()	negated: False ,passive: True
0.875	[*A*]the resulting penalties[*R*]to pay[*A*]they	context()	negated: False ,passive: True
0.917	[*A*]Cloud providers[*R*]should not allow[*A*]over-consumption[*A*]when the resulting penalties they have to pay are higher than the expected revenue from over-consumption	context()	negated: True ,passive: False
[LINE#339] To tackle this problem, we introduce five policy modes for every resource that describe the interaction of the five escalation levels.
0.271	[*A*]we[*R*]introduce[*A*]five policy modes for every resource that describe the interaction of the five escalation levels	context()	negated: False ,passive: False
0.921	[*A*]five policy modes for every resource[*R*]describe[*A*]the interaction of the five escalation levels	context()	negated: False ,passive: False
[LINE#340] As can be seen in Table 3 the policy modes are green, green-orange, orange, orange-red and red.
0.783	[*A*]the policy modes[*R*]are[*A*]red	context()	negated: False ,passive: True
0.783	[*A*]the policy modes[*R*]are[*A*]orange - red	context()	negated: False ,passive: True
0.783	[*A*]the policy modes[*R*]are[*A*]orange	context()	negated: False ,passive: True
0.911	[*A*]the policy modes[*R*]are[*A*]green - orange	context()	negated: False ,passive: True
0.783	[*A*]the policy modes[*R*]are[*A*]green	context()	negated: False ,passive: True
[LINE#341] They range from low utilization of the system with lots of free resources left (policy mode green) over a scarce resource situation (policy mode orange) to an extremely tight resource situation (policy mode red), where it is impossible to fulfill all SLAs to their full extent and decisions have to be made which SLAs to deliberately break and which applications to outsource.
0.943	[*A*]free resources[*R*]left[*A*]policy mode green ) over a scarce resource situation ( policy mode orange ) to an extremely tight resource situation	context()	negated: False ,passive: True
0.616	[*A*]They[*R*]range[*A*]from low utilization of the system	context()	negated: False ,passive: True
[LINE#342+343]  In order to know whether a resource r is in danger of under-provisioning or already is under-provisioned, or whether it is over-provisioned, we calculate the current utilization utr=userprr100, where user and prr signify how much of a resource r was used and provided, respectively, and divide the percentage range into three regions using the two "threat thresholds" TTlowr and TThighr: Region.
0.504	[*A*]we[*R*]calculate[*A*]the current utilization utr=userprr100, where user and prr signify	context()	negated: False ,passive: False
0.278	[*A*]it[*R*]is[*A*]over-provisioned	context()	negated: False ,passive: True
0.918	[*A*]a resource r[*R*]is[*A*]under-provisioned, or whether it is over-provisioned[*A*]already	context()	negated: False ,passive: True
0.939	[*A*]user and prr[*R*]signify[*A*]the current utilization utr=userprr100	context()	negated: False ,passive: False
[LINE#344+345+346]  Danger of under-provisioning, or under-provisioning (>TThighr).Region 0 : Well provisioned (TThighrandTTlowr).Region +1: Over-Provisioning(<TTlowr).The idea of this rule-based design is that the ideal value that we call target value tv(r) for utilization of a resource r is exactly in the center of region 0.
0.920	[*A*]the ideal value[*R*]call[*A*]target value tv	context()	negated: False ,passive: True
[LINE#347+348]  So, if the utilization value after some measurement leaves this region by using more (Region -1) or less resources (Region +1), then we reset the utilization to the target value, i.e., we increase or decrease allocated resources so that the utilization is again at tv(r)=TTlowr+TThighr2%.
0.170	[*A*]we[*R*]decrease	context()	negated: False ,passive: False
0.531	[*A*]we[*R*]reset[*A*]the utilization[*A*]to the target value[*A*]then	context()	negated: False ,passive: False
0.925	[*A*]the utilization[*R*]is[*A*]again[*A*]at tv(r)=TTlowr+TThighr2%	context()	negated: False ,passive: True
0.932	[*A*]the utilization value after some measurement[*R*]leaves[*A*]this region	context()	negated: False ,passive: False
[LINE#349] As long as the utilization value stays in region 0, no action will be executed.
0.957	[*A*]no action[*R*]will be executed[*A*]As long as the utilization value stays in region 0	context()	negated: False ,passive: True
0.911	[*A*]the utilization value[*R*]stays[*A*]in region 0	context()	negated: False ,passive: True
[LINE#350] E.g., for r=storage,TTlowr=60%, and TThighr=80%, the target value would be tv(r)=70%.
0.880	[*A*]E.g. for r=storage , TTlowr=60 % and TThighr=80 %[*R*]would have the target value of[*A*]70 %	context()	negated: False ,passive: False
0.973	[*A*]the target value[*R*]would be[*A*]70 %	context()	negated: False ,passive: False
0.911	[*A*]the target value[*R*]would be[*A*]tv(r)=70%	context()	negated: False ,passive: True
[LINE#351]  3 shows the regions and measurements (expressed as utilization of a certain resource).
0.449	[*A*]3[*R*]shows[*A*]the measurements	context()	negated: False ,passive: False
0.887	[*A*]the regions[*R*]expressed[*A*]as utilization of a certain resource	context()	negated: False ,passive: True
0.567	[*A*]3[*R*]shows[*A*]the regions ( expressed as utilization of a certain resource	context()	negated: False ,passive: False
[LINE#352] At t1 the utilization of the resource is in Region -1, because it is in danger of a violation.
0.522	[*A*]it[*R*]is[*A*]in danger of a violation	context()	negated: False ,passive: True
0.951	[*A*]the utilization of the resource[*R*]is[*A*]in Region -1[*A*]because it is in danger of a violation[*A*]At t1	context()	negated: False ,passive: True
[LINE#353] Thus, the KB recommends to increase the resource such that at the next iteration t2 the utilization is at the center of Region 0, which equals the target value.
0.779	[*A*]the KB[*R*]recommends to increase[*A*]the resource such that at the next iteration t2 the utilization is at the center of Region 0,	context(the KB recommends)	negated: False ,passive: False
0.833	[*A*]the KB[*R*]recommends[*A*]to increase the resource	context()	negated: False ,passive: False
0.914	[*A*]Region 0[*R*]equals[*A*]the target value	context()	negated: False ,passive: True
0.926	[*A*]the resource[*R*]is[*A*]at the center of Region 0	context()	negated: False ,passive: True
[LINE#354] At time steps t3 and t4 utilization stays in the center region and consequently, no action is required.
0.732	[*A*]no action[*R*]is required	context()	negated: False ,passive: False
0.938	[*A*]At time steps t3 and t4 utilization[*R*]stays[*A*]in the center region	context()	negated: False ,passive: True
[LINE#355] At t5, the resource is under-utilized and so the KB recommends the decrease of the resource to tv(r), which is attained at t6.
0.817	[*A*]tv ( r[*R*]is attained[*A*]at t6	context()	negated: False ,passive: True
0.867	[*A*]the KB[*R*]recommends[*A*]the decrease of the resource to tv ( r	context()	negated: False ,passive: False
0.977	[*A*]the resource[*R*]is[*A*]so the KB recommends the decrease of the resource to tv ( r[*A*]At t5	context()	negated: False ,passive: True
0.957	[*A*]the resource[*R*]is[*A*]under - utilized[*A*]At t5	context()	negated: False ,passive: True
[LINE#356] Additionally, if over-provisioning is allowed in the current policy mode, then the adjustment will always be executed as described regardless of what limit was agreed in the SLA.
0.954	[*A*]the adjustment[*R*]will be executed[*A*]as described regardless of what limit was agreed in the SLA[*A*]then[*A*]always	context()	negated: False ,passive: True
0.894	[*A*]over-provisioning[*R*]is allowed[*A*]in the current policy mode	context()	negated: False ,passive: True
[LINE#357]  On the other hand, if over-provisioning is not allowed in the current policy mode, then the rule will allocate at most as much as agreed in the SLA (SLOr).The concept of a rule increasing resource r is depicted in Fig..
0.937	[*A*]a rule increasing resource r[*R*]is depicted[*A*]in Fig	context()	negated: False ,passive: True
0.903	[*A*]a rule[*R*]increasing[*A*]resource r	context()	negated: False ,passive: False
0.970	[*A*]the rule[*R*]will allocate[*A*]at most[*A*]The concept of a rule increasing resource r is depicted in Fig[*A*]then	context()	negated: False ,passive: False
0.894	[*A*]over-provisioning[*R*]is not allowed[*A*]in the current policy mode	context()	negated: True ,passive: True
[LINE#358] The rule executes if the current utilization utr and the predicted utilization utpredictedr of the next iteration (cf.
0.937	[*A*]The rule[*R*]executes[*A*]the current utilization utr and the predicted utilization utpredictedr of the next iteration	context()	negated: False ,passive: False
0.732	[*A*]The rule[*R*]executes	context()	negated: False ,passive: False
[LINE#359] Depending on what policy level is active the rule either sets the provided resource prr to the target value tv(r) for policy levels green and green-orange (line 3) or to at most what was agreed in the SLA (SLOr) plus a certain percentage  to account for rounding errors when calculating the target value in policy levels orange, orange-red and red (line 5).
0.889	[*A*]the rule[*R*]sets[*A*]the provided resource prr[*A*]to the target value tv(r	context()	negated: False ,passive: False
[LINE#360]  A similar rule scheme for decreasing a resource can be seen in Fig..
0.952	[*A*]A similar rule scheme for decreasing a resource[*R*]can be seen[*A*]in Fig	context()	negated: False ,passive: True
[LINE#361] The main difference is that it does not distinguish between policy modes and that it sets the provisioned resource to at least a minimum value minPrr, which may be 0, that is needed to keep the application alive (line 4).
0.342	[*A*]0[*R*]is needed[*A*]to keep the application alive (line 4	context()	negated: False ,passive: True
0.575	[*A*]at least a minimum value[*R*]may be[*A*]0, that is needed	context()	negated: False ,passive: True
0.522	[*A*]it[*R*]sets[*A*]the provisioned resource[*A*]to at least a minimum value	context()	negated: False ,passive: False
0.397	[*A*]it[*R*]does not distinguish[*A*]between policy modes	context(The main difference is)	negated: True ,passive: False
0.776	[*A*]The main difference[*R*]is[*A*]that it does not distinguish between policy modes and that it sets the provisioned resource to at least a minimum value	context()	negated: False ,passive: True
[LINE#362+363]  The rule is executed if the current utilization utr and the predicted utilization utpredictedr of the next iteration both lie below TTlowr2).A large enough span between the thresholds TTlowr and TThighr helps to prevent oscillations of repeatedly increasing and decreasing the same resource.
0.934	[*A*]the predicted utilization utpredictedr of the next iteration[*R*]decreasing[*A*]the same resource	context()	negated: False ,passive: False
0.937	[*A*]The rule[*R*]is executed[*A*]if the predicted utilization utpredictedr of the next iteration both decreasing the same resource	context()	negated: False ,passive: True
0.905	[*A*]the current utilization utr[*R*]decreasing[*A*]the same resource	context()	negated: False ,passive: False
0.937	[*A*]The rule[*R*]is executed[*A*]if the current utilization utr both decreasing the same resource	context()	negated: False ,passive: True
0.944	[*A*]the predicted utilization utpredictedr of the next iteration[*R*]lie[*A*]below TTlowr2	context()	negated: False ,passive: True
0.947	[*A*]The rule[*R*]is executed[*A*]if the predicted utilization utpredictedr of the next iteration both lie below TTlowr2	context()	negated: False ,passive: True
0.920	[*A*]the current utilization utr[*R*]lie[*A*]below TTlowr2	context()	negated: False ,passive: True
0.918	[*A*]The rule[*R*]is executed[*A*]if the current utilization utr both lie below TTlowr2	context()	negated: False ,passive: True
[LINE#364] However, to further reduce the risk of oscillations, we suggest to calculate a prediction for the next value based on the latest measurements.
0.388	[*A*]we[*R*]suggest to calculate[*A*]a prediction for the next value	context(we suggest)	negated: False ,passive: False
0.388	[*A*]we[*R*]suggest[*A*]to calculate a prediction for the next value	context()	negated: False ,passive: False
0.911	[*A*]the next value[*R*]based[*A*]on the latest measurements	context()	negated: False ,passive: True
[LINE#365] Thus, an action is only invoked when the current AND the predicted measurement exceed the respective TT.
0.925	[*A*]the predicted measurement[*R*]exceed[*A*]the respective TT	context()	negated: False ,passive: False
0.880	[*A*]an action[*R*]is invoked[*A*]when the predicted measurement exceed the respective TT	context()	negated: False ,passive: True
0.613	[*A*]the current[*R*]exceed[*A*]the respective TT	context()	negated: False ,passive: False
0.880	[*A*]an action[*R*]is invoked[*A*]when the current exceed the respective TT	context()	negated: False ,passive: True
[LINE#366] So, especially when only one value exceeds the TT, no action is executed.
0.732	[*A*]no action[*R*]is executed	context()	negated: False ,passive: False
[LINE#367] The rules have been implemented using the Java rule engine Drools [41].
0.918	[*A*]The rules[*R*]have been implemented[*A*]using the Java rule engine Drools	context()	negated: False ,passive: True
[LINE#368] The Drools engine sets up a knowledge session consisting of different rules and a working memory.
0.911	[*A*]a knowledge session[*R*]consisting[*A*]of a working memory	context()	negated: False ,passive: True
0.933	[*A*]The Drools engine[*R*]sets up[*A*]a knowledge session consisting of a working memory	context()	negated: False ,passive: False
0.911	[*A*]a knowledge session[*R*]consisting[*A*]of different rules	context()	negated: False ,passive: True
0.933	[*A*]The Drools engine[*R*]sets up[*A*]a knowledge session consisting of different rules	context()	negated: False ,passive: False
[LINE#369] Rules get activated when specific elements are inserted into the working memory such that the conditional "when" part evaluates to true.
0.903	[*A*]specific elements[*R*]are inserted[*A*]into the working memory such	context()	negated: False ,passive: True
0.931	[*A*]Rules[*R*]get activated[*A*]when specific elements are inserted into the working memory such	context()	negated: False ,passive: True
0.737	[*A*]the working memory such[*R*]to true	context()	negated: False ,passive: False
0.947	[*A*]Rules[*R*]get[*A*]activated when specific elements are inserted into the working memory such	context()	negated: False ,passive: True
[LINE#370] Activated rules are then triggered by the simulation engine.
0.916	[*A*]Activated rules[*R*]are triggered[*A*]by the simulation engine[*A*]then	context()	negated: False ,passive: True
[LINE#371] In our case, the simulation engine inserts measurements and SLAs of applications into the working memory.
[LINE#372] Different policy modes will load slightly modified rules into the Drools engine and thus achieve a high adaptability of the KM system reacting to the general performance of the Cloud infrastructure.
0.944	[*A*]the KM system[*R*]reacting[*A*]to the general performance of the Cloud infrastructure	context()	negated: False ,passive: False
0.549	[*A*]Different[*R*]achieve[*A*]a high adaptability of the KM system	context()	negated: False ,passive: False
0.925	[*A*]Different policy modes[*R*]will load[*A*]slightly modified rules[*A*]into the Drools engine	context()	negated: False ,passive: False
[LINE#373] As opposed to the CBR approach in [7], the rule-based approach is able to fire more than one action at the same iteration, which inherently increases the flexibility of the system.
0.897	[*A*]the same iteration[*R*]inherently increases[*A*]the flexibility of the system	context()	negated: False ,passive: False
0.913	[*A*]the rule-based approach[*R*]to fire[*A*]more than one action[*A*]at the same iteration	context()	negated: False ,passive: False
0.964	[*A*]the rule-based approach[*R*]is[*A*]able to fire more than one action at the same iteration	context()	negated: False ,passive: True
[LINE#374+375]  Without loss of generality we can assume that one application runs on one VM (several applications' SLAs can be aggregated to form one VM SLA)and we assume the more interesting case of policy modes orange, orange-red or red, where over-provisioning is not allowed.
0.569	[*A*]we[*R*]assume[*A*]the more interesting case of policy modes orange, orange-red or red, where over-provisioning is not allowed	context()	negated: False ,passive: False
0.920	[*A*]several applications' SLAs[*R*]to form[*A*]one VM SLA	context()	negated: False ,passive: False
0.931	[*A*]several applications' SLAs[*R*]can be aggregated[*A*]to form one VM SLA	context()	negated: False ,passive: True
0.740	[*A*]over-provisioning[*R*]is not allowed[*A*]the more interesting case of policy modes orange, orange-red or red	context()	negated: True ,passive: True
0.736	[*A*]one application[*R*]runs	context(we can assume)	negated: False ,passive: False
0.195	[*A*]we[*R*]can assume[*A*]that one application runs on one VM (several applications' SLAs can be aggregated to form one VM SLA)and we assume the more interesting case of policy modes orange, orange-red or red	context()	negated: False ,passive: False
[LINE#376]  Listing 1 shows the rule to increase parameter storage formulated in the Drools language following the pattern presented in Fig..
0.918	[*A*]the pattern[*R*]presented[*A*]in Fig	context()	negated: False ,passive: True
0.732	[*A*]parameter storage[*R*]formulated	context()	negated: False ,passive: False
0.636	[*A*]Listing 1[*R*]shows[*A*]the rule to increase parameter storage	context()	negated: False ,passive: False
[LINE#377] Line 1 defines the name of the rule that is split into a condition part (when, lines 2-12) and an execution part (then, lines 13-17).
0.698	[*A*]the rule[*R*]is split	context()	negated: False ,passive: False
0.887	[*A*]the rule[*R*]is split[*A*]into a condition part	context()	negated: False ,passive: True
0.927	[*A*]Line 1[*R*]defines[*A*]the name of the rule	context()	negated: False ,passive: False
[LINE#378] Line 4 tries to find the SLA of an application, and stores its id in $slaID and the SLA into $slaApp.
0.847	[*A*]Line[*R*]stores[*A*]its id[*A*]in the SLA	context()	negated: False ,passive: False
0.847	[*A*]Line[*R*]stores[*A*]its id[*A*]in $ slaID into $ slaApp	context()	negated: False ,passive: False
0.924	[*A*]Line 4[*R*]tries to find[*A*]the SLA of an application	context(Line 4 tries)	negated: False ,passive: False
0.924	[*A*]Line 4[*R*]tries[*A*]to find the SLA of an application	context()	negated: False ,passive: False
[LINE#379+380]  Line 6 looks for a set of actions for this $slaID where no storage action has been added yet (storage ==false) in order to avoid contradicting actions for storage for one measurement.
0.911	[*A*]no storage action[*R*]has been added[*A*]yet[*A*]in order	context()	negated: False ,passive: True
0.788	[*A*]Line 6[*R*]looks	context()	negated: False ,passive: False
[LINE#381+382+383+384]  Line 8 searches for a measurement for the appropriate VM (vmID == $slaID) that has been inserted into working memory that is no prediction ($prediction == false) and where the percentage of utilized storage exceeds TThighr(storage_utilized>storage_HighTT), and stores used and provided values into $s_used and $s_provided, respectively.
0.718	[*A*]provided values into[*R*]s_provided	context()	negated: False ,passive: False
0.926	[*A*]working memory[*R*]is[*A*]where the percentage of utilized storage exceeds TThighr	context()	negated: False ,passive: True
0.788	[*A*]TThighr stores[*R*]used	context()	negated: False ,passive: False
0.937	[*A*]the percentage of utilized storage[*R*]exceeds[*A*]TThighr stores	context()	negated: False ,passive: False
0.926	[*A*]working memory[*R*]is[*A*]where the percentage of utilized storage exceeds TThighr stores	context()	negated: False ,passive: True
0.937	[*A*]the percentage of utilized storage[*R*]exceeds[*A*]TThighr ( storage_utilized	context()	negated: False ,passive: False
0.953	[*A*]working memory[*R*]is[*A*]where the percentage of utilized storage exceeds TThighr ( storage_utilized	context()	negated: False ,passive: True
0.940	[*A*]the appropriate VM[*R*]is[*A*]no prediction	context()	negated: False ,passive: True
0.922	[*A*]the appropriate VM[*R*]has been inserted[*A*]into working memory	context()	negated: False ,passive: True
[LINE#385] The predicted measurement for the next iteration is handled similarly in line 10.
0.938	[*A*]The predicted measurement for the next iteration[*R*]is handled similarly[*A*]in line 10	context()	negated: False ,passive: True
[LINE#386] Finally, line 12 checks whether provided storage is still below the agreed value in the SLA.
0.937	[*A*]provided storage[*R*]is[*A*]still[*A*]below the agreed value in the SLA	context()	negated: False ,passive: True
[LINE#387] This is done, because in policy modes orange to red over-consumption is prohibited.
0.878	[*A*]policy modes[*R*]orange[*A*]to red over-consumption[*A*]is prohibited	context()	negated: False ,passive: False
0.451	[*A*]This[*R*]is done[*A*]because in policy modes orange to red over-consumption is prohibited	context()	negated: False ,passive: True
[LINE#388] The rules for policy modes green and green-orange would omit this line.
0.943	[*A*]The rules for policy modes green - orange[*R*]would omit[*A*]this line	context()	negated: False ,passive: False
0.913	[*A*]The rules for policy modes[*R*]would omit[*A*]this line	context()	negated: False ,passive: False
0.732	[*A*]policy modes[*R*]green	context()	negated: False ,passive: False
[LINE#389] Now, if all these conditions are met, the rule gets activated.
0.698	[*A*]the rule[*R*]activated	context()	negated: False ,passive: False
0.886	[*A*]the rule[*R*]gets[*A*]activated[*A*]Now	context()	negated: False ,passive: True
0.751	[*A*]all these conditions[*R*]are met	context()	negated: False ,passive: False
[LINE#390]  When fired, line 15 calculates the new value for prr as explained in Fig..
0.952	[*A*]line 15[*R*]calculates[*A*]the new value for prr[*A*]as explained in Fig[*A*]When fired	context()	negated: False ,passive: False
[LINE#391] This line (as line 12) would also be altered for policy modes green and green-orange.
0.883	[*A*]This line ( as line 12[*R*]would be altered[*A*]for policy modes	context()	negated: False ,passive: True
0.883	[*A*]This line ( as line 12[*R*]would be altered[*A*]for policy modes green	context()	negated: False ,passive: True
[LINE#392] Line 17 then modifies the action container $as and inserts the appropriate storage action with the value for provided storage to be set.
0.785	[*A*]the value for provided storage[*R*]to be set	context()	negated: False ,passive: False
0.950	[*A*]Line 17[*R*]modifies[*A*]the action container $[*A*]then	context()	negated: False ,passive: False
[LINE#393] Other rules follow the same pattern as described here and in Fig. 4 for rules increasing resource allocations and in Fig. 5 for rules decreasing resource allocations.
0.918	[*A*]Other rules[*R*]follow[*A*]the same pattern as in Fig	context()	negated: False ,passive: True
0.894	[*A*]rules[*R*]decreasing[*A*]resource allocations	context()	negated: False ,passive: False
0.894	[*A*]rules[*R*]increasing[*A*]resource allocations	context()	negated: False ,passive: False
0.903	[*A*]Other rules[*R*]follow[*A*]the same pattern as described here	context()	negated: False ,passive: True
[LINE#394] The vision of Cloud Computing is to provide computing power as a utility, like gas, electricity or water [1].
0.973	[*A*]The vision of Cloud Computing[*R*]is[*A*]to provide computing power as a utility, like gas, electricity or water [1	context()	negated: False ,passive: True
[LINE#395] For the underlying infrastructure this means that it has to deal with dynamic load changes, ranging from peak performance to utilization gaps.
0.086	[*A*]this[*R*]means[*A*]that it has to deal with dynamic load changes	context()	negated: False ,passive: False
0.897	[*A*]dynamic load changes[*R*]ranging[*A*]from peak performance[*A*]to utilization gaps	context()	negated: False ,passive: True
0.411	[*A*]it[*R*]to deal[*A*]with dynamic load changes	context()	negated: False ,passive: False
[LINE#396] This brings up two issues: on the one hand, the management of a Cloud Computing infrastructure has to guarantee pre-established contracts despite all the dynamism of workload changes.
0.945	[*A*]the management of a Cloud Computing infrastructure[*R*]to guarantee[*A*]pre-established contracts[*A*]despite all the dynamism of workload changes	context()	negated: False ,passive: False
[LINE#397] On the other hand it has to efficiently utilize resources and reduce resource wastage.
0.411	[*A*]it[*R*]to efficiently reduce[*A*]resource wastage	context()	negated: False ,passive: False
0.411	[*A*]it[*R*]to efficiently utilize[*A*]resources	context()	negated: False ,passive: False
[LINE#398+399+400]  As to the former, the pre-established contracts, so called Service Level Agreements (SLAs), contain Service Level Objectives (SLOs) that represent Quality of , "storage should be at least 1000 GB", "bandwidth should beat least 10 Mbit/s" or "response time should be less than 2 s", and penalties that have to be paid to the customer if these goals are violated.
0.973	[*A*]storage[*R*]should be[*A*]1000 gb "	context()	negated: False ,passive: False
0.911	[*A*]bandwidth[*R*]should beat[*A*]least 10 Mbit/s	context()	negated: False ,passive: False
0.732	[*A*]these goals[*R*]are violated	context()	negated: False ,passive: False
0.911	[*A*]storage[*R*]should be[*A*]at least 1000 GB	context()	negated: False ,passive: True
0.877	[*A*]penalties[*R*]to be paid[*A*]to the customer[*A*]if these goals are violated	context()	negated: False ,passive: True
0.958	[*A*]Service Level Objectives[*R*]represent[*A*]Quality of , "storage should be at least 1000 GB", "bandwidth should beat least 10 Mbit/s" or "response time should be less than 2 s", and penalties	context()	negated: False ,passive: False
0.946	[*A*]the pre-established contracts, so called Service Level Agreements (SLAs)[*R*]contain[*A*]Service Level Objectives	context()	negated: False ,passive: False
0.903	[*A*]response time[*R*]should be[*A*]less than 2 s	context()	negated: False ,passive: True
0.913	[*A*]the pre-established contracts[*R*]so called[*A*]Service Level Agreements	context()	negated: False ,passive: True
[LINE#401] This work can be integrated into the Foundations of Self-governing ICT Infrastructure (FoSII) project [2], but is on its own completely self-sufficient.
0.870	[*A*]This work[*R*]is[*A*]on its own completely self - sufficient	context()	negated: False ,passive: True
0.947	[*A*]This work[*R*]can be integrated[*A*]into the Foundations of Self - governing ICT Infrastructure ( FoSII ) project	context()	negated: False ,passive: True
[LINE#402] The FoSII project aims at developing an infrastructure for autonomic SLA management and enforcement.
0.933	[*A*]The FoSII project[*R*]aims[*A*]at developing an infrastructure for enforcement	context()	negated: False ,passive: False
0.944	[*A*]The FoSII project[*R*]aims[*A*]at developing an infrastructure for autonomic SLA management	context()	negated: False ,passive: False
[LINE#403] Besides the already implemented LoM2HiS framework [3] that takes care of monitoring the state of the Cloud infrastructure and its applications, the knowledge management (KM) system presented in this article can be viewed as another building block of the FoSII infrastructure.
0.954	[*A*]the knowledge management ( KM ) system[*R*]can be viewed[*A*]as another building block of the FoSII infrastructure	context()	negated: False ,passive: True
0.220	[*A*]3[*R*]takes[*A*]care[*A*]of monitoring the state of its applications	context()	negated: False ,passive: False
0.953	[*A*]the knowledge management ( KM ) system[*R*]presented[*A*]in this article	context()	negated: False ,passive: True
0.501	[*A*]3[*R*]takes[*A*]care[*A*]of monitoring the state of the Cloud infrastructure , the knowledge management ( KM ) system	context()	negated: False ,passive: False
[LINE#404+405]  [4] proposes an approach to manage Cloud infrastructures by means of Autonomic Computing, which in a control loop monitors (M) Cloud parameters, analyzes (A) them, plans (P) actions and executes(E) them; the full cycle is known as MAPE [5].
0.334	[*A*]4[*R*]proposes[*A*]an approach to manage Cloud infrastructures	context(the full cycle is known)	negated: False ,passive: False
0.346	[*A*]them[*R*]executes[*A*]E	context(Autonomic Computing analyzes)	negated: False ,passive: False
0.924	[*A*]Autonomic Computing[*R*]analyzes[*A*]in a control loop monitors	context()	negated: False ,passive: False
0.334	[*A*]4[*R*]proposes[*A*]an approach to manage Cloud infrastructures	context(the full cycle is known)	negated: False ,passive: False
0.908	[*A*]the full cycle[*R*]is known[*A*]as MAPE	context()	negated: False ,passive: True
0.896	[*A*]Autonomic Computing[*R*]analyzes[*A*]them[*A*]in a control loop monitors	context()	negated: False ,passive: False
[LINE#406] According to [6] a MAPE-K loop stores knowledge (K) required for decision-making in a knowledge base (KB) that is accessed by the individual phases.
0.945	[*A*]a MAPE-K loop stores knowledge[*R*]is accessed[*A*]by the individual phases	context()	negated: False ,passive: True
0.945	[*A*]a MAPE-K loop stores knowledge[*R*]required[*A*]for decision-making[*A*]in a knowledge base	context()	negated: False ,passive: True
[LINE#407] This paper addresses the research question of finding a suitable KM system (i.e., a technique of how stored information should be used) and determining how it interacts with the other phases for dynamically and efficiently allocating resources.
0.918	[*A*]This paper[*R*]addresses[*A*]the research question of finding a suitable KM system	context()	negated: False ,passive: False
[LINE#408] One of the imminent problems that come up when dealing with the MAPE-K loop is to define possible actions that can be executed at the end of the loop.
0.887	[*A*]possible actions[*R*]can be executed[*A*]at the end of the loop	context()	negated: False ,passive: True
0.933	[*A*]One of the imminent problems[*R*]is[*A*]to define possible actions	context()	negated: False ,passive: True
0.913	[*A*]the imminent problems[*R*]come up[*A*]when dealing with the MAPE-K loop	context()	negated: False ,passive: True
[LINE#409+410]  Due to the plethora of possible reconfiguration actions in Clouds, e.g., increasing/decreasing available memory or storage for virtual machines (VMs), choosing VMs to migrate to selected physical machines (PMs), determining PMs to power on/off, etc., it is not trivial to identify the most beneficial action in a certain situation.
0.855	[*A*]VMs[*R*]to migrate[*A*]to selected physical machines	context()	negated: False ,passive: False
0.675	[*A*]PMs[*R*]to power[*A*]on/off	context()	negated: False ,passive: False
[LINE#411] On the one hand it is not trivial to retrieve and store all necessary information in a Cloud infrastructure.
[LINE#412] On the other hand, and more important in our work, dealing with the complexity of recommending an action based on this information is, as we will see, in most cases NP-hard.
0.445	[*A*]we[*R*]will see hard[*A*]in most cases	context()	negated: False ,passive: False
0.942	[*A*]dealing with the complexity of recommending an action[*R*]is[*A*]as we will see, in most cases NP-hard	context()	negated: False ,passive: True
0.903	[*A*]an action[*R*]based[*A*]on this information	context()	negated: False ,passive: True
[LINE#413] To tackle this, we structure all possible actions and organize them in a hierarchical model of so called escalation levels.
0.452	[*A*]we[*R*]structure[*A*]all possible actions	context()	negated: False ,passive: False
[LINE#414] In [7,8] we have shown that approaches using Case Based Reasoning (CBR) and rules as knowledge management techniques succeed in autonomically enacting SLAs and governing important parts of Cloud computing infrastructures.
0.867	[*A*]approaches[*R*]using[*A*]rules as knowledge management techniques	context(we have shown approaches using rules as knowledge management techniques succeed)	negated: False ,passive: False
0.933	[*A*]approaches using rules as knowledge management techniques[*R*]succeed[*A*]in governing important parts of Cloud computing infrastructures	context(we have shown)	negated: False ,passive: False
0.444	[*A*]we[*R*]have shown[*A*]that approaches using rules as knowledge management techniques succeed in governing important parts of Cloud computing infrastructures[*A*]In [ 7,8	context()	negated: False ,passive: False
0.925	[*A*]knowledge management techniques[*R*]succeed[*A*]in autonomically enacting SLAs	context()	negated: False ,passive: False
0.918	[*A*]that approaches[*R*]using[*A*]rules[*A*]as knowledge management techniques succeed in autonomically enacting SLAs	context()	negated: False ,passive: False
0.350	[*A*]we[*R*]have shown[*A*]that approaches using rules[*A*]In [ 7,8	context()	negated: False ,passive: False
0.911	[*A*]approaches[*R*]using[*A*]Case[*A*]Based Reasoning	context()	negated: False ,passive: False
0.393	[*A*]we[*R*]have shown[*A*]that approaches using Case Based Reasoning ( CBR )[*A*]In [ 7,8	context()	negated: False ,passive: False
[LINE#415] Case Based Reasoning was chosen, because it offers a natural translation of Cloud status information into formal knowledge representation and an easy integration with the MAPE phases.
0.498	[*A*]it[*R*]offers[*A*]a natural translation of Cloud status information[*A*]into an easy integration with the MAPE phases	context()	negated: False ,passive: False
0.924	[*A*]Case Based Reasoning[*R*]was chosen[*A*]because it offers a natural translation of Cloud status information into an easy integration with the MAPE phases	context()	negated: False ,passive: True
0.614	[*A*]it[*R*]offers[*A*]a natural translation of Cloud status information into formal knowledge representation	context()	negated: False ,passive: False
0.924	[*A*]Case Based Reasoning[*R*]was chosen[*A*]because it offers a natural translation of Cloud status information into formal knowledge representation	context()	negated: False ,passive: True
[LINE#416] Moreover, it promises to be scalable (as opposed to e.g., Situation Calculus) and easily configurable (as opposed to rule-based systems).
0.965	[*A*]Situation Calculus[*R*]to rule[*A*]( as opposed to e.g. , Situation Calculus to rule - based systems	context(it promises)	negated: False ,passive: False
0.183	[*A*]it[*R*]promises[*A*]to be scalable	context()	negated: False ,passive: False
0.197	[*A*]it[*R*]to be[*A*]scalable	context()	negated: False ,passive: True
[LINE#417] Related work has not observed the usage of CBR nor has it evaluated different KM techniques in Cloud environments.
0.918	[*A*]Related work[*R*]has not observed[*A*]the usage of CBR	context()	negated: True ,passive: False
[LINE#418] However, we determined some drawbacks of CBR as far as its learning performance and its scalability were concerned.
0.341	[*A*]its scalability[*R*]were concerned	context()	negated: False ,passive: False
0.363	[*A*]its learning performance[*R*]were concerned	context()	negated: False ,passive: False
0.491	[*A*]we[*R*]determined as far[*A*]some drawbacks of CBR	context()	negated: False ,passive: False
[LINE#419] Therefore, we also designed and implemented a rule-based knowledge management approach.
0.411	[*A*]we[*R*]implemented[*A*]a rule - based knowledge management approach	context()	negated: False ,passive: False
0.170	[*A*]we[*R*]designed	context()	negated: False ,passive: False
[LINE#420] Using rules [8] we managed to improve not only SLA adherence and resource allocation efficiency as discussed in [7], but also attained an efficient use of reallocation actions and high scalability.
0.903	[*A*]Using rules[*R*]attained[*A*]an efficient use of high scalability	context()	negated: False ,passive: False
0.903	[*A*]Using rules[*R*]attained[*A*]an efficient use of reallocation actions	context()	negated: False ,passive: False
0.388	[*A*]we[*R*]managed to improve[*A*]resource allocation efficiency	context(we managed)	negated: False ,passive: False
0.504	[*A*]we[*R*]managed[*A*]to improve resource allocation efficiency as discussed in [ 7 ]	context()	negated: False ,passive: False
0.443	[*A*]we[*R*]managed to improve[*A*]not only SLA adherence	context(we managed)	negated: False ,passive: False
0.443	[*A*]we[*R*]managed[*A*]to improve not only SLA adherence	context()	negated: False ,passive: False
[LINE#421] Yet, evaluating the KM system on a real environment is not a trivial task because of two reasons: First, Cloud infrastructures usually are huge data centers consisting of hundreds of PMs and even more VMs.
0.946	[*A*]Cloud infrastructures[*R*]are[*A*]huge data centers consisting of even more VMs[*A*]First[*A*]usually	context()	negated: False ,passive: True
0.925	[*A*]huge data centers[*R*]consisting[*A*]of even more VMs	context()	negated: False ,passive: True
0.946	[*A*]evaluating the KM system on a real environment[*R*]is not[*A*]a trivial task[*A*]because of two reasons	context(Cloud infrastructures are)	negated: True ,passive: True
0.946	[*A*]Cloud infrastructures[*R*]are[*A*]huge data centers consisting of hundreds of PMs[*A*]First[*A*]usually	context()	negated: False ,passive: True
0.925	[*A*]huge data centers[*R*]consisting[*A*]of hundreds of PMs	context()	negated: False ,passive: True
[LINE#422] Thus, a first step is to simulate the impact of autonomic management decisions on the Cloud infrastructure to determine the performance of the KM decisions.
0.963	[*A*]a first step[*R*]is[*A*]to simulate the impact of autonomic management decisions on the Cloud infrastructure	context()	negated: False ,passive: True
[LINE#423] Consequently, we designed and implemented a simulation engine that mimics the MAPE-K cycle on large Clouds.
0.913	[*A*]a simulation engine[*R*]mimics[*A*]the MAPE - K cycle	context()	negated: False ,passive: False
0.195	[*A*]we[*R*]designed	context()	negated: False ,passive: False
[LINE#424] Second, workload data for a large number of VMs has to be provided as input for the simulation.
0.950	[*A*]workload data for a large number of VMs[*R*]to be provided[*A*]as input for the simulation	context()	negated: False ,passive: True
[LINE#425] We decided to go two ways: On the one hand, we generated synthetic workload data categorized into different workload volatility classes.
0.388	[*A*]We[*R*]decided[*A*]to go two ways	context(we generated)	negated: False ,passive: False
0.388	[*A*]we[*R*]generated[*A*]synthetic workload data categorized into different workload volatility classes	context()	negated: False ,passive: False
0.911	[*A*]synthetic workload data[*R*]categorized[*A*]into different workload volatility classes	context()	negated: False ,passive: True
[LINE#426] These workload volatility classes are determined by the speed and intensity of workload change.
0.919	[*A*]These workload volatility classes[*R*]are determined[*A*]by the intensity of workload change	context()	negated: False ,passive: True
0.919	[*A*]These workload volatility classes[*R*]are determined[*A*]by the speed	context()	negated: False ,passive: True
[LINE#427] On the other hand, we gathered real world data from monitoring scientific workflow applications in the field of bioinformatics [9].
0.388	[*A*]we[*R*]gathered real world data from monitoring[*A*]scientific workflow applications in the field of bioinformatics	context(we gathered)	negated: False ,passive: False
0.504	[*A*]we[*R*]gathered[*A*]real world data[*A*]from monitoring scientific workflow applications in the field of bioinformatics	context()	negated: False ,passive: False
[LINE#428+429]  These workflows need a huge, yet unpredictable and varying amount of resources, and are thus-due to the needed flexibility and scalability-a perfect match for a Cloud computing application [10].The main challenge in this work is to evaluate KM techniques for autonomic SLA enactment in Cloud computing infrastructures that fulfill the three following conflicting goals:(i) achieving low SLA violation rates; (ii) achieving high resource utilization such that the level of allocated but unused resources is as low as possible; and (iii) achieving (i) and (ii) by as few time- and energy-consuming reallocation actions as possible.
0.938	[*A*]These workflows[*R*]are[*A*]thus-due to the needed flexibility and scalability-a perfect match for a Cloud computing application [10].The main challenge in this work	context()	negated: False ,passive: True
0.892	[*A*]Cloud computing infrastructures[*R*]fulfill[*A*]the three following conflicting goals:(i) achieving low SLA violation rates; (ii) achieving high resource utilization such that the level of allocated but unused resources is as low as possible; and (iii) achieving (i) and (ii) by as few time- and energy-consuming reallocation actions as possible	context()	negated: False ,passive: False
0.876	[*A*]the level of allocated but unused resources[*R*]is[*A*]as low as possible	context()	negated: False ,passive: True
[LINE#430] We will call this problem the resource allocation problem throughout the rest of the paper.
0.452	[*A*]We[*R*]will call[*A*]this problem[*A*]the resource allocation problem	context()	negated: False ,passive: False
[LINE#431] The main contributions of this paper are: 1.Design and implementation of a generic (KM-technique agnostic) simulation engine to assess the quality of the KM and decision-making techniques.2.Partitioning the resource allocation problem for Cloud infrastructures into several subproblems by proposing escalation levels that structure all possible reaction possibilities into different subproblems using a hierarchical model.3.Design, Implementation and Evaluation of two KM techniques for one escalation level, i.e., VM resource configuration: CBR, and the rule-based approach.4.Application of the rule-based approach to real-world monitoring data from scientific workflow applications in the field of bioinformatics.
0.957	[*A*]The main contributions of this paper[*R*]are[*A*]implementation of a generic ( KM - technique agnostic ) simulation engine	context()	negated: False ,passive: True
0.887	[*A*]escalation levels[*R*]structure[*A*]all possible reaction possibilities	context()	negated: False ,passive: False
0.544	[*A*]the KM[*R*]techniques.2.Partitioning the resource allocation problem for Cloud infrastructures by proposing[*A*]escalation levels that structure all possible reaction possibilities	context(the KM techniques.2.Partitioning)	negated: False ,passive: False
0.858	[*A*]the KM[*R*]techniques.2.Partitioning[*A*]the resource allocation problem for Cloud infrastructures[*A*]into several subproblems	context()	negated: False ,passive: False
0.801	[*A*]The main contributions of this paper[*R*]are	context()	negated: False ,passive: False
[LINE#432]  The remainder of this work is divided as follows:.
0.814	[*A*]The remainder of this work[*R*]is divided[*A*]as follows:.	context()	negated: False ,passive: True
[LINE#433] In Section 2 we present related work.
[LINE#434] Section 3 gives some background information by explaining the MAPE-K loop and the FoSII project.
0.903	[*A*]Section 3[*R*]gives[*A*]some background information	context()	negated: False ,passive: False
[LINE#435] In Section 4 we structure the problem into the mentioned escalation levels, and in Section 5 we describe how to use the two KM techniques (CBR and rules) to tackle the resource allocation problem for a certain escalation level.
0.686	[*A*]we[*R*]describe[*A*]how to use the two KM techniques ( rules ) to tackle the resource allocation problem for a certain escalation level[*A*]in Section 5	context()	negated: False ,passive: False
0.444	[*A*]we[*R*]describe to use[*A*]the two KM techniques[*A*]to tackle the resource allocation problem for a certain escalation level	context(we describe)	negated: False ,passive: False
0.686	[*A*]we[*R*]describe[*A*]how to use the two KM techniques ( CBR ) to tackle the resource allocation problem for a certain escalation level[*A*]in Section 5	context()	negated: False ,passive: False
0.595	[*A*]we[*R*]structure[*A*]the problem[*A*]into the mentioned escalation levels[*A*]In Section 4	context()	negated: False ,passive: False
[LINE#436] Section 6 shows the evaluation of both approaches, especially focusing on the rule-based approach.
0.925	[*A*]Section 6[*R*]shows[*A*]the evaluation of both approaches[*A*]especially focusing on the rule-based approach	context()	negated: False ,passive: False
[LINE#437] Section 7 concludes this contribution and points out future work.
0.894	[*A*]Section[*R*]points out[*A*]future work	context()	negated: False ,passive: False
0.903	[*A*]Section 7[*R*]concludes[*A*]this contribution	context()	negated: False ,passive: False
[LINE#438+439]  Related workConcerning related work, we have determined four different ways to compare our work with other achievements in this area.
0.418	[*A*]we[*R*]have determined[*A*]four different ways to compare our work with other achievements in this area	context()	negated: False ,passive: False
[LINE#440] Whereas the first level compares other works dealing with SLA enactment and resource efficiency, the second one considers the area of knowledge management, and the third one compares commercial products to our approach.
0.903	[*A*]other works[*R*]dealing[*A*]with resource efficiency	context()	negated: False ,passive: False
0.911	[*A*]the first level[*R*]compares[*A*]other works dealing with resource efficiency	context()	negated: False ,passive: False
0.911	[*A*]the second one[*R*]considers[*A*]the area of knowledge management	context()	negated: False ,passive: False
0.918	[*A*]other works[*R*]dealing[*A*]with SLA enactment	context()	negated: False ,passive: False
0.925	[*A*]the first level[*R*]compares[*A*]other works dealing with SLA enactment	context()	negated: False ,passive: False
0.848	[*A*]the third one[*R*]compares[*A*]commercial products[*A*]to our approach	context()	negated: False ,passive: False
[LINE#441] Fourthly, the FoSII project is briefly related to other projects in this field.
0.901	[*A*]the FoSII project[*R*]is related[*A*]to other projects in this field	context()	negated: False ,passive: True
[LINE#442] Firstly, there has been some considerable work on optimizing resource usage while keeping QoS goals.
[LINE#443] These papers, however, concentrate on specific subsystems of Large Scale Distributed Systems, such as [11] on the performance of memory systems, or only deal with one or two specific SLA parameters.
0.905	[*A*]These papers[*R*]deal[*A*]with one or two specific SLA parameters	context()	negated: False ,passive: False
0.785	[*A*]specific subsystems of Large Scale[*R*]Distributed	context()	negated: False ,passive: False
0.938	[*A*]These papers[*R*]concentrate[*A*]on specific subsystems of Large Scale Distributed Systems, such as [11[*A*]on the performance of memory systems	context()	negated: False ,passive: False
[LINE#444] [13] investigate one general resource constraint and Khanna et al.
[LINE#445] [14] only focuses on response time and throughput.
0.503	[*A*]14[*R*]focuses[*A*]on throughput	context()	negated: False ,passive: False
0.503	[*A*]14[*R*]focuses[*A*]on response time	context()	negated: False ,passive: False
[LINE#446] A quite similar approach to our concept is provided by the Sandpiper framework [15], which offers black-box and gray-box resource management for VMs.
0.922	[*A*]the Sandpiper framework[*R*]offers[*A*]black - gray - box resource management	context()	negated: False ,passive: False
0.922	[*A*]the Sandpiper framework[*R*]offers[*A*]black - box	context()	negated: False ,passive: False
0.775	[*A*]A quite similar approach to our concept[*R*]is provided[*A*]by the Sandpiper framework	context()	negated: False ,passive: True
[LINE#447] Contrary to our approach, though, it plans reactions just after violations have occurred.
0.522	[*A*]it[*R*]plans[*A*]reactions	context()	negated: False ,passive: False
[LINE#448] Also the VCONF model by Rao et al.
[LINE#449] [16] has similar goals as presented in Section 1, but depends on specific parameters, can only execute one action per iteration and it neglects the energy consumption of executed actions.
0.452	[*A*]it[*R*]neglects[*A*]the energy consumption of executed actions	context()	negated: False ,passive: False
0.544	[*A*]16[*R*]depends[*A*]on specific parameters	context()	negated: False ,passive: False
0.573	[*A*]16[*R*]has[*A*]similar goals as presented in Section 1	context()	negated: False ,passive: False
[LINE#450] Other papers focus on different escalation levels (as described in Section 4).
0.903	[*A*]Other papers[*R*]focus[*A*]on different escalation levels	context()	negated: False ,passive: False
[LINE#451] [17,18] focus on VM migration and [19] on turning on and off physical machines, whereas our paper focuses on VM re-configuration.
0.680	[*A*]our paper[*R*]focuses[*A*]on VM re-configuration	context()	negated: False ,passive: False
[LINE#452] Additionally, none of the presented papers uses a KB for recording past action and learning.
0.926	[*A*]none of the presented papers[*R*]uses[*A*]a KB for recording past learning	context()	negated: False ,passive: False
0.926	[*A*]none of the presented papers[*R*]uses[*A*]a KB for recording past action	context()	negated: False ,passive: False
[LINE#453] [20] also undertake a speculative approach as in our work by overbooking PM resources.
0.354	[*A*]20[*R*]undertake[*A*]a speculative approach[*A*]as in our work	context()	negated: False ,passive: False
[LINE#454] They assign VMs to PMs that would exceed their maximum resource capacities, because VMs hardly ever use all their assigned resources.
0.064	[*A*]that[*R*]would exceed[*A*]their maximum resource capacities	context(VMs to PMs)	negated: False ,passive: False
0.554	[*A*]VMs[*R*]to PMs[*A*]that would exceed their maximum resource capacities	context()	negated: False ,passive: False
0.829	[*A*]VMs[*R*]use[*A*]all their assigned resources[*A*]hardly ever	context()	negated: False ,passive: False
[LINE#455] Computing this allocation they also take into consideration workload correlation of different VMs.
0.556	[*A*]they[*R*]take[*A*]into consideration[*A*]workload correlation of different VMs	context()	negated: False ,passive: False
[LINE#456] [21] tackle the trade-off between consolidating VMs on PMs and turning off PMs on the one hand, and attaining SLOs for CPU and memory on the other.
[LINE#457] However, the authors assume a static setting and do not consider dynamically changing workloads.
0.878	[*A*]the authors[*R*]do not consider dynamically changing[*A*]workloads	context(the authors do not consider)	negated: True ,passive: False
0.878	[*A*]the authors[*R*]do not consider[*A*]dynamically changing workloads	context()	negated: True ,passive: False
0.903	[*A*]the authors[*R*]assume[*A*]a static setting	context()	negated: False ,passive: False
[LINE#458] So, e.g., they do not take the number of migrations into account.
0.616	[*A*]they[*R*]do not take[*A*]the number of migrations[*A*]into account	context()	negated: True ,passive: False
[LINE#459] [22] in a similar setting define the resource allocation problem for static workloads, present the optimal solution for small instances and evaluate heuristics by simulations.
[LINE#460] [23], e.g., also deal with VM placement on PMs using scheduling techniques.
[LINE#461] [24] react to changing workload demands by starting new VM instances; taking into account VM startup time, they use prediction models to have VMs available already before the peak occurs.
0.552	[*A*]they[*R*]use prediction models to have[*A*]VMs available already before the peak occurs	context(they use)	negated: False ,passive: False
0.552	[*A*]they[*R*]use[*A*]prediction models[*A*]to have VMs available already	context()	negated: False ,passive: False
0.732	[*A*]the peak[*R*]occurs	context()	negated: False ,passive: False
[LINE#462] Other works such as [25] have already considered the last escalation level (see Section 4), i.e., outsourcing of applications to other Clouds.
0.963	[*A*]Other works such as [25[*R*]have considered[*A*]the last escalation level (see Section 4), i.e., outsourcing of applications to other Clouds[*A*]already	context()	negated: False ,passive: False
[LINE#463] Summarizing we can say that there has been a great deal of work on the different escalation levels, whereas VM configuration has not been observed yet.
0.195	[*A*]we[*R*]can say[*A*]that there has been a great deal of work on the different escalation levels, whereas VM configuration has not been observed yet	context()	negated: False ,passive: False
0.817	[*A*]VM configuration[*R*]has not been observed[*A*]yet	context()	negated: True ,passive: True
[LINE#464] Secondly, there has been work on KM of SLAs, especially rule-based systems.
[LINE#465] Paschke and Bichler [26] look into a rule based approach in combination with the logical formalism ContractLog.
0.940	[*A*]Bichler[*R*]look[*A*]into a rule based approach in combination with the logical formalism	context()	negated: False ,passive: False
0.948	[*A*]Paschke[*R*]look[*A*]into a rule based approach in combination with the logical formalism	context()	negated: False ,passive: False
[LINE#466] It specifies rules to trigger after a violation has occurred, but it does not deal with avoidance of SLA violations.
0.498	[*A*]it[*R*]does not deal[*A*]with avoidance of SLA violations	context()	negated: True ,passive: False
0.732	[*A*]a violation[*R*]has occurred	context()	negated: False ,passive: False
0.894	[*A*]rules[*R*]to trigger[*A*]after a violation has occurred	context()	negated: False ,passive: False
0.452	[*A*]It[*R*]specifies[*A*]rules[*A*]to trigger after a violation has occurred	context()	negated: False ,passive: False
[LINE#467] Others inspected the use of ontologies as KBs only at a conceptual level.
0.911	[*A*]Others[*R*]inspected[*A*]the use of ontologies as KBs	context()	negated: False ,passive: False
[LINE#468] [27] viewed the system in four layers (i.e., business, system, network and device) and broke down the SLA into relevant information for each layer, which had the responsibility of allocating required resources.
0.503	[*A*]27[*R*]viewed[*A*]the system	context()	negated: False ,passive: False
0.503	[*A*]27[*R*]viewed[*A*]the system[*A*]in four layers	context()	negated: False ,passive: False
0.913	[*A*]each layer[*R*]had[*A*]the responsibility of allocating required resources	context()	negated: False ,passive: False
0.590	[*A*]27[*R*]broke down[*A*]the SLA[*A*]into relevant information[*A*]for each layer	context()	negated: False ,passive: False
[LINE#469] Again, no details on how to achieve this have been given.
0.888	[*A*]no details on how to achieve this[*R*]have been given[*A*]Again	context()	negated: False ,passive: True
[LINE#470] Bahati and Bauer [28] also use policies, i.e., rules, to achieve autonomic management.
0.922	[*A*]Bauer [ 28[*R*]use[*A*]policies , i.e. , rules[*A*]to achieve autonomic management	context()	negated: False ,passive: False
0.877	[*A*]Bahati[*R*]use[*A*]policies , i.e. , rules[*A*]to achieve autonomic management	context()	negated: False ,passive: False
[LINE#471] They provide a system architecture including a KB and a learning component, and divide all possible states of the system into so called regions, which they assign a certain benefit for being in this region.
0.616	[*A*]They[*R*]provide[*A*]a system architecture including a learning component	context()	negated: False ,passive: False
0.658	[*A*]They[*R*]provide[*A*]a system architecture including a KB	context()	negated: False ,passive: False
0.897	[*A*]so called regions[*R*]assign[*A*]a certain benefit for being in this region	context()	negated: False ,passive: True
[LINE#472+473]  A bad region would be, e.g., response time>500 (too slow), fair region responsetime<100 (too fast, consuming unnecessary resources) and a good region 100response time500.
0.934	[*A*]fair region responsetime < 100 ( too fast[*R*]consuming[*A*]unnecessary resources	context()	negated: False ,passive: False
0.895	[*A*]A bad region[*R*]would be[*A*]e.g.[*A*]response time	context()	negated: False ,passive: True
[LINE#474] The actions are not structured, but are mixed together into a single rule, which makes the rules very hard to manage and to determine a salience concept behind them.
0.883	[*A*]a single rule[*R*]makes[*A*]the rules very hard to determine a salience concept behind them	context()	negated: False ,passive: False
0.897	[*A*]a single rule[*R*]makes[*A*]the rules very hard to manage	context()	negated: False ,passive: False
0.903	[*A*]The actions[*R*]are mixed together[*A*]into a single rule	context()	negated: False ,passive: True
0.732	[*A*]The actions[*R*]are not structured	context()	negated: True ,passive: False
[LINE#475] However, we share the idea of defining "over-utilized", "neutral" and "under-utilized" regions.
0.569	[*A*]we[*R*]share[*A*]the idea of defining " under - utilized " regions	context()	negated: False ,passive: False
0.452	[*A*]we[*R*]share[*A*]the idea of defining " neutral	context()	negated: False ,passive: False
0.452	[*A*]we[*R*]share[*A*]the idea of defining " over-utilized	context()	negated: False ,passive: False
[LINE#476] Our KM system allows us to choose any arbitrary number of resource parameters that can be adjusted on a VM.
0.397	[*A*]us[*R*]to choose[*A*]any arbitrary number of resource parameters	context(Our KM system allows)	negated: False ,passive: False
0.534	[*A*]Our KM system[*R*]allows[*A*]us to choose any arbitrary number of resource parameters	context()	negated: False ,passive: False
0.905	[*A*]resource parameters[*R*]can be adjusted[*A*]on a VM	context()	negated: False ,passive: True
[LINE#477] Moreover, our paper provides a more wholesome approach than related work and integrates the different action levels that work has been carried out on.
0.945	[*A*]the different action levels[*R*]has been carried out[*A*]work	context()	negated: False ,passive: True
0.638	[*A*]our paper[*R*]provides[*A*]a more wholesome approach than related work	context()	negated: False ,passive: False
[LINE#478] Thirdly, commercial Cloud IaaS platforms such as Amazon EC2 [29], Rackspace [30] or RightScale [31] have a very limited choice of preconfigured and static VM resource provisioning types.
0.984	[*A*]commercial Cloud IaaS platforms such as Amazon EC2 [29], Rackspace [30] or RightScale [31[*R*]have[*A*]a very limited choice of preconfigured and static VM resource provisioning types	context()	negated: False ,passive: False
[LINE#479] Amazon EC2 only offers VM instance types such as small, medium or large with predefined storage, computing units, and memory without the possibility of reconfiguring or fine-tuning them beforehand, not to mention during runtime.
0.918	[*A*]Amazon EC2[*R*]offers[*A*]VM instance types such as small, medium or large with predefined storage, computing units, and memory without the possibility of reconfiguring or fine-tuning them beforehand, not to mention during runtime	context()	negated: False ,passive: False
[LINE#480] Rackspace only offers storage on the IaaS level, and RightScale focuses more on integrating different IaaS platforms such as Amazon EC2 or Rackspace into a holistic view.
0.957	[*A*]RightScale[*R*]focuses[*A*]more[*A*]on integrating different IaaS platforms such as Amazon EC2 or Rackspace into a holistic view	context()	negated: False ,passive: False
0.921	[*A*]Rackspace[*R*]offers[*A*]storage[*A*]on the IaaS level	context()	negated: False ,passive: False
[LINE#481] Fourthly, compared to other SLA management projects like SLA@SOI [32], the FoSII project in general is more specific on Cloud Computing aspects like deployment, monitoring of resources and their translation into high level SLAs instead of just working on high-level SLAs in general service-oriented architectures.
0.959	[*A*]the FoSII project in general[*R*]is[*A*]more specific on Cloud Computing aspects like deployment , monitoring of their translation into high level SLAs	context()	negated: False ,passive: True
0.964	[*A*]the FoSII project in general[*R*]is[*A*]more specific on Cloud Computing aspects like deployment	context()	negated: False ,passive: True
[LINE#482] Structuring the problem: escalation levelsThis section presents a methodology of dividing the resource allocation problem into smaller subproblems using a hierarchical approach.
0.903	[*A*]smaller subproblems[*R*]using[*A*]a hierarchical approach	context()	negated: False ,passive: False
0.943	[*A*]escalation levelsThis section[*R*]presents[*A*]a methodology of dividing the resource allocation problem into smaller subproblems	context()	negated: False ,passive: False
[LINE#483] It demonstrates which actions can be executed in what level to achieve SLA adherence and efficient resource allocation for Cloud infrastructures.
0.560	[*A*]It[*R*]demonstrates[*A*]which actions can be executed in what level to achieve efficient resource allocation for Cloud infrastructures	context()	negated: False ,passive: False
0.560	[*A*]It[*R*]demonstrates[*A*]which actions can be executed in what level to achieve SLA adherence	context()	negated: False ,passive: False
[LINE#484+485+486+487]  In general, we can think of the following reallocation actions: 1.for individual applications: (a)Increase incoming bandwidth share by x%.(b)Decrease incoming bandwidth share by x%.(c)Increase outgoing bandwidth share by x%.(d)Decrease outgoing bandwidth share by x%.(e)Increase memory by x%.(f)Decrease memory by x%.(g)Add allocated storage by x%.(h)Remove allocated storage by x%.(i)Increase CPU share by x%.(j)Decrease CPU share by x%.(k)Outsource (move application) to other Cloud.(l)Insource (accept application) from other Cloud.(m)Migrate application to different VM.2.for VMs: ( a)Increase incoming bandwidth share by x%.(b)Decrease incoming bandwidth share by x%.(c)Increase outgoing bandwidth share by x%.(d)Decrease outgoing bandwidth share by x%.(e)Increase memory by x%.(f)Decrease memory by x%.(g)Add allocated storage by x%.(h)Remove allocated storage by x%.(i)Increase CPU share by x%.(j)Decrease CPU share by x%.(k)Outsource (move VM) to other Cloud.(l)Insource (accept VM) from other Cloud.(m)Migrate VM to different PM.3.for physical machines (computing nodes): (a)Addx computing nodes.4.Do nothing.
0.877	[*A*]Addx[*R*]computing[*A*]nodes.4.Do nothing	context()	negated: False ,passive: False
0.928	[*A*]different PM.3.for physical machines[*R*]computing[*A*]nodes	context()	negated: False ,passive: False
0.411	[*A*]i[*R*]Increase[*A*]CPU share	context()	negated: False ,passive: False
0.388	[*A*]we[*R*]can think[*A*]of the following reallocation actions	context()	negated: False ,passive: False
[LINE#488] For an application, under "increase incoming bandwidth share" we understand to increase the application's share of all the available incoming bandwidth of a VM, and for a VM the share relates to all the available incoming bandwidth of a PM.
0.952	[*A*]the share[*R*]relates[*A*]to all the available incoming bandwidth of a PM[*A*]for a VM	context()	negated: False ,passive: True
0.560	[*A*]we[*R*]understand to increase[*A*]the application 's share of all the available incoming bandwidth of a VM	context(we understand)	negated: False ,passive: False
0.560	[*A*]we[*R*]understand[*A*]to increase the application 's share of all the available incoming bandwidth of a VM	context()	negated: False ,passive: False
[LINE#489] The idea of bandwidth sharing is a common idea in network systems as described in [36].
0.943	[*A*]The idea of bandwidth sharing[*R*]is[*A*]a common idea in network systems[*A*]as described in [36	context()	negated: False ,passive: True
[LINE#490] Similar arguments account for outgoing bandwidth or CPU share.
0.903	[*A*]Similar arguments[*R*]account[*A*]for outgoing bandwidth or CPU share	context()	negated: False ,passive: False
[LINE#491] We then group these actions into so called escalation levels that we define in Table 1.
0.920	[*A*]so called escalation levels[*R*]define[*A*]in Table 1	context()	negated: False ,passive: True
0.554	[*A*]We[*R*]group[*A*]these actions[*A*]into so called escalation levels[*A*]then	context()	negated: False ,passive: False
[LINE#492] The idea is that every problem that occurs should be solved on the lowest escalation level.
0.900	[*A*]every problem that occurs[*R*]should be solved[*A*]on the lowest escalation level	context(The idea is)	negated: False ,passive: True
0.853	[*A*]The idea[*R*]is[*A*]that every problem that occurs should be solved on the lowest escalation level	context()	negated: False ,passive: True
0.698	[*A*]every problem[*R*]occurs	context()	negated: False ,passive: False
[LINE#493] Only if this is not possible, the problem is tried to be solved on the next level, and again, if this fails, on the next one, and so on.
0.106	[*A*]this[*R*]fails so on	context()	negated: False ,passive: False
0.887	[*A*]the problem[*R*]to be solved[*A*]on the next level[*A*]if this fails , so on	context()	negated: False ,passive: True
0.153	[*A*]this[*R*]fails	context()	negated: False ,passive: False
0.887	[*A*]the problem[*R*]to be solved[*A*]on the next level[*A*]if this fails	context()	negated: False ,passive: True
0.732	[*A*]the problem[*R*]is tried	context()	negated: False ,passive: False
[LINE#494] The levels are ordered in a way such that lower levels offer faster and more local solutions than higher ones.
0.903	[*A*]lower levels[*R*]offer[*A*]more local solutions than higher ones	context()	negated: False ,passive: False
0.903	[*A*]lower levels[*R*]offer[*A*]faster local solutions than higher ones	context()	negated: False ,passive: False
0.732	[*A*]The levels[*R*]are ordered	context()	negated: False ,passive: False
[LINE#495] At every level it has to be decided, whether the proposed action should be executed or not, because it is important to know when to do nothing, since every reallocation action is time and energy consuming.
0.713	[*A*]energy[*R*]consuming	context()	negated: False ,passive: False
0.932	[*A*]every reallocation action[*R*]is[*A*]time and energy consuming	context()	negated: False ,passive: True
0.706	[*A*]the proposed action[*R*]should be executed	context(it to be decided)	negated: False ,passive: False
0.140	[*A*]it[*R*]to be decided	context()	negated: False ,passive: False
[LINE#496] In fact, for every level there is the possibility not to execute the proposed action.
[LINE#497] If the proposed action is not executed, then the decision-making process will stop and not evaluate whether the next escalation level should be considered or not.
0.929	[*A*]the decision-making process[*R*]not evaluate[*A*]whether the next escalation level should be considered or not	context()	negated: True ,passive: False
0.785	[*A*]the decision-making process[*R*]will stop	context()	negated: False ,passive: False
0.751	[*A*]the proposed action[*R*]is not executed	context()	negated: True ,passive: False
[LINE#498] The first escalation level ("change VM configuration") works locally on a PM and tries to change the amount of storage or memory, e.g., that is allocated to the VM from the PM resources.
0.944	[*A*]the amount of storage or memory, e.g.[*R*]is allocated[*A*]to the VM	context()	negated: False ,passive: True
0.939	[*A*]The first escalation level[*R*]tries[*A*]to change the amount of storage or memory, e.g.	context()	negated: False ,passive: False
0.905	[*A*]The first escalation level[*R*]works locally[*A*]on a PM	context()	negated: False ,passive: False
[LINE#499] Then, migrating applications (escalation level 2) is more lightweight than migrating VMs and turning PMs on/off (escalation levels 3 and 4).
0.730	[*A*]migrating applications[*R*]is off[*A*]Then	context()	negated: False ,passive: True
0.973	[*A*]migrating applications[*R*]is[*A*]more lightweight than turning PMs on / off ( escalation levels 3[*A*]Then	context()	negated: False ,passive: True
0.957	[*A*]migrating applications[*R*]is[*A*]more lightweight than migrating VMs[*A*]Then	context()	negated: False ,passive: True
[LINE#500] For all three escalation levels already the whole system state has to be taken into account to find an optimal solution.
0.983	[*A*]all three escalation levels already the whole system state has to be taken into account[*R*]to find[*A*]an optimal solution[*A*]already	context()	negated: False ,passive: False
0.905	[*A*]the whole system state[*R*]to be taken[*A*]into account	context()	negated: False ,passive: True
[LINE#501] The problem stemming from escalation level 3 alone can be formulated into a binary integer problem (BIP), which is known to be NP-complete [37].
0.920	[*A*]a binary integer problem[*R*]to be[*A*]NP-complete	context()	negated: False ,passive: True
0.920	[*A*]a binary integer problem[*R*]is known[*A*]to be NP-complete	context()	negated: False ,passive: True
0.943	[*A*]The problem stemming from escalation level 3 alone[*R*]can be formulated[*A*]into a binary integer problem	context()	negated: False ,passive: True
0.903	[*A*]The problem[*R*]stemming[*A*]from escalation level 3 alone	context()	negated: False ,passive: True
[LINE#502] The proof is out of scope for this paper, but a similar approach can be seen in [12].
0.993	[*A*]a similar approach[*R*]can be seen in[*A*]12 ]	context()	negated: False ,passive: False
0.783	[*A*]a similar approach[*R*]can be seen[*A*]in [ 12	context()	negated: False ,passive: True
0.925	[*A*]The proof[*R*]is[*A*]out of scope	context()	negated: False ,passive: True
[LINE#503] The last escalation level has least locality and greatest complexity, since the capacity of other Cloud infrastructures have to be taken into account, too, and negotiations have to be started with them as well.
0.929	[*A*]The last escalation level[*R*]has[*A*]greatest complexity[*A*]since the negotiations have to be started with them as well	context()	negated: False ,passive: False
0.940	[*A*]the capacity of other Cloud infrastructures[*R*]to be taken[*A*]into account	context()	negated: False ,passive: True
0.967	[*A*]The last escalation level[*R*]has[*A*]greatest complexity[*A*]since the capacity of other Cloud infrastructures have to be taken into account , too	context()	negated: False ,passive: False
0.806	[*A*]the negotiations[*R*]to be started as well[*A*]with them	context()	negated: False ,passive: True
0.908	[*A*]The last escalation level[*R*]has least[*A*]locality[*A*]since the negotiations have to be started with them as well	context()	negated: False ,passive: False
0.956	[*A*]The last escalation level[*R*]has least[*A*]locality[*A*]since the capacity of other Cloud infrastructures have to be taken into account , too	context()	negated: False ,passive: False
[LINE#504] Also the rule-based approach benefits from this hierarchical action level model, because it provides a salience concept for contradicting rules.
0.452	[*A*]it[*R*]provides[*A*]a salience concept for contradicting rules	context()	negated: False ,passive: False
[LINE#505] Without this concept it would be troublesome to determine which of the actions, e.g., "Power on additional PM with extra storage and migrate VM to this PM", "Increase storage for VM by 10%" or "Migrate application to another VM with more storage" should be executed, if a certain threshold for allocated storage has been exceeded.
0.849	[*A*]Migrate application to another VM with more storage[*R*]should be executed	context()	negated: False ,passive: False
0.801	[*A*]a certain threshold for allocated storage[*R*]has been exceeded	context()	negated: False ,passive: False
[LINE#506] The proposed KM approaches will present a solution for escalation level 1.
0.939	[*A*]The proposed KM approaches[*R*]will present[*A*]a solution for escalation level 1	context()	negated: False ,passive: False
[LINE#507] 2 visualizes the escalation levels from Table 1 before and after actions are executed.
0.713	[*A*]actions[*R*]are executed	context()	negated: False ,passive: False
0.425	[*A*]2[*R*]visualizes[*A*]the escalation levels from Table 1 before[*A*]after actions are executed	context()	negated: False ,passive: False
[LINE#508+509]  Fig. 2(a) shows applications App1 and App2 deployed on VM1that is itself deployed on PM1, whereas App3 runs on VM2 running on PM2.
0.917	[*A*]App3[*R*]runs on VM2 running[*A*]on PM2	context(App3 runs)	negated: False ,passive: False
0.932	[*A*]App2[*R*]deployed[*A*]on VM1that	context()	negated: False ,passive: True
0.948	[*A*]App3[*R*]runs[*A*]on VM2	context()	negated: False ,passive: False
0.953	[*A*]a ) shows applications App1[*R*]deployed[*A*]on VM1that	context()	negated: False ,passive: False
[LINE#510] 2(b) shows example actions for all five escalation levels.
0.856	[*A*]2(b[*R*]shows[*A*]example actions for all five escalation levels	context()	negated: False ,passive: False
[LINE#511] The legend numbers correspond to the respective numbering of the escalation levels.
0.911	[*A*]The legend numbers[*R*]correspond[*A*]to the respective numbering of the escalation levels	context()	negated: False ,passive: True
[LINE#512] Escalation level 1: At first, the autonomic manager considers whether it should change VM configuration or not.
0.433	[*A*]it[*R*]should change[*A*]VM configuration	context(the autonomic manager considers)	negated: False ,passive: False
0.902	[*A*]the autonomic manager[*R*]considers[*A*]whether it should change VM configuration or not[*A*]At first	context()	negated: False ,passive: False
[LINE#513+514]  Actions (1) show that the autonomic manager decided to change the VM configuration; VM1 is being up-sized and VM2 being down-sized.Escalation level 2: If VM reconfiguration has taken place, or if it has been recommended, but cannot be fulfilled yet, because some resource cannot be increased anymore due to the constraints of the PM hosting the VM, in level 2the autonomic manager considers migrating the application to another larger VM that fulfills the required specifications from level 1.
0.855	[*A*]VM2[*R*]being[*A*]down-sized.Escalation level 2	context()	negated: False ,passive: True
0.903	[*A*]some resource[*R*]can not be increased[*A*]anymore[*A*]due to the constraints of the PM	context()	negated: True ,passive: True
0.922	[*A*]another larger VM[*R*]fulfills[*A*]the required specifications from level 1	context()	negated: False ,passive: False
0.852	[*A*]the PM[*R*]hosting[*A*]the VM	context()	negated: False ,passive: False
0.195	[*A*]it[*R*]has been recommended	context()	negated: False ,passive: False
0.927	[*A*]VM reconfiguration[*R*]has taken[*A*]place	context()	negated: False ,passive: True
0.908	[*A*]the autonomic manager[*R*]decided to change[*A*]the VM configuration	context(Actions show the autonomic manager decided)	negated: False ,passive: False
0.908	[*A*]the autonomic manager[*R*]decided[*A*]to change the VM configuration	context(Actions show)	negated: False ,passive: False
0.843	[*A*]Actions[*R*]show[*A*]that the autonomic manager decided to change the VM configuration	context()	negated: False ,passive: False
[LINE#515] So if, e.g., provided storage needs to be increased from 500 to 800 GB, but only 200 GB are available on the respective VM, then the application has to be migrated to a VM that has at least the same resources as the current one plus the remaining 100 GB of storage.
0.905	[*A*]provided storage[*R*]to be increased[*A*]from only 200 GB	context()	negated: False ,passive: True
0.879	[*A*]a VM[*R*]has[*A*]at least the same resources	context()	negated: False ,passive: False
0.934	[*A*]a VM[*R*]has[*A*]at least the same resources as the remaining 100 GB of storage	context()	negated: False ,passive: False
0.698	[*A*]the application[*R*]to be migrated	context()	negated: False ,passive: False
0.905	[*A*]provided storage[*R*]to be increased[*A*]from 500[*A*]to 800 GB	context()	negated: False ,passive: True
0.879	[*A*]a VM[*R*]has[*A*]at least the same resources as the current one	context()	negated: False ,passive: False
[LINE#516] Action (2) shows the re-deployment of App2 to VM2.
0.919	[*A*]Action[*R*]shows[*A*]the re-deployment of App2[*A*]to VM2	context()	negated: False ,passive: False
[LINE#517] Due to possible confinements of some applications to certain VMs, e.g., a user deployed several applications that need to work together on one VM, this escalation might be skipped in some scenarios.
0.879	[*A*]several applications[*R*]need to work together[*A*]on one VM	context(several applications need)	negated: False ,passive: False
0.879	[*A*]several applications[*R*]need[*A*]to work together on one VM	context()	negated: False ,passive: False
0.878	[*A*]this escalation[*R*]might be skipped[*A*]in some scenarios	context(a user deployed)	negated: False ,passive: True
0.835	[*A*]a user[*R*]deployed[*A*]several applications that need to work together on one VM	context()	negated: False ,passive: False
[LINE#518+519]  Also for Infrastructure as a Service (IaaS) providers, who directly provide the VMs without caring about the applications running on them, this escalation level is omitted.Escalation level 3: If there is no appropriate VM available in level 2, or if level 2 is skipped and VM configurations have been recommended in level 1, in level 3the autonomic manager considers creating a new VM on an appropriate PM or migrating the VM to a PM that has enough available resources.
0.835	[*A*]the applications[*R*]running[*A*]on them	context()	negated: False ,passive: True
0.927	[*A*]VM configurations[*R*]have been recommended[*A*]in level 1[*A*]in level 3the	context()	negated: False ,passive: True
0.843	[*A*]a PM[*R*]has[*A*]enough available resources	context()	negated: False ,passive: False
0.732	[*A*]level 2[*R*]is skipped	context()	negated: False ,passive: False
0.950	[*A*]a Service (IaaS) providers[*R*]directly provide[*A*]the VMs	context()	negated: False ,passive: False
[LINE#520]  Action (3) shows the re-deployment of VM2 to PM1.Escalation level 4:.
0.919	[*A*]Action[*R*]shows[*A*]the re-deployment of VM2[*A*]to PM1.Escalation level 4	context()	negated: False ,passive: False
[LINE#521] Again, if there is no appropriate PM available in level 3, the autonomic manager suggests turning on a new PM (or turning it off if the last VM was emigrated from this PM) in level 4.
0.933	[*A*]the last VM[*R*]was emigrated[*A*]from this PM	context()	negated: False ,passive: True
0.848	[*A*]the autonomic manager[*R*]suggests[*A*]turning on a new turning it off	context()	negated: False ,passive: False
0.911	[*A*]the autonomic manager[*R*]suggests[*A*]turning on a new PM	context()	negated: False ,passive: False
[LINE#522]  Action (4) shows powering on a new PM (PM3).Escalation level 5:.
0.802	[*A*]Action (4[*R*]shows[*A*]powering	context()	negated: False ,passive: False
[LINE#523] Finally, the last escalation level 5 tries to outsource the application to another Cloud provider as explained, e.g., in the Reservoir project [38].
0.920	[*A*]the last escalation level 5[*R*]tries to outsource[*A*]the application to another Cloud provider	context(the last escalation level 5 tries)	negated: False ,passive: False
0.954	[*A*]the last escalation level 5[*R*]tries[*A*]to outsource the application to another Cloud provider[*A*]Finally	context()	negated: False ,passive: False
[LINE#524] Action (5) outsources App3 to another Cloud provider.
0.937	[*A*]Action (5) outsources[*R*]App3[*A*]to another Cloud provider	context()	negated: False ,passive: True
[LINE#525] For an IaaS provider omitting escalation level 2, the sequence of these escalation levels is quite obvious: If VM sizes are not changed in escalation level 1, there is no need to trigger escalation level 3 as VMs have not changed, and no better allocation of VMs to PMs can be found, if the previous one was already optimal.
0.828	[*A*]the previous one[*R*]was[*A*]already[*A*]optimal	context()	negated: False ,passive: True
0.922	[*A*]no better allocation of VMs[*R*]can be found[*A*]if the previous one was already optimal	context()	negated: False ,passive: True
0.927	[*A*]VM sizes[*R*]are not changed[*A*]in escalation level 1	context()	negated: True ,passive: True
0.634	[*A*]VMs[*R*]have not changed	context()	negated: True ,passive: False
0.933	[*A*]an IaaS provider[*R*]omitting[*A*]escalation level 2	context()	negated: False ,passive: False
[LINE#526] However, if VM sizes were changed, escalation level 3 can still come to the conclusion that VM migrations are unnecessary.
0.817	[*A*]VM migrations[*R*]are[*A*]unnecessary	context()	negated: False ,passive: True
0.840	[*A*]escalation level 3[*R*]can come[*A*]to the conclusion that VM migrations are unnecessary[*A*]still	context()	negated: False ,passive: True
0.788	[*A*]VM sizes[*R*]were changed	context()	negated: False ,passive: False
[LINE#527] On the other hand, if VM migrations were recommended, some PMs could be then turned off in escalation level 4.
0.936	[*A*]some PMs[*R*]could be turned off[*A*]in escalation level 4[*A*]then	context()	negated: False ,passive: True
0.788	[*A*]VM migrations[*R*]were recommended	context()	negated: False ,passive: False
[LINE#528] Similarly, if no migrations were triggered, thinking about turning off PMs is unnecessary, as no PMs run idle now that have not been running idle before.
0.696	[*A*]no PMs[*R*]run idle[*A*]now	context()	negated: False ,passive: False
0.732	[*A*]no migrations[*R*]were triggered	context()	negated: False ,passive: False
[LINE#529] Finally, if all the previous actions were successfully executed without the help of another Cloud provider, there is no need to consider outsourcing applications.
0.769	[*A*]all the previous actions[*R*]were successfully executed	context()	negated: False ,passive: False
[LINE#530] Only if the last possibility failed, outsourcing applications should be considered.
0.732	[*A*]outsourcing applications[*R*]should be considered	context()	negated: False ,passive: False
[LINE#531]  (Other business incentives for outsourcing applications such as cheaper execution costs in other Clouds, etc., are not considered here.).
[LINE#532] For providers of other Cloud delivery models such as SaaS or PaaS, the sequence of placing application migration after VM reconfiguration is arguable; another model could also propose an inverse sequence for these two levels.
0.859	[*A*]another model[*R*]could propose[*A*]an inverse sequence for these two levels	context()	negated: False ,passive: False
0.855	[*A*]VM reconfiguration[*R*]is[*A*]arguable	context()	negated: False ,passive: True
